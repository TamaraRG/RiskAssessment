{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ead2005-672a-48c0-9b23-0fad71af0159",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, itertools, re, sqlite3, math, os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Normalization\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rcParams\n",
    "from IPython.display import display, Markdown\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66b8f361-8239-42d9-a43b-ed4b7e33d796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10572, 21) (10572,)\n",
      "(1760, 21) (1760,)\n",
      "(1764, 21) (1764,)\n"
     ]
    }
   ],
   "source": [
    "rcParams[\"figure.figsize\"] = (18,8)\n",
    "rcParams[\"axes.spines.top\"] = False\n",
    "rcParams[\"axes.spines.right\"] = False\n",
    "current_path = os.getcwd()\n",
    "sys.path.append(current_path)\n",
    "\n",
    "# enable to get always the same result model\n",
    "tf.keras.utils.set_random_seed(1)\n",
    "tf.random.set_seed(1)\n",
    "#tf.config.experimental.enable_op_determinism()\n",
    "\n",
    "NUM_OF_CATEGORIES = 4\n",
    "EPOCHS = 3000\n",
    "\n",
    "feature_column = \"k_rechtsvorm,k_sbi1,k_sbi2,k_sbi3,j_account,j_subcat,j_bedrag,c_investeringsverw,c_beursontwikkeling,m_M,m_UM,m_TA,r_bestaan,r_voorkomen,r_volledigheid,r_nauwkeurigheid,r_waardering,r_afgrenzing,r_classificatie,r_presentatie,r_rechten_en_verplichtingen\"\n",
    "feature_names = feature_column.split(',')\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_valid = []\n",
    "y_valid = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "conn = sqlite3.connect(os.path.join(current_path,\"tmp\",\"save.db3\"))\n",
    "curr = conn.cursor()\n",
    "curr.execute(f\"Select {feature_column},result,set_type FROM DataSet\")\n",
    "label_size_cor = None\n",
    "for row in curr.fetchall():\n",
    "    label_size_cor = (len(feature_names),len(row)-2)\n",
    "    if row[-1] == \"training\":\n",
    "        X_train.append(row[:-2])\n",
    "        y_train.append(row[-2])\n",
    "    if row[-1] == \"valid\":\n",
    "        X_valid.append(row[:-2])\n",
    "        y_valid.append(row[-2])\n",
    "    if row[-1] == \"test\":\n",
    "        X_test.append(row[:-2])\n",
    "        y_test.append(row[-2])\n",
    "conn.close()\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "X_valid = np.array(X_valid)\n",
    "y_valid = np.array(y_valid)\n",
    "X_test = np.array(X_test)\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_valid.shape, y_valid.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    "\n",
    "from keras import utils\n",
    "y_nosparse_train = utils.to_categorical(y_train, NUM_OF_CATEGORIES)\n",
    "y_nosparse_valid = utils.to_categorical(y_valid, NUM_OF_CATEGORIES)\n",
    "y_nosparse_test = utils.to_categorical(y_test, NUM_OF_CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ce4a864-e763-45b2-aadd-14f25998c11a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[START] Pre-training step:\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 0.915707\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 0.891889\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 0.838549\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 0.802529\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 0.792035\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 0.799653\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 0.847493\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 0.900758\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 0.999769\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 1.179654\n",
      ">> Epoch 1 finished \tRBM Reconstruction error 200.691254\n",
      ">> Epoch 2 finished \tRBM Reconstruction error 306.441498\n",
      ">> Epoch 3 finished \tRBM Reconstruction error 248.558105\n",
      ">> Epoch 4 finished \tRBM Reconstruction error 295.272522\n",
      ">> Epoch 5 finished \tRBM Reconstruction error 300.310516\n",
      ">> Epoch 6 finished \tRBM Reconstruction error 367.513885\n",
      ">> Epoch 7 finished \tRBM Reconstruction error 245.103653\n",
      ">> Epoch 8 finished \tRBM Reconstruction error 225.044815\n",
      ">> Epoch 9 finished \tRBM Reconstruction error 307.389191\n",
      ">> Epoch 10 finished \tRBM Reconstruction error 269.989227\n",
      "[END] Pre-training step\n",
      "[START] Fine tuning step:\n",
      ">> Epoch 0 finished \tANN training loss 1.351452 Accuracy: 0.305713\n",
      ">> Epoch 1 finished \tANN training loss 1.433904 Accuracy: 0.266364\n",
      ">> Epoch 2 finished \tANN training loss 1.356993 Accuracy: 0.323118\n",
      ">> Epoch 3 finished \tANN training loss 1.339980 Accuracy: 0.335982\n",
      ">> Epoch 4 finished \tANN training loss 1.353612 Accuracy: 0.323874\n",
      ">> Epoch 5 finished \tANN training loss 1.366732 Accuracy: 0.276958\n",
      ">> Epoch 6 finished \tANN training loss 1.369361 Accuracy: 0.331820\n",
      ">> Epoch 7 finished \tANN training loss 1.349854 Accuracy: 0.340522\n",
      ">> Epoch 8 finished \tANN training loss 1.347782 Accuracy: 0.329550\n",
      ">> Epoch 9 finished \tANN training loss 1.344386 Accuracy: 0.321226\n",
      ">> Epoch 10 finished \tANN training loss 1.335651 Accuracy: 0.343549\n",
      ">> Epoch 11 finished \tANN training loss 1.345632 Accuracy: 0.348846\n",
      ">> Epoch 12 finished \tANN training loss 1.332527 Accuracy: 0.307983\n",
      ">> Epoch 13 finished \tANN training loss 1.330300 Accuracy: 0.312902\n",
      ">> Epoch 14 finished \tANN training loss 1.371347 Accuracy: 0.321226\n",
      ">> Epoch 15 finished \tANN training loss 1.326316 Accuracy: 0.326523\n",
      ">> Epoch 16 finished \tANN training loss 1.348738 Accuracy: 0.299659\n",
      ">> Epoch 17 finished \tANN training loss 1.307548 Accuracy: 0.338630\n",
      ">> Epoch 18 finished \tANN training loss 1.289381 Accuracy: 0.383277\n",
      ">> Epoch 19 finished \tANN training loss 1.288601 Accuracy: 0.382142\n",
      ">> Epoch 20 finished \tANN training loss 1.316847 Accuracy: 0.339387\n",
      ">> Epoch 21 finished \tANN training loss 1.283363 Accuracy: 0.390087\n",
      ">> Epoch 22 finished \tANN training loss 1.252980 Accuracy: 0.415059\n",
      ">> Epoch 23 finished \tANN training loss 1.326484 Accuracy: 0.383277\n",
      ">> Epoch 24 finished \tANN training loss 1.716329 Accuracy: 0.326901\n",
      ">> Epoch 25 finished \tANN training loss 1.289211 Accuracy: 0.358683\n",
      ">> Epoch 26 finished \tANN training loss 1.488384 Accuracy: 0.317821\n",
      ">> Epoch 27 finished \tANN training loss 1.246332 Accuracy: 0.427166\n",
      ">> Epoch 28 finished \tANN training loss 1.369228 Accuracy: 0.364737\n",
      ">> Epoch 29 finished \tANN training loss 1.189474 Accuracy: 0.454408\n",
      ">> Epoch 30 finished \tANN training loss 1.239704 Accuracy: 0.392736\n",
      ">> Epoch 31 finished \tANN training loss 1.219874 Accuracy: 0.386303\n",
      ">> Epoch 32 finished \tANN training loss 1.180400 Accuracy: 0.438138\n",
      ">> Epoch 33 finished \tANN training loss 1.187930 Accuracy: 0.450246\n",
      ">> Epoch 34 finished \tANN training loss 1.167358 Accuracy: 0.474082\n",
      ">> Epoch 35 finished \tANN training loss 1.216974 Accuracy: 0.459705\n",
      ">> Epoch 36 finished \tANN training loss 1.155936 Accuracy: 0.480893\n",
      ">> Epoch 37 finished \tANN training loss 1.113422 Accuracy: 0.495649\n",
      ">> Epoch 38 finished \tANN training loss 1.336637 Accuracy: 0.413167\n",
      ">> Epoch 39 finished \tANN training loss 1.075686 Accuracy: 0.517215\n",
      ">> Epoch 40 finished \tANN training loss 1.191518 Accuracy: 0.450246\n",
      ">> Epoch 41 finished \tANN training loss 1.108873 Accuracy: 0.517594\n",
      ">> Epoch 42 finished \tANN training loss 1.104631 Accuracy: 0.507756\n",
      ">> Epoch 43 finished \tANN training loss 1.098240 Accuracy: 0.491109\n",
      ">> Epoch 44 finished \tANN training loss 1.092841 Accuracy: 0.542944\n",
      ">> Epoch 45 finished \tANN training loss 1.132257 Accuracy: 0.474839\n",
      ">> Epoch 46 finished \tANN training loss 1.071810 Accuracy: 0.534998\n",
      ">> Epoch 47 finished \tANN training loss 1.029938 Accuracy: 0.557321\n",
      ">> Epoch 48 finished \tANN training loss 1.127602 Accuracy: 0.483920\n",
      ">> Epoch 49 finished \tANN training loss 1.109717 Accuracy: 0.480136\n",
      ">> Epoch 50 finished \tANN training loss 1.175032 Accuracy: 0.452894\n",
      ">> Epoch 51 finished \tANN training loss 1.037387 Accuracy: 0.549754\n",
      ">> Epoch 52 finished \tANN training loss 1.019034 Accuracy: 0.550132\n",
      ">> Epoch 53 finished \tANN training loss 1.119190 Accuracy: 0.501324\n",
      ">> Epoch 54 finished \tANN training loss 0.989446 Accuracy: 0.557321\n",
      ">> Epoch 55 finished \tANN training loss 0.975237 Accuracy: 0.584563\n",
      ">> Epoch 56 finished \tANN training loss 0.992883 Accuracy: 0.576239\n",
      ">> Epoch 57 finished \tANN training loss 1.171735 Accuracy: 0.489217\n",
      ">> Epoch 58 finished \tANN training loss 0.939347 Accuracy: 0.603103\n",
      ">> Epoch 59 finished \tANN training loss 1.008556 Accuracy: 0.565267\n",
      ">> Epoch 60 finished \tANN training loss 0.932079 Accuracy: 0.601211\n",
      ">> Epoch 61 finished \tANN training loss 0.983070 Accuracy: 0.566780\n",
      ">> Epoch 62 finished \tANN training loss 0.904872 Accuracy: 0.629588\n",
      ">> Epoch 63 finished \tANN training loss 0.922325 Accuracy: 0.590238\n",
      ">> Epoch 64 finished \tANN training loss 0.938167 Accuracy: 0.617102\n",
      ">> Epoch 65 finished \tANN training loss 0.878409 Accuracy: 0.615210\n",
      ">> Epoch 66 finished \tANN training loss 1.038922 Accuracy: 0.582293\n",
      ">> Epoch 67 finished \tANN training loss 0.873353 Accuracy: 0.631858\n",
      ">> Epoch 68 finished \tANN training loss 0.853390 Accuracy: 0.651154\n",
      ">> Epoch 69 finished \tANN training loss 0.869336 Accuracy: 0.627317\n",
      ">> Epoch 70 finished \tANN training loss 0.900774 Accuracy: 0.614075\n",
      ">> Epoch 71 finished \tANN training loss 0.865577 Accuracy: 0.631858\n",
      ">> Epoch 72 finished \tANN training loss 0.828627 Accuracy: 0.676504\n",
      ">> Epoch 73 finished \tANN training loss 0.843802 Accuracy: 0.651154\n",
      ">> Epoch 74 finished \tANN training loss 0.853713 Accuracy: 0.634885\n",
      ">> Epoch 75 finished \tANN training loss 0.820750 Accuracy: 0.659856\n",
      ">> Epoch 76 finished \tANN training loss 0.782196 Accuracy: 0.694287\n",
      ">> Epoch 77 finished \tANN training loss 0.977782 Accuracy: 0.572077\n",
      ">> Epoch 78 finished \tANN training loss 0.962779 Accuracy: 0.575482\n",
      ">> Epoch 79 finished \tANN training loss 0.792184 Accuracy: 0.679152\n",
      ">> Epoch 80 finished \tANN training loss 0.909220 Accuracy: 0.595535\n",
      ">> Epoch 81 finished \tANN training loss 0.751729 Accuracy: 0.676882\n",
      ">> Epoch 82 finished \tANN training loss 0.789504 Accuracy: 0.677639\n",
      ">> Epoch 83 finished \tANN training loss 0.816590 Accuracy: 0.655694\n",
      ">> Epoch 84 finished \tANN training loss 0.805004 Accuracy: 0.652667\n",
      ">> Epoch 85 finished \tANN training loss 0.795026 Accuracy: 0.671207\n",
      ">> Epoch 86 finished \tANN training loss 0.808648 Accuracy: 0.646614\n",
      ">> Epoch 87 finished \tANN training loss 0.744005 Accuracy: 0.689747\n",
      ">> Epoch 88 finished \tANN training loss 0.833677 Accuracy: 0.651532\n",
      ">> Epoch 89 finished \tANN training loss 0.745232 Accuracy: 0.686341\n",
      ">> Epoch 90 finished \tANN training loss 0.820842 Accuracy: 0.636398\n",
      ">> Epoch 91 finished \tANN training loss 0.873284 Accuracy: 0.627317\n",
      ">> Epoch 92 finished \tANN training loss 0.728041 Accuracy: 0.714718\n",
      ">> Epoch 93 finished \tANN training loss 0.795918 Accuracy: 0.681423\n",
      ">> Epoch 94 finished \tANN training loss 0.742357 Accuracy: 0.725312\n",
      ">> Epoch 95 finished \tANN training loss 0.757822 Accuracy: 0.698070\n",
      ">> Epoch 96 finished \tANN training loss 0.718003 Accuracy: 0.703746\n",
      ">> Epoch 97 finished \tANN training loss 0.748177 Accuracy: 0.670829\n",
      ">> Epoch 98 finished \tANN training loss 0.703144 Accuracy: 0.703746\n",
      ">> Epoch 99 finished \tANN training loss 0.772628 Accuracy: 0.652667\n",
      ">> Epoch 100 finished \tANN training loss 0.747452 Accuracy: 0.690882\n",
      ">> Epoch 101 finished \tANN training loss 0.704556 Accuracy: 0.708286\n",
      ">> Epoch 102 finished \tANN training loss 0.690423 Accuracy: 0.729474\n",
      ">> Epoch 103 finished \tANN training loss 0.759936 Accuracy: 0.685206\n",
      ">> Epoch 104 finished \tANN training loss 0.800102 Accuracy: 0.660991\n",
      ">> Epoch 105 finished \tANN training loss 0.716662 Accuracy: 0.695800\n",
      ">> Epoch 106 finished \tANN training loss 0.705960 Accuracy: 0.715475\n",
      ">> Epoch 107 finished \tANN training loss 0.708971 Accuracy: 0.710556\n",
      ">> Epoch 108 finished \tANN training loss 0.673450 Accuracy: 0.723799\n",
      ">> Epoch 109 finished \tANN training loss 0.654602 Accuracy: 0.747635\n",
      ">> Epoch 110 finished \tANN training loss 0.715615 Accuracy: 0.715096\n",
      ">> Epoch 111 finished \tANN training loss 0.693249 Accuracy: 0.717745\n",
      ">> Epoch 112 finished \tANN training loss 0.732780 Accuracy: 0.698827\n",
      ">> Epoch 113 finished \tANN training loss 0.727350 Accuracy: 0.693152\n",
      ">> Epoch 114 finished \tANN training loss 0.650882 Accuracy: 0.738555\n",
      ">> Epoch 115 finished \tANN training loss 0.695352 Accuracy: 0.736285\n",
      ">> Epoch 116 finished \tANN training loss 0.748451 Accuracy: 0.664018\n",
      ">> Epoch 117 finished \tANN training loss 0.644817 Accuracy: 0.735149\n",
      ">> Epoch 118 finished \tANN training loss 0.675347 Accuracy: 0.730988\n",
      ">> Epoch 119 finished \tANN training loss 0.699556 Accuracy: 0.733636\n",
      ">> Epoch 120 finished \tANN training loss 0.678263 Accuracy: 0.728339\n",
      ">> Epoch 121 finished \tANN training loss 0.620105 Accuracy: 0.756337\n",
      ">> Epoch 122 finished \tANN training loss 0.638629 Accuracy: 0.765796\n",
      ">> Epoch 123 finished \tANN training loss 0.641747 Accuracy: 0.736285\n",
      ">> Epoch 124 finished \tANN training loss 0.659234 Accuracy: 0.729852\n",
      ">> Epoch 125 finished \tANN training loss 0.717439 Accuracy: 0.704124\n",
      ">> Epoch 126 finished \tANN training loss 0.621980 Accuracy: 0.746500\n",
      ">> Epoch 127 finished \tANN training loss 0.661101 Accuracy: 0.734393\n",
      ">> Epoch 128 finished \tANN training loss 0.702204 Accuracy: 0.715853\n",
      ">> Epoch 129 finished \tANN training loss 0.640417 Accuracy: 0.736663\n",
      ">> Epoch 130 finished \tANN training loss 0.628001 Accuracy: 0.757473\n",
      ">> Epoch 131 finished \tANN training loss 0.604931 Accuracy: 0.763905\n",
      ">> Epoch 132 finished \tANN training loss 0.641995 Accuracy: 0.714718\n",
      ">> Epoch 133 finished \tANN training loss 0.599045 Accuracy: 0.753311\n",
      ">> Epoch 134 finished \tANN training loss 0.625317 Accuracy: 0.762770\n",
      ">> Epoch 135 finished \tANN training loss 0.620995 Accuracy: 0.760878\n",
      ">> Epoch 136 finished \tANN training loss 0.598098 Accuracy: 0.772607\n",
      ">> Epoch 137 finished \tANN training loss 0.631365 Accuracy: 0.747635\n",
      ">> Epoch 138 finished \tANN training loss 0.751440 Accuracy: 0.697692\n",
      ">> Epoch 139 finished \tANN training loss 0.607190 Accuracy: 0.763148\n",
      ">> Epoch 140 finished \tANN training loss 0.663740 Accuracy: 0.728717\n",
      ">> Epoch 141 finished \tANN training loss 0.558249 Accuracy: 0.787363\n",
      ">> Epoch 142 finished \tANN training loss 0.670591 Accuracy: 0.726069\n",
      ">> Epoch 143 finished \tANN training loss 0.676133 Accuracy: 0.723042\n",
      ">> Epoch 144 finished \tANN training loss 0.587418 Accuracy: 0.765796\n",
      ">> Epoch 145 finished \tANN training loss 0.594031 Accuracy: 0.773364\n",
      ">> Epoch 146 finished \tANN training loss 0.622679 Accuracy: 0.745743\n",
      ">> Epoch 147 finished \tANN training loss 0.588690 Accuracy: 0.769958\n",
      ">> Epoch 148 finished \tANN training loss 0.586014 Accuracy: 0.776769\n",
      ">> Epoch 149 finished \tANN training loss 0.603434 Accuracy: 0.756337\n",
      ">> Epoch 150 finished \tANN training loss 0.559519 Accuracy: 0.784336\n",
      ">> Epoch 151 finished \tANN training loss 0.707720 Accuracy: 0.710935\n",
      ">> Epoch 152 finished \tANN training loss 0.570853 Accuracy: 0.775255\n",
      ">> Epoch 153 finished \tANN training loss 0.699936 Accuracy: 0.706773\n",
      ">> Epoch 154 finished \tANN training loss 0.595302 Accuracy: 0.767688\n",
      ">> Epoch 155 finished \tANN training loss 0.598669 Accuracy: 0.763148\n",
      ">> Epoch 156 finished \tANN training loss 0.604955 Accuracy: 0.754067\n",
      ">> Epoch 157 finished \tANN training loss 0.607278 Accuracy: 0.768445\n",
      ">> Epoch 158 finished \tANN training loss 0.709583 Accuracy: 0.708664\n",
      ">> Epoch 159 finished \tANN training loss 0.630850 Accuracy: 0.740068\n",
      ">> Epoch 160 finished \tANN training loss 0.552269 Accuracy: 0.788876\n",
      ">> Epoch 161 finished \tANN training loss 0.522881 Accuracy: 0.800227\n",
      ">> Epoch 162 finished \tANN training loss 0.594180 Accuracy: 0.749149\n",
      ">> Epoch 163 finished \tANN training loss 0.533131 Accuracy: 0.801740\n",
      ">> Epoch 164 finished \tANN training loss 0.579393 Accuracy: 0.771472\n",
      ">> Epoch 165 finished \tANN training loss 0.602840 Accuracy: 0.750662\n",
      ">> Epoch 166 finished \tANN training loss 0.523238 Accuracy: 0.799092\n",
      ">> Epoch 167 finished \tANN training loss 0.626030 Accuracy: 0.743852\n",
      ">> Epoch 168 finished \tANN training loss 0.591127 Accuracy: 0.755959\n",
      ">> Epoch 169 finished \tANN training loss 0.524129 Accuracy: 0.796065\n",
      ">> Epoch 170 finished \tANN training loss 0.639767 Accuracy: 0.754067\n",
      ">> Epoch 171 finished \tANN training loss 0.583681 Accuracy: 0.766932\n",
      ">> Epoch 172 finished \tANN training loss 0.596002 Accuracy: 0.775634\n",
      ">> Epoch 173 finished \tANN training loss 0.534668 Accuracy: 0.791525\n",
      ">> Epoch 174 finished \tANN training loss 0.549841 Accuracy: 0.783579\n",
      ">> Epoch 175 finished \tANN training loss 0.505068 Accuracy: 0.799849\n",
      ">> Epoch 176 finished \tANN training loss 0.538107 Accuracy: 0.789633\n",
      ">> Epoch 177 finished \tANN training loss 0.518441 Accuracy: 0.791903\n",
      ">> Epoch 178 finished \tANN training loss 0.546819 Accuracy: 0.769580\n",
      ">> Epoch 179 finished \tANN training loss 0.564642 Accuracy: 0.760499\n",
      ">> Epoch 180 finished \tANN training loss 0.566458 Accuracy: 0.789633\n",
      ">> Epoch 181 finished \tANN training loss 0.562076 Accuracy: 0.773364\n",
      ">> Epoch 182 finished \tANN training loss 0.616215 Accuracy: 0.750284\n",
      ">> Epoch 183 finished \tANN training loss 0.559327 Accuracy: 0.774120\n",
      ">> Epoch 184 finished \tANN training loss 0.510189 Accuracy: 0.802497\n",
      ">> Epoch 185 finished \tANN training loss 0.510831 Accuracy: 0.793795\n",
      ">> Epoch 186 finished \tANN training loss 0.518520 Accuracy: 0.805902\n",
      ">> Epoch 187 finished \tANN training loss 0.628960 Accuracy: 0.750662\n",
      ">> Epoch 188 finished \tANN training loss 0.554039 Accuracy: 0.794552\n",
      ">> Epoch 189 finished \tANN training loss 0.492770 Accuracy: 0.817631\n",
      ">> Epoch 190 finished \tANN training loss 0.481897 Accuracy: 0.818388\n",
      ">> Epoch 191 finished \tANN training loss 0.494432 Accuracy: 0.808173\n",
      ">> Epoch 192 finished \tANN training loss 0.523530 Accuracy: 0.798714\n",
      ">> Epoch 193 finished \tANN training loss 0.538072 Accuracy: 0.789255\n",
      ">> Epoch 194 finished \tANN training loss 0.519961 Accuracy: 0.801362\n",
      ">> Epoch 195 finished \tANN training loss 0.472972 Accuracy: 0.821037\n",
      ">> Epoch 196 finished \tANN training loss 0.523317 Accuracy: 0.786984\n",
      ">> Epoch 197 finished \tANN training loss 0.484787 Accuracy: 0.816118\n",
      ">> Epoch 198 finished \tANN training loss 0.460599 Accuracy: 0.831252\n",
      ">> Epoch 199 finished \tANN training loss 0.502108 Accuracy: 0.821793\n",
      ">> Epoch 200 finished \tANN training loss 0.530828 Accuracy: 0.786228\n",
      ">> Epoch 201 finished \tANN training loss 0.504903 Accuracy: 0.800605\n",
      ">> Epoch 202 finished \tANN training loss 0.620513 Accuracy: 0.736663\n",
      ">> Epoch 203 finished \tANN training loss 0.468365 Accuracy: 0.818767\n",
      ">> Epoch 204 finished \tANN training loss 0.498553 Accuracy: 0.816875\n",
      ">> Epoch 205 finished \tANN training loss 0.461365 Accuracy: 0.818767\n",
      ">> Epoch 206 finished \tANN training loss 0.521040 Accuracy: 0.798335\n",
      ">> Epoch 207 finished \tANN training loss 0.473148 Accuracy: 0.812334\n",
      ">> Epoch 208 finished \tANN training loss 0.469251 Accuracy: 0.827469\n",
      ">> Epoch 209 finished \tANN training loss 0.457661 Accuracy: 0.819902\n",
      ">> Epoch 210 finished \tANN training loss 0.491922 Accuracy: 0.818010\n",
      ">> Epoch 211 finished \tANN training loss 0.519154 Accuracy: 0.807416\n",
      ">> Epoch 212 finished \tANN training loss 0.469298 Accuracy: 0.819145\n",
      ">> Epoch 213 finished \tANN training loss 0.489270 Accuracy: 0.795308\n",
      ">> Epoch 214 finished \tANN training loss 0.563993 Accuracy: 0.768823\n",
      ">> Epoch 215 finished \tANN training loss 0.509519 Accuracy: 0.808173\n",
      ">> Epoch 216 finished \tANN training loss 0.483660 Accuracy: 0.827469\n",
      ">> Epoch 217 finished \tANN training loss 0.513108 Accuracy: 0.794552\n",
      ">> Epoch 218 finished \tANN training loss 0.452732 Accuracy: 0.834279\n",
      ">> Epoch 219 finished \tANN training loss 0.477322 Accuracy: 0.811578\n",
      ">> Epoch 220 finished \tANN training loss 0.445001 Accuracy: 0.844117\n",
      ">> Epoch 221 finished \tANN training loss 0.532470 Accuracy: 0.792660\n",
      ">> Epoch 222 finished \tANN training loss 0.460672 Accuracy: 0.818767\n",
      ">> Epoch 223 finished \tANN training loss 0.437212 Accuracy: 0.841846\n",
      ">> Epoch 224 finished \tANN training loss 0.438832 Accuracy: 0.823685\n",
      ">> Epoch 225 finished \tANN training loss 0.509528 Accuracy: 0.797579\n",
      ">> Epoch 226 finished \tANN training loss 0.508757 Accuracy: 0.806659\n",
      ">> Epoch 227 finished \tANN training loss 0.440276 Accuracy: 0.836549\n",
      ">> Epoch 228 finished \tANN training loss 0.461118 Accuracy: 0.838820\n",
      ">> Epoch 229 finished \tANN training loss 0.432044 Accuracy: 0.836549\n",
      ">> Epoch 230 finished \tANN training loss 0.448828 Accuracy: 0.824820\n",
      ">> Epoch 231 finished \tANN training loss 0.525006 Accuracy: 0.798335\n",
      ">> Epoch 232 finished \tANN training loss 0.469593 Accuracy: 0.818388\n",
      ">> Epoch 233 finished \tANN training loss 0.440883 Accuracy: 0.838820\n",
      ">> Epoch 234 finished \tANN training loss 0.443032 Accuracy: 0.833144\n",
      ">> Epoch 235 finished \tANN training loss 0.461046 Accuracy: 0.828226\n",
      ">> Epoch 236 finished \tANN training loss 0.441888 Accuracy: 0.828982\n",
      ">> Epoch 237 finished \tANN training loss 0.499141 Accuracy: 0.788120\n",
      ">> Epoch 238 finished \tANN training loss 0.448426 Accuracy: 0.821793\n",
      ">> Epoch 239 finished \tANN training loss 0.525451 Accuracy: 0.805524\n",
      ">> Epoch 240 finished \tANN training loss 0.492084 Accuracy: 0.810443\n",
      ">> Epoch 241 finished \tANN training loss 0.457246 Accuracy: 0.828604\n",
      ">> Epoch 242 finished \tANN training loss 0.413121 Accuracy: 0.841090\n",
      ">> Epoch 243 finished \tANN training loss 0.462174 Accuracy: 0.821037\n",
      ">> Epoch 244 finished \tANN training loss 0.421244 Accuracy: 0.856224\n",
      ">> Epoch 245 finished \tANN training loss 0.455128 Accuracy: 0.825577\n",
      ">> Epoch 246 finished \tANN training loss 0.435026 Accuracy: 0.836928\n",
      ">> Epoch 247 finished \tANN training loss 0.551061 Accuracy: 0.780931\n",
      ">> Epoch 248 finished \tANN training loss 0.447679 Accuracy: 0.830874\n",
      ">> Epoch 249 finished \tANN training loss 0.433766 Accuracy: 0.823307\n",
      ">> Epoch 250 finished \tANN training loss 0.427946 Accuracy: 0.843360\n",
      ">> Epoch 251 finished \tANN training loss 0.435441 Accuracy: 0.813091\n",
      ">> Epoch 252 finished \tANN training loss 0.412474 Accuracy: 0.852440\n",
      ">> Epoch 253 finished \tANN training loss 0.390976 Accuracy: 0.858116\n",
      ">> Epoch 254 finished \tANN training loss 0.450313 Accuracy: 0.841846\n",
      ">> Epoch 255 finished \tANN training loss 0.455926 Accuracy: 0.836171\n",
      ">> Epoch 256 finished \tANN training loss 0.450957 Accuracy: 0.830496\n",
      ">> Epoch 257 finished \tANN training loss 0.413762 Accuracy: 0.847143\n",
      ">> Epoch 258 finished \tANN training loss 0.430568 Accuracy: 0.835036\n",
      ">> Epoch 259 finished \tANN training loss 0.432831 Accuracy: 0.836928\n",
      ">> Epoch 260 finished \tANN training loss 0.393070 Accuracy: 0.848278\n",
      ">> Epoch 261 finished \tANN training loss 0.405484 Accuracy: 0.845252\n",
      ">> Epoch 262 finished \tANN training loss 0.412829 Accuracy: 0.842603\n",
      ">> Epoch 263 finished \tANN training loss 0.412114 Accuracy: 0.833901\n",
      ">> Epoch 264 finished \tANN training loss 0.410233 Accuracy: 0.854332\n",
      ">> Epoch 265 finished \tANN training loss 0.461221 Accuracy: 0.823685\n",
      ">> Epoch 266 finished \tANN training loss 0.404627 Accuracy: 0.855089\n",
      ">> Epoch 267 finished \tANN training loss 0.480019 Accuracy: 0.792281\n",
      ">> Epoch 268 finished \tANN training loss 0.442122 Accuracy: 0.815361\n",
      ">> Epoch 269 finished \tANN training loss 0.389661 Accuracy: 0.850927\n",
      ">> Epoch 270 finished \tANN training loss 0.427372 Accuracy: 0.827090\n",
      ">> Epoch 271 finished \tANN training loss 0.434949 Accuracy: 0.838820\n",
      ">> Epoch 272 finished \tANN training loss 0.460287 Accuracy: 0.823685\n",
      ">> Epoch 273 finished \tANN training loss 0.379740 Accuracy: 0.855467\n",
      ">> Epoch 274 finished \tANN training loss 0.431381 Accuracy: 0.831631\n",
      ">> Epoch 275 finished \tANN training loss 0.385505 Accuracy: 0.859629\n",
      ">> Epoch 276 finished \tANN training loss 0.406108 Accuracy: 0.848278\n",
      ">> Epoch 277 finished \tANN training loss 0.515032 Accuracy: 0.785849\n",
      ">> Epoch 278 finished \tANN training loss 0.427612 Accuracy: 0.839576\n",
      ">> Epoch 279 finished \tANN training loss 0.396016 Accuracy: 0.851684\n",
      ">> Epoch 280 finished \tANN training loss 0.388392 Accuracy: 0.856981\n",
      ">> Epoch 281 finished \tANN training loss 0.471906 Accuracy: 0.818388\n",
      ">> Epoch 282 finished \tANN training loss 0.396489 Accuracy: 0.853954\n",
      ">> Epoch 283 finished \tANN training loss 0.431115 Accuracy: 0.835793\n",
      ">> Epoch 284 finished \tANN training loss 0.382762 Accuracy: 0.867953\n",
      ">> Epoch 285 finished \tANN training loss 0.375708 Accuracy: 0.865305\n",
      ">> Epoch 286 finished \tANN training loss 0.462694 Accuracy: 0.816875\n",
      ">> Epoch 287 finished \tANN training loss 0.402721 Accuracy: 0.842981\n",
      ">> Epoch 288 finished \tANN training loss 0.450639 Accuracy: 0.821037\n",
      ">> Epoch 289 finished \tANN training loss 0.398593 Accuracy: 0.852062\n",
      ">> Epoch 290 finished \tANN training loss 0.412020 Accuracy: 0.849792\n",
      ">> Epoch 291 finished \tANN training loss 0.384701 Accuracy: 0.852062\n",
      ">> Epoch 292 finished \tANN training loss 0.464755 Accuracy: 0.831631\n",
      ">> Epoch 293 finished \tANN training loss 0.394625 Accuracy: 0.859629\n",
      ">> Epoch 294 finished \tANN training loss 0.403971 Accuracy: 0.856602\n",
      ">> Epoch 295 finished \tANN training loss 0.356659 Accuracy: 0.879682\n",
      ">> Epoch 296 finished \tANN training loss 0.377003 Accuracy: 0.867575\n",
      ">> Epoch 297 finished \tANN training loss 0.566745 Accuracy: 0.751040\n",
      ">> Epoch 298 finished \tANN training loss 0.377134 Accuracy: 0.861143\n",
      ">> Epoch 299 finished \tANN training loss 0.377539 Accuracy: 0.855089\n",
      ">> Epoch 300 finished \tANN training loss 0.355110 Accuracy: 0.868331\n",
      ">> Epoch 301 finished \tANN training loss 0.403476 Accuracy: 0.856602\n",
      ">> Epoch 302 finished \tANN training loss 0.436851 Accuracy: 0.832387\n",
      ">> Epoch 303 finished \tANN training loss 0.394672 Accuracy: 0.842981\n",
      ">> Epoch 304 finished \tANN training loss 0.416140 Accuracy: 0.835793\n",
      ">> Epoch 305 finished \tANN training loss 0.396063 Accuracy: 0.856981\n",
      ">> Epoch 306 finished \tANN training loss 0.379310 Accuracy: 0.864926\n",
      ">> Epoch 307 finished \tANN training loss 0.402176 Accuracy: 0.847522\n",
      ">> Epoch 308 finished \tANN training loss 0.373400 Accuracy: 0.868331\n",
      ">> Epoch 309 finished \tANN training loss 0.373955 Accuracy: 0.855467\n",
      ">> Epoch 310 finished \tANN training loss 0.393268 Accuracy: 0.848278\n",
      ">> Epoch 311 finished \tANN training loss 0.362805 Accuracy: 0.861521\n",
      ">> Epoch 312 finished \tANN training loss 0.442571 Accuracy: 0.835414\n",
      ">> Epoch 313 finished \tANN training loss 0.491420 Accuracy: 0.817253\n",
      ">> Epoch 314 finished \tANN training loss 0.436133 Accuracy: 0.832387\n",
      ">> Epoch 315 finished \tANN training loss 0.378200 Accuracy: 0.866061\n",
      ">> Epoch 316 finished \tANN training loss 0.373514 Accuracy: 0.861143\n",
      ">> Epoch 317 finished \tANN training loss 0.390982 Accuracy: 0.854332\n",
      ">> Epoch 318 finished \tANN training loss 0.418828 Accuracy: 0.834658\n",
      ">> Epoch 319 finished \tANN training loss 0.404253 Accuracy: 0.847900\n",
      ">> Epoch 320 finished \tANN training loss 0.434579 Accuracy: 0.848657\n",
      ">> Epoch 321 finished \tANN training loss 0.377795 Accuracy: 0.856981\n",
      ">> Epoch 322 finished \tANN training loss 0.345266 Accuracy: 0.873628\n",
      ">> Epoch 323 finished \tANN training loss 0.357167 Accuracy: 0.869088\n",
      ">> Epoch 324 finished \tANN training loss 0.355563 Accuracy: 0.869467\n",
      ">> Epoch 325 finished \tANN training loss 0.372946 Accuracy: 0.856602\n",
      ">> Epoch 326 finished \tANN training loss 0.338790 Accuracy: 0.885736\n",
      ">> Epoch 327 finished \tANN training loss 0.377735 Accuracy: 0.859251\n",
      ">> Epoch 328 finished \tANN training loss 0.350505 Accuracy: 0.880439\n",
      ">> Epoch 329 finished \tANN training loss 0.350360 Accuracy: 0.866061\n",
      ">> Epoch 330 finished \tANN training loss 0.352751 Accuracy: 0.870980\n",
      ">> Epoch 331 finished \tANN training loss 0.395352 Accuracy: 0.848657\n",
      ">> Epoch 332 finished \tANN training loss 0.375923 Accuracy: 0.875899\n",
      ">> Epoch 333 finished \tANN training loss 0.358825 Accuracy: 0.871737\n",
      ">> Epoch 334 finished \tANN training loss 0.337922 Accuracy: 0.888763\n",
      ">> Epoch 335 finished \tANN training loss 0.372093 Accuracy: 0.862656\n",
      ">> Epoch 336 finished \tANN training loss 0.381142 Accuracy: 0.859629\n",
      ">> Epoch 337 finished \tANN training loss 0.407108 Accuracy: 0.855846\n",
      ">> Epoch 338 finished \tANN training loss 0.358063 Accuracy: 0.876277\n",
      ">> Epoch 339 finished \tANN training loss 0.358488 Accuracy: 0.868331\n",
      ">> Epoch 340 finished \tANN training loss 0.366854 Accuracy: 0.874007\n",
      ">> Epoch 341 finished \tANN training loss 0.391373 Accuracy: 0.852062\n",
      ">> Epoch 342 finished \tANN training loss 0.419203 Accuracy: 0.827469\n",
      ">> Epoch 343 finished \tANN training loss 0.375644 Accuracy: 0.855089\n",
      ">> Epoch 344 finished \tANN training loss 0.344781 Accuracy: 0.871737\n",
      ">> Epoch 345 finished \tANN training loss 0.356150 Accuracy: 0.865305\n",
      ">> Epoch 346 finished \tANN training loss 0.443289 Accuracy: 0.823685\n",
      ">> Epoch 347 finished \tANN training loss 0.370508 Accuracy: 0.870223\n",
      ">> Epoch 348 finished \tANN training loss 0.345400 Accuracy: 0.884222\n",
      ">> Epoch 349 finished \tANN training loss 0.362170 Accuracy: 0.864926\n",
      ">> Epoch 350 finished \tANN training loss 0.359223 Accuracy: 0.861521\n",
      ">> Epoch 351 finished \tANN training loss 0.328530 Accuracy: 0.887628\n",
      ">> Epoch 352 finished \tANN training loss 0.342319 Accuracy: 0.881952\n",
      ">> Epoch 353 finished \tANN training loss 0.335161 Accuracy: 0.883466\n",
      ">> Epoch 354 finished \tANN training loss 0.353907 Accuracy: 0.870602\n",
      ">> Epoch 355 finished \tANN training loss 0.348323 Accuracy: 0.874007\n",
      ">> Epoch 356 finished \tANN training loss 0.348928 Accuracy: 0.867953\n",
      ">> Epoch 357 finished \tANN training loss 0.351762 Accuracy: 0.875142\n",
      ">> Epoch 358 finished \tANN training loss 0.333697 Accuracy: 0.882331\n",
      ">> Epoch 359 finished \tANN training loss 0.336020 Accuracy: 0.872493\n",
      ">> Epoch 360 finished \tANN training loss 0.412375 Accuracy: 0.847143\n",
      ">> Epoch 361 finished \tANN training loss 0.334397 Accuracy: 0.885736\n",
      ">> Epoch 362 finished \tANN training loss 0.324277 Accuracy: 0.884222\n",
      ">> Epoch 363 finished \tANN training loss 0.349502 Accuracy: 0.880061\n",
      ">> Epoch 364 finished \tANN training loss 0.396124 Accuracy: 0.846008\n",
      ">> Epoch 365 finished \tANN training loss 0.324510 Accuracy: 0.879682\n",
      ">> Epoch 366 finished \tANN training loss 0.388897 Accuracy: 0.849035\n",
      ">> Epoch 367 finished \tANN training loss 0.361455 Accuracy: 0.871737\n",
      ">> Epoch 368 finished \tANN training loss 0.325130 Accuracy: 0.882709\n",
      ">> Epoch 369 finished \tANN training loss 0.414229 Accuracy: 0.835414\n",
      ">> Epoch 370 finished \tANN training loss 0.329278 Accuracy: 0.882709\n",
      ">> Epoch 371 finished \tANN training loss 0.332223 Accuracy: 0.870602\n",
      ">> Epoch 372 finished \tANN training loss 0.318601 Accuracy: 0.894438\n",
      ">> Epoch 373 finished \tANN training loss 0.342786 Accuracy: 0.866818\n",
      ">> Epoch 374 finished \tANN training loss 0.361890 Accuracy: 0.878547\n",
      ">> Epoch 375 finished \tANN training loss 0.399449 Accuracy: 0.849792\n",
      ">> Epoch 376 finished \tANN training loss 0.303436 Accuracy: 0.897087\n",
      ">> Epoch 377 finished \tANN training loss 0.401205 Accuracy: 0.846765\n",
      ">> Epoch 378 finished \tANN training loss 0.386692 Accuracy: 0.855089\n",
      ">> Epoch 379 finished \tANN training loss 0.407965 Accuracy: 0.839955\n",
      ">> Epoch 380 finished \tANN training loss 0.376526 Accuracy: 0.852819\n",
      ">> Epoch 381 finished \tANN training loss 0.315012 Accuracy: 0.878169\n",
      ">> Epoch 382 finished \tANN training loss 0.344039 Accuracy: 0.889141\n",
      ">> Epoch 383 finished \tANN training loss 0.373018 Accuracy: 0.844495\n",
      ">> Epoch 384 finished \tANN training loss 0.343301 Accuracy: 0.873250\n",
      ">> Epoch 385 finished \tANN training loss 0.317262 Accuracy: 0.884979\n",
      ">> Epoch 386 finished \tANN training loss 0.350587 Accuracy: 0.875520\n",
      ">> Epoch 387 finished \tANN training loss 0.363435 Accuracy: 0.855846\n",
      ">> Epoch 388 finished \tANN training loss 0.326473 Accuracy: 0.872493\n",
      ">> Epoch 389 finished \tANN training loss 0.425136 Accuracy: 0.828982\n",
      ">> Epoch 390 finished \tANN training loss 0.361146 Accuracy: 0.864170\n",
      ">> Epoch 391 finished \tANN training loss 0.308883 Accuracy: 0.897843\n",
      ">> Epoch 392 finished \tANN training loss 0.321167 Accuracy: 0.892546\n",
      ">> Epoch 393 finished \tANN training loss 0.358477 Accuracy: 0.869088\n",
      ">> Epoch 394 finished \tANN training loss 0.327906 Accuracy: 0.874007\n",
      ">> Epoch 395 finished \tANN training loss 0.324923 Accuracy: 0.881952\n",
      ">> Epoch 396 finished \tANN training loss 0.328978 Accuracy: 0.872872\n",
      ">> Epoch 397 finished \tANN training loss 0.318750 Accuracy: 0.896708\n",
      ">> Epoch 398 finished \tANN training loss 0.320589 Accuracy: 0.877412\n",
      ">> Epoch 399 finished \tANN training loss 0.336804 Accuracy: 0.884601\n",
      ">> Epoch 400 finished \tANN training loss 0.352345 Accuracy: 0.862278\n",
      ">> Epoch 401 finished \tANN training loss 0.311809 Accuracy: 0.885358\n",
      ">> Epoch 402 finished \tANN training loss 0.290247 Accuracy: 0.889519\n",
      ">> Epoch 403 finished \tANN training loss 0.337329 Accuracy: 0.870602\n",
      ">> Epoch 404 finished \tANN training loss 0.356031 Accuracy: 0.866440\n",
      ">> Epoch 405 finished \tANN training loss 0.297053 Accuracy: 0.904275\n",
      ">> Epoch 406 finished \tANN training loss 0.314639 Accuracy: 0.888384\n",
      ">> Epoch 407 finished \tANN training loss 0.308096 Accuracy: 0.891411\n",
      ">> Epoch 408 finished \tANN training loss 0.339655 Accuracy: 0.866061\n",
      ">> Epoch 409 finished \tANN training loss 0.438034 Accuracy: 0.828226\n",
      ">> Epoch 410 finished \tANN training loss 0.352801 Accuracy: 0.868710\n",
      ">> Epoch 411 finished \tANN training loss 0.385554 Accuracy: 0.849414\n",
      ">> Epoch 412 finished \tANN training loss 0.351023 Accuracy: 0.865683\n",
      ">> Epoch 413 finished \tANN training loss 0.330043 Accuracy: 0.885358\n",
      ">> Epoch 414 finished \tANN training loss 0.342314 Accuracy: 0.876655\n",
      ">> Epoch 415 finished \tANN training loss 0.330668 Accuracy: 0.872493\n",
      ">> Epoch 416 finished \tANN training loss 0.329166 Accuracy: 0.874007\n",
      ">> Epoch 417 finished \tANN training loss 0.292139 Accuracy: 0.896708\n",
      ">> Epoch 418 finished \tANN training loss 0.353407 Accuracy: 0.861899\n",
      ">> Epoch 419 finished \tANN training loss 0.341967 Accuracy: 0.875899\n",
      ">> Epoch 420 finished \tANN training loss 0.299628 Accuracy: 0.880439\n",
      ">> Epoch 421 finished \tANN training loss 0.323941 Accuracy: 0.885358\n",
      ">> Epoch 422 finished \tANN training loss 0.328982 Accuracy: 0.880439\n",
      ">> Epoch 423 finished \tANN training loss 0.289469 Accuracy: 0.891033\n",
      ">> Epoch 424 finished \tANN training loss 0.313114 Accuracy: 0.886114\n",
      ">> Epoch 425 finished \tANN training loss 0.335220 Accuracy: 0.878925\n",
      ">> Epoch 426 finished \tANN training loss 0.334925 Accuracy: 0.887249\n",
      ">> Epoch 427 finished \tANN training loss 0.323201 Accuracy: 0.885736\n",
      ">> Epoch 428 finished \tANN training loss 0.360992 Accuracy: 0.866061\n",
      ">> Epoch 429 finished \tANN training loss 0.348388 Accuracy: 0.872115\n",
      ">> Epoch 430 finished \tANN training loss 0.325214 Accuracy: 0.877412\n",
      ">> Epoch 431 finished \tANN training loss 0.364605 Accuracy: 0.857737\n",
      ">> Epoch 432 finished \tANN training loss 0.307927 Accuracy: 0.888384\n",
      ">> Epoch 433 finished \tANN training loss 0.292110 Accuracy: 0.894060\n",
      ">> Epoch 434 finished \tANN training loss 0.319813 Accuracy: 0.893681\n",
      ">> Epoch 435 finished \tANN training loss 0.324953 Accuracy: 0.881196\n",
      ">> Epoch 436 finished \tANN training loss 0.329375 Accuracy: 0.881574\n",
      ">> Epoch 437 finished \tANN training loss 0.283667 Accuracy: 0.909194\n",
      ">> Epoch 438 finished \tANN training loss 0.314620 Accuracy: 0.891411\n",
      ">> Epoch 439 finished \tANN training loss 0.305037 Accuracy: 0.886871\n",
      ">> Epoch 440 finished \tANN training loss 0.302430 Accuracy: 0.892546\n",
      ">> Epoch 441 finished \tANN training loss 0.308287 Accuracy: 0.894060\n",
      ">> Epoch 442 finished \tANN training loss 0.297396 Accuracy: 0.900492\n",
      ">> Epoch 443 finished \tANN training loss 0.290273 Accuracy: 0.893303\n",
      ">> Epoch 444 finished \tANN training loss 0.293717 Accuracy: 0.895195\n",
      ">> Epoch 445 finished \tANN training loss 0.365258 Accuracy: 0.850549\n",
      ">> Epoch 446 finished \tANN training loss 0.301759 Accuracy: 0.882331\n",
      ">> Epoch 447 finished \tANN training loss 0.293299 Accuracy: 0.899735\n",
      ">> Epoch 448 finished \tANN training loss 0.382964 Accuracy: 0.847143\n",
      ">> Epoch 449 finished \tANN training loss 0.344708 Accuracy: 0.864926\n",
      ">> Epoch 450 finished \tANN training loss 0.425480 Accuracy: 0.823307\n",
      ">> Epoch 451 finished \tANN training loss 0.320377 Accuracy: 0.880061\n",
      ">> Epoch 452 finished \tANN training loss 0.336007 Accuracy: 0.883087\n",
      ">> Epoch 453 finished \tANN training loss 0.355148 Accuracy: 0.870980\n",
      ">> Epoch 454 finished \tANN training loss 0.368653 Accuracy: 0.865305\n",
      ">> Epoch 455 finished \tANN training loss 0.324165 Accuracy: 0.880439\n",
      ">> Epoch 456 finished \tANN training loss 0.344763 Accuracy: 0.864926\n",
      ">> Epoch 457 finished \tANN training loss 0.321997 Accuracy: 0.883466\n",
      ">> Epoch 458 finished \tANN training loss 0.306215 Accuracy: 0.883466\n",
      ">> Epoch 459 finished \tANN training loss 0.301092 Accuracy: 0.891790\n",
      ">> Epoch 460 finished \tANN training loss 0.317691 Accuracy: 0.888384\n",
      ">> Epoch 461 finished \tANN training loss 0.297298 Accuracy: 0.893303\n",
      ">> Epoch 462 finished \tANN training loss 0.311159 Accuracy: 0.877790\n",
      ">> Epoch 463 finished \tANN training loss 0.292714 Accuracy: 0.902762\n",
      ">> Epoch 464 finished \tANN training loss 0.289460 Accuracy: 0.906167\n",
      ">> Epoch 465 finished \tANN training loss 0.314218 Accuracy: 0.891790\n",
      ">> Epoch 466 finished \tANN training loss 0.348637 Accuracy: 0.881196\n",
      ">> Epoch 467 finished \tANN training loss 0.273682 Accuracy: 0.909572\n",
      ">> Epoch 468 finished \tANN training loss 0.277163 Accuracy: 0.908816\n",
      ">> Epoch 469 finished \tANN training loss 0.282090 Accuracy: 0.899357\n",
      ">> Epoch 470 finished \tANN training loss 0.272702 Accuracy: 0.915248\n",
      ">> Epoch 471 finished \tANN training loss 0.306993 Accuracy: 0.897465\n",
      ">> Epoch 472 finished \tANN training loss 0.291717 Accuracy: 0.897465\n",
      ">> Epoch 473 finished \tANN training loss 0.314783 Accuracy: 0.883466\n",
      ">> Epoch 474 finished \tANN training loss 0.315158 Accuracy: 0.884601\n",
      ">> Epoch 475 finished \tANN training loss 0.323031 Accuracy: 0.886114\n",
      ">> Epoch 476 finished \tANN training loss 0.305329 Accuracy: 0.889519\n",
      ">> Epoch 477 finished \tANN training loss 0.293403 Accuracy: 0.906167\n",
      ">> Epoch 478 finished \tANN training loss 0.281181 Accuracy: 0.891033\n",
      ">> Epoch 479 finished \tANN training loss 0.308279 Accuracy: 0.894438\n",
      ">> Epoch 480 finished \tANN training loss 0.268607 Accuracy: 0.901249\n",
      ">> Epoch 481 finished \tANN training loss 0.315007 Accuracy: 0.888384\n",
      ">> Epoch 482 finished \tANN training loss 0.301235 Accuracy: 0.877412\n",
      ">> Epoch 483 finished \tANN training loss 0.302774 Accuracy: 0.898600\n",
      ">> Epoch 484 finished \tANN training loss 0.350282 Accuracy: 0.866818\n",
      ">> Epoch 485 finished \tANN training loss 0.309400 Accuracy: 0.894816\n",
      ">> Epoch 486 finished \tANN training loss 0.294345 Accuracy: 0.901627\n",
      ">> Epoch 487 finished \tANN training loss 0.276801 Accuracy: 0.898978\n",
      ">> Epoch 488 finished \tANN training loss 0.368147 Accuracy: 0.862278\n",
      ">> Epoch 489 finished \tANN training loss 0.289810 Accuracy: 0.894816\n",
      ">> Epoch 490 finished \tANN training loss 0.306994 Accuracy: 0.887628\n",
      ">> Epoch 491 finished \tANN training loss 0.287462 Accuracy: 0.889141\n",
      ">> Epoch 492 finished \tANN training loss 0.317514 Accuracy: 0.881574\n",
      ">> Epoch 493 finished \tANN training loss 0.320653 Accuracy: 0.896330\n",
      ">> Epoch 494 finished \tANN training loss 0.318619 Accuracy: 0.883466\n",
      ">> Epoch 495 finished \tANN training loss 0.270169 Accuracy: 0.906924\n",
      ">> Epoch 496 finished \tANN training loss 0.277655 Accuracy: 0.911843\n",
      ">> Epoch 497 finished \tANN training loss 0.292104 Accuracy: 0.906167\n",
      ">> Epoch 498 finished \tANN training loss 0.281065 Accuracy: 0.902762\n",
      ">> Epoch 499 finished \tANN training loss 0.338764 Accuracy: 0.876655\n",
      ">> Epoch 500 finished \tANN training loss 0.307642 Accuracy: 0.892925\n",
      ">> Epoch 501 finished \tANN training loss 0.301478 Accuracy: 0.900114\n",
      ">> Epoch 502 finished \tANN training loss 0.276635 Accuracy: 0.908059\n",
      ">> Epoch 503 finished \tANN training loss 0.288206 Accuracy: 0.894816\n",
      ">> Epoch 504 finished \tANN training loss 0.307463 Accuracy: 0.885736\n",
      ">> Epoch 505 finished \tANN training loss 0.320686 Accuracy: 0.885736\n",
      ">> Epoch 506 finished \tANN training loss 0.272634 Accuracy: 0.902005\n",
      ">> Epoch 507 finished \tANN training loss 0.295139 Accuracy: 0.895952\n",
      ">> Epoch 508 finished \tANN training loss 0.297288 Accuracy: 0.890276\n",
      ">> Epoch 509 finished \tANN training loss 0.284389 Accuracy: 0.898600\n",
      ">> Epoch 510 finished \tANN training loss 0.399115 Accuracy: 0.827090\n",
      ">> Epoch 511 finished \tANN training loss 0.335922 Accuracy: 0.866440\n",
      ">> Epoch 512 finished \tANN training loss 0.312369 Accuracy: 0.878925\n",
      ">> Epoch 513 finished \tANN training loss 0.301748 Accuracy: 0.887628\n",
      ">> Epoch 514 finished \tANN training loss 0.311936 Accuracy: 0.896708\n",
      ">> Epoch 515 finished \tANN training loss 0.329031 Accuracy: 0.878169\n",
      ">> Epoch 516 finished \tANN training loss 0.315820 Accuracy: 0.880061\n",
      ">> Epoch 517 finished \tANN training loss 0.548349 Accuracy: 0.875520\n",
      ">> Epoch 518 finished \tANN training loss 0.270496 Accuracy: 0.909951\n",
      ">> Epoch 519 finished \tANN training loss 0.284715 Accuracy: 0.900114\n",
      ">> Epoch 520 finished \tANN training loss 0.265324 Accuracy: 0.912221\n",
      ">> Epoch 521 finished \tANN training loss 0.271451 Accuracy: 0.902005\n",
      ">> Epoch 522 finished \tANN training loss 0.290886 Accuracy: 0.908059\n",
      ">> Epoch 523 finished \tANN training loss 0.307044 Accuracy: 0.882331\n",
      ">> Epoch 524 finished \tANN training loss 0.278748 Accuracy: 0.907681\n",
      ">> Epoch 525 finished \tANN training loss 0.333359 Accuracy: 0.880817\n",
      ">> Epoch 526 finished \tANN training loss 0.324424 Accuracy: 0.877412\n",
      ">> Epoch 527 finished \tANN training loss 0.294896 Accuracy: 0.904275\n",
      ">> Epoch 528 finished \tANN training loss 0.267713 Accuracy: 0.915248\n",
      ">> Epoch 529 finished \tANN training loss 0.300927 Accuracy: 0.894438\n",
      ">> Epoch 530 finished \tANN training loss 0.291464 Accuracy: 0.899357\n",
      ">> Epoch 531 finished \tANN training loss 0.281664 Accuracy: 0.900870\n",
      ">> Epoch 532 finished \tANN training loss 0.276400 Accuracy: 0.898222\n",
      ">> Epoch 533 finished \tANN training loss 0.302366 Accuracy: 0.897465\n",
      ">> Epoch 534 finished \tANN training loss 0.280922 Accuracy: 0.894816\n",
      ">> Epoch 535 finished \tANN training loss 0.330870 Accuracy: 0.870980\n",
      ">> Epoch 536 finished \tANN training loss 0.289811 Accuracy: 0.902005\n",
      ">> Epoch 537 finished \tANN training loss 0.259941 Accuracy: 0.908816\n",
      ">> Epoch 538 finished \tANN training loss 0.453294 Accuracy: 0.816875\n",
      ">> Epoch 539 finished \tANN training loss 0.272170 Accuracy: 0.911464\n",
      ">> Epoch 540 finished \tANN training loss 0.316284 Accuracy: 0.890276\n",
      ">> Epoch 541 finished \tANN training loss 0.287443 Accuracy: 0.901249\n",
      ">> Epoch 542 finished \tANN training loss 0.293035 Accuracy: 0.894060\n",
      ">> Epoch 543 finished \tANN training loss 0.278963 Accuracy: 0.897087\n",
      ">> Epoch 544 finished \tANN training loss 0.257968 Accuracy: 0.920166\n",
      ">> Epoch 545 finished \tANN training loss 0.249194 Accuracy: 0.917896\n",
      ">> Epoch 546 finished \tANN training loss 0.263203 Accuracy: 0.913356\n",
      ">> Epoch 547 finished \tANN training loss 0.295228 Accuracy: 0.885358\n",
      ">> Epoch 548 finished \tANN training loss 0.291024 Accuracy: 0.893681\n",
      ">> Epoch 549 finished \tANN training loss 0.273832 Accuracy: 0.906924\n",
      ">> Epoch 550 finished \tANN training loss 0.262342 Accuracy: 0.909572\n",
      ">> Epoch 551 finished \tANN training loss 0.302367 Accuracy: 0.896708\n",
      ">> Epoch 552 finished \tANN training loss 0.267613 Accuracy: 0.904275\n",
      ">> Epoch 553 finished \tANN training loss 0.254501 Accuracy: 0.915626\n",
      ">> Epoch 554 finished \tANN training loss 0.258820 Accuracy: 0.909572\n",
      ">> Epoch 555 finished \tANN training loss 0.349153 Accuracy: 0.878169\n",
      ">> Epoch 556 finished \tANN training loss 0.284838 Accuracy: 0.904654\n",
      ">> Epoch 557 finished \tANN training loss 0.283283 Accuracy: 0.901627\n",
      ">> Epoch 558 finished \tANN training loss 0.276710 Accuracy: 0.903897\n",
      ">> Epoch 559 finished \tANN training loss 0.374869 Accuracy: 0.854711\n",
      ">> Epoch 560 finished \tANN training loss 0.260478 Accuracy: 0.911843\n",
      ">> Epoch 561 finished \tANN training loss 0.279026 Accuracy: 0.910708\n",
      ">> Epoch 562 finished \tANN training loss 0.333616 Accuracy: 0.853954\n",
      ">> Epoch 563 finished \tANN training loss 0.297278 Accuracy: 0.889898\n",
      ">> Epoch 564 finished \tANN training loss 0.254538 Accuracy: 0.909194\n",
      ">> Epoch 565 finished \tANN training loss 0.270813 Accuracy: 0.908059\n",
      ">> Epoch 566 finished \tANN training loss 0.283172 Accuracy: 0.898222\n",
      ">> Epoch 567 finished \tANN training loss 0.287434 Accuracy: 0.894438\n",
      ">> Epoch 568 finished \tANN training loss 0.330610 Accuracy: 0.875142\n",
      ">> Epoch 569 finished \tANN training loss 0.308838 Accuracy: 0.881196\n",
      ">> Epoch 570 finished \tANN training loss 0.242725 Accuracy: 0.920545\n",
      ">> Epoch 571 finished \tANN training loss 0.250455 Accuracy: 0.910708\n",
      ">> Epoch 572 finished \tANN training loss 0.242153 Accuracy: 0.915248\n",
      ">> Epoch 573 finished \tANN training loss 0.302736 Accuracy: 0.888384\n",
      ">> Epoch 574 finished \tANN training loss 0.273308 Accuracy: 0.897843\n",
      ">> Epoch 575 finished \tANN training loss 0.312357 Accuracy: 0.882331\n",
      ">> Epoch 576 finished \tANN training loss 0.292994 Accuracy: 0.899357\n",
      ">> Epoch 577 finished \tANN training loss 0.298800 Accuracy: 0.888384\n",
      ">> Epoch 578 finished \tANN training loss 0.235823 Accuracy: 0.923193\n",
      ">> Epoch 579 finished \tANN training loss 0.282239 Accuracy: 0.901627\n",
      ">> Epoch 580 finished \tANN training loss 0.252521 Accuracy: 0.920923\n",
      ">> Epoch 581 finished \tANN training loss 0.299585 Accuracy: 0.883844\n",
      ">> Epoch 582 finished \tANN training loss 0.264909 Accuracy: 0.909951\n",
      ">> Epoch 583 finished \tANN training loss 0.256966 Accuracy: 0.911086\n",
      ">> Epoch 584 finished \tANN training loss 0.265350 Accuracy: 0.909951\n",
      ">> Epoch 585 finished \tANN training loss 0.280852 Accuracy: 0.902762\n",
      ">> Epoch 586 finished \tANN training loss 0.251274 Accuracy: 0.924328\n",
      ">> Epoch 587 finished \tANN training loss 0.270872 Accuracy: 0.911086\n",
      ">> Epoch 588 finished \tANN training loss 0.299626 Accuracy: 0.900114\n",
      ">> Epoch 589 finished \tANN training loss 0.264957 Accuracy: 0.909572\n",
      ">> Epoch 590 finished \tANN training loss 0.249040 Accuracy: 0.923193\n",
      ">> Epoch 591 finished \tANN training loss 0.270604 Accuracy: 0.897465\n",
      ">> Epoch 592 finished \tANN training loss 0.262905 Accuracy: 0.912599\n",
      ">> Epoch 593 finished \tANN training loss 0.277950 Accuracy: 0.896708\n",
      ">> Epoch 594 finished \tANN training loss 0.241842 Accuracy: 0.918275\n",
      ">> Epoch 595 finished \tANN training loss 0.262173 Accuracy: 0.910708\n",
      ">> Epoch 596 finished \tANN training loss 0.274788 Accuracy: 0.907302\n",
      ">> Epoch 597 finished \tANN training loss 0.283321 Accuracy: 0.899357\n",
      ">> Epoch 598 finished \tANN training loss 0.241321 Accuracy: 0.922437\n",
      ">> Epoch 599 finished \tANN training loss 0.282027 Accuracy: 0.891033\n",
      ">> Epoch 600 finished \tANN training loss 0.284380 Accuracy: 0.894816\n",
      ">> Epoch 601 finished \tANN training loss 0.287948 Accuracy: 0.902762\n",
      ">> Epoch 602 finished \tANN training loss 0.257537 Accuracy: 0.909194\n",
      ">> Epoch 603 finished \tANN training loss 0.246553 Accuracy: 0.912221\n",
      ">> Epoch 604 finished \tANN training loss 0.238373 Accuracy: 0.924328\n",
      ">> Epoch 605 finished \tANN training loss 0.270641 Accuracy: 0.902005\n",
      ">> Epoch 606 finished \tANN training loss 0.256431 Accuracy: 0.916005\n",
      ">> Epoch 607 finished \tANN training loss 0.260500 Accuracy: 0.897843\n",
      ">> Epoch 608 finished \tANN training loss 0.289095 Accuracy: 0.894438\n",
      ">> Epoch 609 finished \tANN training loss 0.230538 Accuracy: 0.922815\n",
      ">> Epoch 610 finished \tANN training loss 0.284229 Accuracy: 0.887628\n",
      ">> Epoch 611 finished \tANN training loss 0.260971 Accuracy: 0.908437\n",
      ">> Epoch 612 finished \tANN training loss 0.246806 Accuracy: 0.916761\n",
      ">> Epoch 613 finished \tANN training loss 0.336372 Accuracy: 0.908816\n",
      ">> Epoch 614 finished \tANN training loss 0.286639 Accuracy: 0.897843\n",
      ">> Epoch 615 finished \tANN training loss 0.247020 Accuracy: 0.924328\n",
      ">> Epoch 616 finished \tANN training loss 0.266203 Accuracy: 0.906167\n",
      ">> Epoch 617 finished \tANN training loss 0.316780 Accuracy: 0.868710\n",
      ">> Epoch 618 finished \tANN training loss 0.298236 Accuracy: 0.878925\n",
      ">> Epoch 619 finished \tANN training loss 0.252148 Accuracy: 0.912599\n",
      ">> Epoch 620 finished \tANN training loss 0.233469 Accuracy: 0.922437\n",
      ">> Epoch 621 finished \tANN training loss 0.252875 Accuracy: 0.911086\n",
      ">> Epoch 622 finished \tANN training loss 0.281802 Accuracy: 0.898600\n",
      ">> Epoch 623 finished \tANN training loss 0.302934 Accuracy: 0.885358\n",
      ">> Epoch 624 finished \tANN training loss 0.292407 Accuracy: 0.903519\n",
      ">> Epoch 625 finished \tANN training loss 0.285281 Accuracy: 0.899357\n",
      ">> Epoch 626 finished \tANN training loss 0.236776 Accuracy: 0.923950\n",
      ">> Epoch 627 finished \tANN training loss 0.334736 Accuracy: 0.883087\n",
      ">> Epoch 628 finished \tANN training loss 0.318117 Accuracy: 0.862656\n",
      ">> Epoch 629 finished \tANN training loss 0.281368 Accuracy: 0.897087\n",
      ">> Epoch 630 finished \tANN training loss 0.240163 Accuracy: 0.919410\n",
      ">> Epoch 631 finished \tANN training loss 0.258624 Accuracy: 0.905411\n",
      ">> Epoch 632 finished \tANN training loss 0.250447 Accuracy: 0.908437\n",
      ">> Epoch 633 finished \tANN training loss 0.271151 Accuracy: 0.900870\n",
      ">> Epoch 634 finished \tANN training loss 0.257187 Accuracy: 0.910329\n",
      ">> Epoch 635 finished \tANN training loss 0.290857 Accuracy: 0.901249\n",
      ">> Epoch 636 finished \tANN training loss 0.240950 Accuracy: 0.908437\n",
      ">> Epoch 637 finished \tANN training loss 0.258809 Accuracy: 0.906924\n",
      ">> Epoch 638 finished \tANN training loss 0.296277 Accuracy: 0.882709\n",
      ">> Epoch 639 finished \tANN training loss 0.280200 Accuracy: 0.891033\n",
      ">> Epoch 640 finished \tANN training loss 0.251715 Accuracy: 0.912221\n",
      ">> Epoch 641 finished \tANN training loss 0.281751 Accuracy: 0.898978\n",
      ">> Epoch 642 finished \tANN training loss 0.228884 Accuracy: 0.927734\n",
      ">> Epoch 643 finished \tANN training loss 0.240001 Accuracy: 0.923193\n",
      ">> Epoch 644 finished \tANN training loss 0.263410 Accuracy: 0.909951\n",
      ">> Epoch 645 finished \tANN training loss 0.317854 Accuracy: 0.884979\n",
      ">> Epoch 646 finished \tANN training loss 0.327578 Accuracy: 0.867953\n",
      ">> Epoch 647 finished \tANN training loss 0.236550 Accuracy: 0.924707\n",
      ">> Epoch 648 finished \tANN training loss 0.258632 Accuracy: 0.901249\n",
      ">> Epoch 649 finished \tANN training loss 0.255686 Accuracy: 0.912599\n",
      ">> Epoch 650 finished \tANN training loss 0.235237 Accuracy: 0.920166\n",
      ">> Epoch 651 finished \tANN training loss 0.231457 Accuracy: 0.922437\n",
      ">> Epoch 652 finished \tANN training loss 0.280054 Accuracy: 0.893303\n",
      ">> Epoch 653 finished \tANN training loss 0.303951 Accuracy: 0.893681\n",
      ">> Epoch 654 finished \tANN training loss 0.293812 Accuracy: 0.890276\n",
      ">> Epoch 655 finished \tANN training loss 0.219359 Accuracy: 0.925463\n",
      ">> Epoch 656 finished \tANN training loss 0.250198 Accuracy: 0.910708\n",
      ">> Epoch 657 finished \tANN training loss 0.239241 Accuracy: 0.921302\n",
      ">> Epoch 658 finished \tANN training loss 0.288602 Accuracy: 0.891033\n",
      ">> Epoch 659 finished \tANN training loss 0.252548 Accuracy: 0.916761\n",
      ">> Epoch 660 finished \tANN training loss 0.278924 Accuracy: 0.896330\n",
      ">> Epoch 661 finished \tANN training loss 0.238123 Accuracy: 0.920166\n",
      ">> Epoch 662 finished \tANN training loss 0.272307 Accuracy: 0.897087\n",
      ">> Epoch 663 finished \tANN training loss 0.256544 Accuracy: 0.911086\n",
      ">> Epoch 664 finished \tANN training loss 0.236030 Accuracy: 0.922437\n",
      ">> Epoch 665 finished \tANN training loss 0.288357 Accuracy: 0.899735\n",
      ">> Epoch 666 finished \tANN training loss 0.275173 Accuracy: 0.910708\n",
      ">> Epoch 667 finished \tANN training loss 0.265913 Accuracy: 0.909194\n",
      ">> Epoch 668 finished \tANN training loss 0.255670 Accuracy: 0.914113\n",
      ">> Epoch 669 finished \tANN training loss 0.261590 Accuracy: 0.905789\n",
      ">> Epoch 670 finished \tANN training loss 0.280005 Accuracy: 0.894816\n",
      ">> Epoch 671 finished \tANN training loss 0.261202 Accuracy: 0.895573\n",
      ">> Epoch 672 finished \tANN training loss 0.250333 Accuracy: 0.904654\n",
      ">> Epoch 673 finished \tANN training loss 0.253625 Accuracy: 0.908059\n",
      ">> Epoch 674 finished \tANN training loss 0.267727 Accuracy: 0.902005\n",
      ">> Epoch 675 finished \tANN training loss 0.242194 Accuracy: 0.916383\n",
      ">> Epoch 676 finished \tANN training loss 0.260594 Accuracy: 0.909951\n",
      ">> Epoch 677 finished \tANN training loss 0.231005 Accuracy: 0.917140\n",
      ">> Epoch 678 finished \tANN training loss 0.249141 Accuracy: 0.916383\n",
      ">> Epoch 679 finished \tANN training loss 0.320844 Accuracy: 0.867953\n",
      ">> Epoch 680 finished \tANN training loss 0.247001 Accuracy: 0.914491\n",
      ">> Epoch 681 finished \tANN training loss 0.252314 Accuracy: 0.912978\n",
      ">> Epoch 682 finished \tANN training loss 0.248716 Accuracy: 0.910708\n",
      ">> Epoch 683 finished \tANN training loss 0.300022 Accuracy: 0.889519\n",
      ">> Epoch 684 finished \tANN training loss 0.246098 Accuracy: 0.909951\n",
      ">> Epoch 685 finished \tANN training loss 0.282789 Accuracy: 0.897087\n",
      ">> Epoch 686 finished \tANN training loss 0.281669 Accuracy: 0.899357\n",
      ">> Epoch 687 finished \tANN training loss 0.271193 Accuracy: 0.898222\n",
      ">> Epoch 688 finished \tANN training loss 0.266538 Accuracy: 0.906167\n",
      ">> Epoch 689 finished \tANN training loss 0.252134 Accuracy: 0.908059\n",
      ">> Epoch 690 finished \tANN training loss 0.271332 Accuracy: 0.909572\n",
      ">> Epoch 691 finished \tANN training loss 0.316936 Accuracy: 0.880061\n",
      ">> Epoch 692 finished \tANN training loss 0.378488 Accuracy: 0.886114\n",
      ">> Epoch 693 finished \tANN training loss 0.338343 Accuracy: 0.865305\n",
      ">> Epoch 694 finished \tANN training loss 0.286041 Accuracy: 0.889519\n",
      ">> Epoch 695 finished \tANN training loss 0.284778 Accuracy: 0.897465\n",
      ">> Epoch 696 finished \tANN training loss 0.317693 Accuracy: 0.878547\n",
      ">> Epoch 697 finished \tANN training loss 0.234634 Accuracy: 0.922058\n",
      ">> Epoch 698 finished \tANN training loss 0.278406 Accuracy: 0.899357\n",
      ">> Epoch 699 finished \tANN training loss 0.242899 Accuracy: 0.914869\n",
      ">> Epoch 700 finished \tANN training loss 0.272737 Accuracy: 0.912978\n",
      ">> Epoch 701 finished \tANN training loss 0.247497 Accuracy: 0.917518\n",
      ">> Epoch 702 finished \tANN training loss 0.247787 Accuracy: 0.921302\n",
      ">> Epoch 703 finished \tANN training loss 0.312399 Accuracy: 0.884222\n",
      ">> Epoch 704 finished \tANN training loss 0.242077 Accuracy: 0.914869\n",
      ">> Epoch 705 finished \tANN training loss 0.276820 Accuracy: 0.914113\n",
      ">> Epoch 706 finished \tANN training loss 0.278809 Accuracy: 0.905789\n",
      ">> Epoch 707 finished \tANN training loss 0.223772 Accuracy: 0.928112\n",
      ">> Epoch 708 finished \tANN training loss 0.219412 Accuracy: 0.926220\n",
      ">> Epoch 709 finished \tANN training loss 0.228745 Accuracy: 0.920923\n",
      ">> Epoch 710 finished \tANN training loss 0.239562 Accuracy: 0.918653\n",
      ">> Epoch 711 finished \tANN training loss 0.273286 Accuracy: 0.905032\n",
      ">> Epoch 712 finished \tANN training loss 0.228816 Accuracy: 0.912978\n",
      ">> Epoch 713 finished \tANN training loss 0.236548 Accuracy: 0.917896\n",
      ">> Epoch 714 finished \tANN training loss 0.248131 Accuracy: 0.914491\n",
      ">> Epoch 715 finished \tANN training loss 0.245151 Accuracy: 0.915626\n",
      ">> Epoch 716 finished \tANN training loss 0.254253 Accuracy: 0.907681\n",
      ">> Epoch 717 finished \tANN training loss 0.245218 Accuracy: 0.908816\n",
      ">> Epoch 718 finished \tANN training loss 0.226755 Accuracy: 0.922437\n",
      ">> Epoch 719 finished \tANN training loss 0.240143 Accuracy: 0.919031\n",
      ">> Epoch 720 finished \tANN training loss 0.244506 Accuracy: 0.906546\n",
      ">> Epoch 721 finished \tANN training loss 0.249210 Accuracy: 0.912978\n",
      ">> Epoch 722 finished \tANN training loss 0.271470 Accuracy: 0.901627\n",
      ">> Epoch 723 finished \tANN training loss 0.293884 Accuracy: 0.885736\n",
      ">> Epoch 724 finished \tANN training loss 0.236457 Accuracy: 0.912221\n",
      ">> Epoch 725 finished \tANN training loss 0.226206 Accuracy: 0.917896\n",
      ">> Epoch 726 finished \tANN training loss 0.223895 Accuracy: 0.930004\n",
      ">> Epoch 727 finished \tANN training loss 0.215231 Accuracy: 0.922815\n",
      ">> Epoch 728 finished \tANN training loss 0.228998 Accuracy: 0.926977\n",
      ">> Epoch 729 finished \tANN training loss 0.239830 Accuracy: 0.908437\n",
      ">> Epoch 730 finished \tANN training loss 0.318976 Accuracy: 0.882709\n",
      ">> Epoch 731 finished \tANN training loss 0.252406 Accuracy: 0.912221\n",
      ">> Epoch 732 finished \tANN training loss 0.244983 Accuracy: 0.909951\n",
      ">> Epoch 733 finished \tANN training loss 0.228182 Accuracy: 0.934166\n",
      ">> Epoch 734 finished \tANN training loss 0.249419 Accuracy: 0.911086\n",
      ">> Epoch 735 finished \tANN training loss 0.292579 Accuracy: 0.900492\n",
      ">> Epoch 736 finished \tANN training loss 0.269186 Accuracy: 0.899357\n",
      ">> Epoch 737 finished \tANN training loss 0.257716 Accuracy: 0.901627\n",
      ">> Epoch 738 finished \tANN training loss 0.253027 Accuracy: 0.922437\n",
      ">> Epoch 739 finished \tANN training loss 0.238363 Accuracy: 0.922437\n",
      ">> Epoch 740 finished \tANN training loss 0.282537 Accuracy: 0.895573\n",
      ">> Epoch 741 finished \tANN training loss 0.229238 Accuracy: 0.921302\n",
      ">> Epoch 742 finished \tANN training loss 0.229188 Accuracy: 0.917518\n",
      ">> Epoch 743 finished \tANN training loss 0.255682 Accuracy: 0.909572\n",
      ">> Epoch 744 finished \tANN training loss 0.226794 Accuracy: 0.919410\n",
      ">> Epoch 745 finished \tANN training loss 0.235894 Accuracy: 0.923950\n",
      ">> Epoch 746 finished \tANN training loss 0.243703 Accuracy: 0.913734\n",
      ">> Epoch 747 finished \tANN training loss 0.259465 Accuracy: 0.909572\n",
      ">> Epoch 748 finished \tANN training loss 0.277363 Accuracy: 0.900492\n",
      ">> Epoch 749 finished \tANN training loss 0.236555 Accuracy: 0.917140\n",
      ">> Epoch 750 finished \tANN training loss 0.208186 Accuracy: 0.934544\n",
      ">> Epoch 751 finished \tANN training loss 0.224782 Accuracy: 0.928869\n",
      ">> Epoch 752 finished \tANN training loss 0.221865 Accuracy: 0.926220\n",
      ">> Epoch 753 finished \tANN training loss 0.229463 Accuracy: 0.923193\n",
      ">> Epoch 754 finished \tANN training loss 0.250312 Accuracy: 0.918275\n",
      ">> Epoch 755 finished \tANN training loss 0.233624 Accuracy: 0.920545\n",
      ">> Epoch 756 finished \tANN training loss 0.229463 Accuracy: 0.922437\n",
      ">> Epoch 757 finished \tANN training loss 0.280316 Accuracy: 0.901249\n",
      ">> Epoch 758 finished \tANN training loss 0.253081 Accuracy: 0.907302\n",
      ">> Epoch 759 finished \tANN training loss 0.215840 Accuracy: 0.923950\n",
      ">> Epoch 760 finished \tANN training loss 0.270710 Accuracy: 0.890276\n",
      ">> Epoch 761 finished \tANN training loss 0.339643 Accuracy: 0.883466\n",
      ">> Epoch 762 finished \tANN training loss 0.286775 Accuracy: 0.891033\n",
      ">> Epoch 763 finished \tANN training loss 0.269124 Accuracy: 0.917140\n",
      ">> Epoch 764 finished \tANN training loss 0.237824 Accuracy: 0.919031\n",
      ">> Epoch 765 finished \tANN training loss 0.256753 Accuracy: 0.899357\n",
      ">> Epoch 766 finished \tANN training loss 0.276750 Accuracy: 0.901249\n",
      ">> Epoch 767 finished \tANN training loss 0.348031 Accuracy: 0.859629\n",
      ">> Epoch 768 finished \tANN training loss 0.281350 Accuracy: 0.896708\n",
      ">> Epoch 769 finished \tANN training loss 0.228184 Accuracy: 0.927734\n",
      ">> Epoch 770 finished \tANN training loss 0.242151 Accuracy: 0.916761\n",
      ">> Epoch 771 finished \tANN training loss 0.282622 Accuracy: 0.885358\n",
      ">> Epoch 772 finished \tANN training loss 0.282178 Accuracy: 0.893681\n",
      ">> Epoch 773 finished \tANN training loss 0.274666 Accuracy: 0.889519\n",
      ">> Epoch 774 finished \tANN training loss 0.271219 Accuracy: 0.905411\n",
      ">> Epoch 775 finished \tANN training loss 0.268995 Accuracy: 0.903140\n",
      ">> Epoch 776 finished \tANN training loss 0.251167 Accuracy: 0.908816\n",
      ">> Epoch 777 finished \tANN training loss 0.225581 Accuracy: 0.916383\n",
      ">> Epoch 778 finished \tANN training loss 0.221916 Accuracy: 0.924707\n",
      ">> Epoch 779 finished \tANN training loss 0.303339 Accuracy: 0.877412\n",
      ">> Epoch 780 finished \tANN training loss 0.272916 Accuracy: 0.889898\n",
      ">> Epoch 781 finished \tANN training loss 0.247690 Accuracy: 0.908437\n",
      ">> Epoch 782 finished \tANN training loss 0.272162 Accuracy: 0.894816\n",
      ">> Epoch 783 finished \tANN training loss 0.289430 Accuracy: 0.897465\n",
      ">> Epoch 784 finished \tANN training loss 0.250274 Accuracy: 0.908059\n",
      ">> Epoch 785 finished \tANN training loss 0.279657 Accuracy: 0.901249\n",
      ">> Epoch 786 finished \tANN training loss 0.272027 Accuracy: 0.903519\n",
      ">> Epoch 787 finished \tANN training loss 0.220155 Accuracy: 0.925463\n",
      ">> Epoch 788 finished \tANN training loss 0.247085 Accuracy: 0.914113\n",
      ">> Epoch 789 finished \tANN training loss 0.247214 Accuracy: 0.905789\n",
      ">> Epoch 790 finished \tANN training loss 0.233118 Accuracy: 0.929625\n",
      ">> Epoch 791 finished \tANN training loss 0.214780 Accuracy: 0.922058\n",
      ">> Epoch 792 finished \tANN training loss 0.221563 Accuracy: 0.921680\n",
      ">> Epoch 793 finished \tANN training loss 0.279442 Accuracy: 0.885736\n",
      ">> Epoch 794 finished \tANN training loss 0.264648 Accuracy: 0.902005\n",
      ">> Epoch 795 finished \tANN training loss 0.226482 Accuracy: 0.925842\n",
      ">> Epoch 796 finished \tANN training loss 0.215132 Accuracy: 0.927355\n",
      ">> Epoch 797 finished \tANN training loss 0.281652 Accuracy: 0.897465\n",
      ">> Epoch 798 finished \tANN training loss 0.235409 Accuracy: 0.913356\n",
      ">> Epoch 799 finished \tANN training loss 0.242915 Accuracy: 0.900114\n",
      ">> Epoch 800 finished \tANN training loss 0.262435 Accuracy: 0.910329\n",
      ">> Epoch 801 finished \tANN training loss 0.222877 Accuracy: 0.923950\n",
      ">> Epoch 802 finished \tANN training loss 0.210546 Accuracy: 0.926977\n",
      ">> Epoch 803 finished \tANN training loss 0.217945 Accuracy: 0.925842\n",
      ">> Epoch 804 finished \tANN training loss 0.244822 Accuracy: 0.916383\n",
      ">> Epoch 805 finished \tANN training loss 0.208109 Accuracy: 0.933409\n",
      ">> Epoch 806 finished \tANN training loss 0.231114 Accuracy: 0.907302\n",
      ">> Epoch 807 finished \tANN training loss 0.225194 Accuracy: 0.921680\n",
      ">> Epoch 808 finished \tANN training loss 0.227802 Accuracy: 0.925463\n",
      ">> Epoch 809 finished \tANN training loss 0.245490 Accuracy: 0.908816\n",
      ">> Epoch 810 finished \tANN training loss 0.250427 Accuracy: 0.909951\n",
      ">> Epoch 811 finished \tANN training loss 0.263167 Accuracy: 0.901249\n",
      ">> Epoch 812 finished \tANN training loss 0.218393 Accuracy: 0.923572\n",
      ">> Epoch 813 finished \tANN training loss 0.230827 Accuracy: 0.912599\n",
      ">> Epoch 814 finished \tANN training loss 0.295174 Accuracy: 0.889519\n",
      ">> Epoch 815 finished \tANN training loss 0.251232 Accuracy: 0.923572\n",
      ">> Epoch 816 finished \tANN training loss 0.223925 Accuracy: 0.920923\n",
      ">> Epoch 817 finished \tANN training loss 0.236206 Accuracy: 0.920166\n",
      ">> Epoch 818 finished \tANN training loss 0.226813 Accuracy: 0.923572\n",
      ">> Epoch 819 finished \tANN training loss 0.212356 Accuracy: 0.919788\n",
      ">> Epoch 820 finished \tANN training loss 0.233043 Accuracy: 0.911464\n",
      ">> Epoch 821 finished \tANN training loss 0.270211 Accuracy: 0.908059\n",
      ">> Epoch 822 finished \tANN training loss 0.228702 Accuracy: 0.925842\n",
      ">> Epoch 823 finished \tANN training loss 0.244380 Accuracy: 0.910708\n",
      ">> Epoch 824 finished \tANN training loss 0.219406 Accuracy: 0.926977\n",
      ">> Epoch 825 finished \tANN training loss 0.224462 Accuracy: 0.918653\n",
      ">> Epoch 826 finished \tANN training loss 0.233128 Accuracy: 0.916005\n",
      ">> Epoch 827 finished \tANN training loss 0.257004 Accuracy: 0.907302\n",
      ">> Epoch 828 finished \tANN training loss 0.214841 Accuracy: 0.924707\n",
      ">> Epoch 829 finished \tANN training loss 0.252178 Accuracy: 0.907302\n",
      ">> Epoch 830 finished \tANN training loss 0.234554 Accuracy: 0.920545\n",
      ">> Epoch 831 finished \tANN training loss 0.237518 Accuracy: 0.910708\n",
      ">> Epoch 832 finished \tANN training loss 0.210182 Accuracy: 0.925085\n",
      ">> Epoch 833 finished \tANN training loss 0.252134 Accuracy: 0.914491\n",
      ">> Epoch 834 finished \tANN training loss 0.224042 Accuracy: 0.924328\n",
      ">> Epoch 835 finished \tANN training loss 0.271987 Accuracy: 0.900870\n",
      ">> Epoch 836 finished \tANN training loss 0.225403 Accuracy: 0.921680\n",
      ">> Epoch 837 finished \tANN training loss 0.235665 Accuracy: 0.913356\n",
      ">> Epoch 838 finished \tANN training loss 0.294083 Accuracy: 0.878925\n",
      ">> Epoch 839 finished \tANN training loss 0.250032 Accuracy: 0.904654\n",
      ">> Epoch 840 finished \tANN training loss 0.253944 Accuracy: 0.912978\n",
      ">> Epoch 841 finished \tANN training loss 0.244972 Accuracy: 0.920166\n",
      ">> Epoch 842 finished \tANN training loss 0.269912 Accuracy: 0.900114\n",
      ">> Epoch 843 finished \tANN training loss 0.295637 Accuracy: 0.891411\n",
      ">> Epoch 844 finished \tANN training loss 0.214813 Accuracy: 0.921680\n",
      ">> Epoch 845 finished \tANN training loss 0.239434 Accuracy: 0.912599\n",
      ">> Epoch 846 finished \tANN training loss 0.291471 Accuracy: 0.869088\n",
      ">> Epoch 847 finished \tANN training loss 0.222772 Accuracy: 0.926599\n",
      ">> Epoch 848 finished \tANN training loss 0.241564 Accuracy: 0.913734\n",
      ">> Epoch 849 finished \tANN training loss 0.269636 Accuracy: 0.902005\n",
      ">> Epoch 850 finished \tANN training loss 0.243569 Accuracy: 0.907302\n",
      ">> Epoch 851 finished \tANN training loss 0.206381 Accuracy: 0.930760\n",
      ">> Epoch 852 finished \tANN training loss 0.207773 Accuracy: 0.925085\n",
      ">> Epoch 853 finished \tANN training loss 0.209388 Accuracy: 0.926599\n",
      ">> Epoch 854 finished \tANN training loss 0.244654 Accuracy: 0.912221\n",
      ">> Epoch 855 finished \tANN training loss 0.209286 Accuracy: 0.928112\n",
      ">> Epoch 856 finished \tANN training loss 0.207853 Accuracy: 0.930760\n",
      ">> Epoch 857 finished \tANN training loss 0.265039 Accuracy: 0.890655\n",
      ">> Epoch 858 finished \tANN training loss 0.239476 Accuracy: 0.905789\n",
      ">> Epoch 859 finished \tANN training loss 0.249097 Accuracy: 0.907681\n",
      ">> Epoch 860 finished \tANN training loss 0.261800 Accuracy: 0.900114\n",
      ">> Epoch 861 finished \tANN training loss 0.254120 Accuracy: 0.906546\n",
      ">> Epoch 862 finished \tANN training loss 0.270006 Accuracy: 0.895573\n",
      ">> Epoch 863 finished \tANN training loss 0.227741 Accuracy: 0.922815\n",
      ">> Epoch 864 finished \tANN training loss 0.277865 Accuracy: 0.906924\n",
      ">> Epoch 865 finished \tANN training loss 0.207307 Accuracy: 0.925085\n",
      ">> Epoch 866 finished \tANN training loss 0.226983 Accuracy: 0.920923\n",
      ">> Epoch 867 finished \tANN training loss 0.221501 Accuracy: 0.922815\n",
      ">> Epoch 868 finished \tANN training loss 0.226310 Accuracy: 0.926220\n",
      ">> Epoch 869 finished \tANN training loss 0.243329 Accuracy: 0.912978\n",
      ">> Epoch 870 finished \tANN training loss 0.221125 Accuracy: 0.920166\n",
      ">> Epoch 871 finished \tANN training loss 0.254413 Accuracy: 0.908059\n",
      ">> Epoch 872 finished \tANN training loss 0.247201 Accuracy: 0.915248\n",
      ">> Epoch 873 finished \tANN training loss 0.266809 Accuracy: 0.895195\n",
      ">> Epoch 874 finished \tANN training loss 0.259768 Accuracy: 0.909194\n",
      ">> Epoch 875 finished \tANN training loss 0.231039 Accuracy: 0.920923\n",
      ">> Epoch 876 finished \tANN training loss 0.215684 Accuracy: 0.922058\n",
      ">> Epoch 877 finished \tANN training loss 0.209116 Accuracy: 0.928869\n",
      ">> Epoch 878 finished \tANN training loss 0.214318 Accuracy: 0.926977\n",
      ">> Epoch 879 finished \tANN training loss 0.234085 Accuracy: 0.920923\n",
      ">> Epoch 880 finished \tANN training loss 0.250939 Accuracy: 0.907681\n",
      ">> Epoch 881 finished \tANN training loss 0.229242 Accuracy: 0.928869\n",
      ">> Epoch 882 finished \tANN training loss 0.217280 Accuracy: 0.927355\n",
      ">> Epoch 883 finished \tANN training loss 0.225301 Accuracy: 0.921680\n",
      ">> Epoch 884 finished \tANN training loss 0.269039 Accuracy: 0.894438\n",
      ">> Epoch 885 finished \tANN training loss 0.208299 Accuracy: 0.926599\n",
      ">> Epoch 886 finished \tANN training loss 0.193694 Accuracy: 0.939084\n",
      ">> Epoch 887 finished \tANN training loss 0.238849 Accuracy: 0.911843\n",
      ">> Epoch 888 finished \tANN training loss 0.216254 Accuracy: 0.921302\n",
      ">> Epoch 889 finished \tANN training loss 0.259074 Accuracy: 0.907302\n",
      ">> Epoch 890 finished \tANN training loss 0.230574 Accuracy: 0.920923\n",
      ">> Epoch 891 finished \tANN training loss 0.229959 Accuracy: 0.932274\n",
      ">> Epoch 892 finished \tANN training loss 0.217067 Accuracy: 0.923950\n",
      ">> Epoch 893 finished \tANN training loss 0.224216 Accuracy: 0.912978\n",
      ">> Epoch 894 finished \tANN training loss 0.219774 Accuracy: 0.932652\n",
      ">> Epoch 895 finished \tANN training loss 0.214227 Accuracy: 0.922437\n",
      ">> Epoch 896 finished \tANN training loss 0.204454 Accuracy: 0.928112\n",
      ">> Epoch 897 finished \tANN training loss 0.245056 Accuracy: 0.906167\n",
      ">> Epoch 898 finished \tANN training loss 0.263840 Accuracy: 0.895573\n",
      ">> Epoch 899 finished \tANN training loss 0.237665 Accuracy: 0.912978\n",
      ">> Epoch 900 finished \tANN training loss 0.214248 Accuracy: 0.923193\n",
      ">> Epoch 901 finished \tANN training loss 0.277796 Accuracy: 0.917140\n",
      ">> Epoch 902 finished \tANN training loss 0.257209 Accuracy: 0.912221\n",
      ">> Epoch 903 finished \tANN training loss 0.249029 Accuracy: 0.906167\n",
      ">> Epoch 904 finished \tANN training loss 0.229722 Accuracy: 0.909194\n",
      ">> Epoch 905 finished \tANN training loss 0.245733 Accuracy: 0.909951\n",
      ">> Epoch 906 finished \tANN training loss 0.242419 Accuracy: 0.908816\n",
      ">> Epoch 907 finished \tANN training loss 0.211243 Accuracy: 0.923193\n",
      ">> Epoch 908 finished \tANN training loss 0.235274 Accuracy: 0.907681\n",
      ">> Epoch 909 finished \tANN training loss 0.250399 Accuracy: 0.915248\n",
      ">> Epoch 910 finished \tANN training loss 0.226784 Accuracy: 0.919031\n",
      ">> Epoch 911 finished \tANN training loss 0.209451 Accuracy: 0.924707\n",
      ">> Epoch 912 finished \tANN training loss 0.317291 Accuracy: 0.865305\n",
      ">> Epoch 913 finished \tANN training loss 0.221803 Accuracy: 0.919788\n",
      ">> Epoch 914 finished \tANN training loss 0.225849 Accuracy: 0.927355\n",
      ">> Epoch 915 finished \tANN training loss 0.217814 Accuracy: 0.921680\n",
      ">> Epoch 916 finished \tANN training loss 0.214458 Accuracy: 0.915626\n",
      ">> Epoch 917 finished \tANN training loss 0.243167 Accuracy: 0.904275\n",
      ">> Epoch 918 finished \tANN training loss 0.249626 Accuracy: 0.908816\n",
      ">> Epoch 919 finished \tANN training loss 0.222943 Accuracy: 0.924707\n",
      ">> Epoch 920 finished \tANN training loss 0.210595 Accuracy: 0.937949\n",
      ">> Epoch 921 finished \tANN training loss 0.198490 Accuracy: 0.926977\n",
      ">> Epoch 922 finished \tANN training loss 0.307647 Accuracy: 0.883087\n",
      ">> Epoch 923 finished \tANN training loss 0.247276 Accuracy: 0.906924\n",
      ">> Epoch 924 finished \tANN training loss 0.207902 Accuracy: 0.929247\n",
      ">> Epoch 925 finished \tANN training loss 0.205579 Accuracy: 0.931517\n",
      ">> Epoch 926 finished \tANN training loss 0.283622 Accuracy: 0.890276\n",
      ">> Epoch 927 finished \tANN training loss 0.225264 Accuracy: 0.913734\n",
      ">> Epoch 928 finished \tANN training loss 0.198990 Accuracy: 0.935679\n",
      ">> Epoch 929 finished \tANN training loss 0.242498 Accuracy: 0.922815\n",
      ">> Epoch 930 finished \tANN training loss 0.246473 Accuracy: 0.911086\n",
      ">> Epoch 931 finished \tANN training loss 0.257859 Accuracy: 0.900114\n",
      ">> Epoch 932 finished \tANN training loss 0.219227 Accuracy: 0.926599\n",
      ">> Epoch 933 finished \tANN training loss 0.194080 Accuracy: 0.938706\n",
      ">> Epoch 934 finished \tANN training loss 0.252067 Accuracy: 0.899357\n",
      ">> Epoch 935 finished \tANN training loss 0.206095 Accuracy: 0.927355\n",
      ">> Epoch 936 finished \tANN training loss 0.221834 Accuracy: 0.914113\n",
      ">> Epoch 937 finished \tANN training loss 0.196264 Accuracy: 0.932652\n",
      ">> Epoch 938 finished \tANN training loss 0.211177 Accuracy: 0.929247\n",
      ">> Epoch 939 finished \tANN training loss 0.220596 Accuracy: 0.931139\n",
      ">> Epoch 940 finished \tANN training loss 0.237512 Accuracy: 0.908437\n",
      ">> Epoch 941 finished \tANN training loss 0.246773 Accuracy: 0.908059\n",
      ">> Epoch 942 finished \tANN training loss 0.247909 Accuracy: 0.907681\n",
      ">> Epoch 943 finished \tANN training loss 0.247143 Accuracy: 0.913356\n",
      ">> Epoch 944 finished \tANN training loss 0.218607 Accuracy: 0.923950\n",
      ">> Epoch 945 finished \tANN training loss 0.261894 Accuracy: 0.892168\n",
      ">> Epoch 946 finished \tANN training loss 0.229005 Accuracy: 0.916005\n",
      ">> Epoch 947 finished \tANN training loss 0.210200 Accuracy: 0.936814\n",
      ">> Epoch 948 finished \tANN training loss 0.248242 Accuracy: 0.906167\n",
      ">> Epoch 949 finished \tANN training loss 0.218511 Accuracy: 0.921302\n",
      ">> Epoch 950 finished \tANN training loss 0.208452 Accuracy: 0.929247\n",
      ">> Epoch 951 finished \tANN training loss 0.246403 Accuracy: 0.906546\n",
      ">> Epoch 952 finished \tANN training loss 0.204262 Accuracy: 0.936058\n",
      ">> Epoch 953 finished \tANN training loss 0.194410 Accuracy: 0.944381\n",
      ">> Epoch 954 finished \tANN training loss 0.263073 Accuracy: 0.906924\n",
      ">> Epoch 955 finished \tANN training loss 0.235985 Accuracy: 0.921302\n",
      ">> Epoch 956 finished \tANN training loss 0.213096 Accuracy: 0.928869\n",
      ">> Epoch 957 finished \tANN training loss 0.293410 Accuracy: 0.881196\n",
      ">> Epoch 958 finished \tANN training loss 0.222555 Accuracy: 0.921680\n",
      ">> Epoch 959 finished \tANN training loss 0.211782 Accuracy: 0.924328\n",
      ">> Epoch 960 finished \tANN training loss 0.259183 Accuracy: 0.902762\n",
      ">> Epoch 961 finished \tANN training loss 0.188877 Accuracy: 0.934922\n",
      ">> Epoch 962 finished \tANN training loss 0.258005 Accuracy: 0.905789\n",
      ">> Epoch 963 finished \tANN training loss 0.269737 Accuracy: 0.911843\n",
      ">> Epoch 964 finished \tANN training loss 0.252520 Accuracy: 0.909572\n",
      ">> Epoch 965 finished \tANN training loss 0.224711 Accuracy: 0.925463\n",
      ">> Epoch 966 finished \tANN training loss 0.270231 Accuracy: 0.886114\n",
      ">> Epoch 967 finished \tANN training loss 0.280819 Accuracy: 0.890655\n",
      ">> Epoch 968 finished \tANN training loss 0.274604 Accuracy: 0.897843\n",
      ">> Epoch 969 finished \tANN training loss 0.222917 Accuracy: 0.922437\n",
      ">> Epoch 970 finished \tANN training loss 0.210918 Accuracy: 0.932652\n",
      ">> Epoch 971 finished \tANN training loss 0.193329 Accuracy: 0.936058\n",
      ">> Epoch 972 finished \tANN training loss 0.221595 Accuracy: 0.928490\n",
      ">> Epoch 973 finished \tANN training loss 0.222303 Accuracy: 0.931517\n",
      ">> Epoch 974 finished \tANN training loss 0.213839 Accuracy: 0.930760\n",
      ">> Epoch 975 finished \tANN training loss 0.251705 Accuracy: 0.905411\n",
      ">> Epoch 976 finished \tANN training loss 0.246895 Accuracy: 0.907681\n",
      ">> Epoch 977 finished \tANN training loss 0.192666 Accuracy: 0.939084\n",
      ">> Epoch 978 finished \tANN training loss 0.196041 Accuracy: 0.937193\n",
      ">> Epoch 979 finished \tANN training loss 0.255402 Accuracy: 0.903519\n",
      ">> Epoch 980 finished \tANN training loss 0.194325 Accuracy: 0.930004\n",
      ">> Epoch 981 finished \tANN training loss 0.198141 Accuracy: 0.934166\n",
      ">> Epoch 982 finished \tANN training loss 0.348026 Accuracy: 0.849414\n",
      ">> Epoch 983 finished \tANN training loss 0.249939 Accuracy: 0.902005\n",
      ">> Epoch 984 finished \tANN training loss 0.211954 Accuracy: 0.920923\n",
      ">> Epoch 985 finished \tANN training loss 0.214180 Accuracy: 0.925842\n",
      ">> Epoch 986 finished \tANN training loss 0.209626 Accuracy: 0.933409\n",
      ">> Epoch 987 finished \tANN training loss 0.225391 Accuracy: 0.920545\n",
      ">> Epoch 988 finished \tANN training loss 0.188453 Accuracy: 0.940219\n",
      ">> Epoch 989 finished \tANN training loss 0.226157 Accuracy: 0.912599\n",
      ">> Epoch 990 finished \tANN training loss 0.236841 Accuracy: 0.911086\n",
      ">> Epoch 991 finished \tANN training loss 0.240325 Accuracy: 0.908059\n",
      ">> Epoch 992 finished \tANN training loss 0.225517 Accuracy: 0.919788\n",
      ">> Epoch 993 finished \tANN training loss 0.253191 Accuracy: 0.903897\n",
      ">> Epoch 994 finished \tANN training loss 0.201798 Accuracy: 0.926977\n",
      ">> Epoch 995 finished \tANN training loss 0.216179 Accuracy: 0.920166\n",
      ">> Epoch 996 finished \tANN training loss 0.241935 Accuracy: 0.913734\n",
      ">> Epoch 997 finished \tANN training loss 0.229204 Accuracy: 0.924328\n",
      ">> Epoch 998 finished \tANN training loss 0.242089 Accuracy: 0.913356\n",
      ">> Epoch 999 finished \tANN training loss 0.220920 Accuracy: 0.934166\n",
      ">> Epoch 1000 finished \tANN training loss 0.191255 Accuracy: 0.939463\n",
      ">> Epoch 1001 finished \tANN training loss 0.216562 Accuracy: 0.923193\n",
      ">> Epoch 1002 finished \tANN training loss 0.213849 Accuracy: 0.926220\n",
      ">> Epoch 1003 finished \tANN training loss 0.237854 Accuracy: 0.920166\n",
      ">> Epoch 1004 finished \tANN training loss 0.257239 Accuracy: 0.892168\n",
      ">> Epoch 1005 finished \tANN training loss 0.341430 Accuracy: 0.878169\n",
      ">> Epoch 1006 finished \tANN training loss 0.229400 Accuracy: 0.918275\n",
      ">> Epoch 1007 finished \tANN training loss 0.263775 Accuracy: 0.904275\n",
      ">> Epoch 1008 finished \tANN training loss 0.283624 Accuracy: 0.889898\n",
      ">> Epoch 1009 finished \tANN training loss 0.207511 Accuracy: 0.931896\n",
      ">> Epoch 1010 finished \tANN training loss 0.219079 Accuracy: 0.928112\n",
      ">> Epoch 1011 finished \tANN training loss 0.208124 Accuracy: 0.933409\n",
      ">> Epoch 1012 finished \tANN training loss 0.239860 Accuracy: 0.908437\n",
      ">> Epoch 1013 finished \tANN training loss 0.204085 Accuracy: 0.927355\n",
      ">> Epoch 1014 finished \tANN training loss 0.194907 Accuracy: 0.928112\n",
      ">> Epoch 1015 finished \tANN training loss 0.208806 Accuracy: 0.928112\n",
      ">> Epoch 1016 finished \tANN training loss 0.317928 Accuracy: 0.875899\n",
      ">> Epoch 1017 finished \tANN training loss 0.211914 Accuracy: 0.930760\n",
      ">> Epoch 1018 finished \tANN training loss 0.187984 Accuracy: 0.935301\n",
      ">> Epoch 1019 finished \tANN training loss 0.230411 Accuracy: 0.918275\n",
      ">> Epoch 1020 finished \tANN training loss 0.197244 Accuracy: 0.930004\n",
      ">> Epoch 1021 finished \tANN training loss 0.373773 Accuracy: 0.845252\n",
      ">> Epoch 1022 finished \tANN training loss 0.205980 Accuracy: 0.922437\n",
      ">> Epoch 1023 finished \tANN training loss 0.258157 Accuracy: 0.911843\n",
      ">> Epoch 1024 finished \tANN training loss 0.289733 Accuracy: 0.882331\n",
      ">> Epoch 1025 finished \tANN training loss 0.219608 Accuracy: 0.922058\n",
      ">> Epoch 1026 finished \tANN training loss 0.224633 Accuracy: 0.919031\n",
      ">> Epoch 1027 finished \tANN training loss 0.197789 Accuracy: 0.939084\n",
      ">> Epoch 1028 finished \tANN training loss 0.209050 Accuracy: 0.930382\n",
      ">> Epoch 1029 finished \tANN training loss 0.213667 Accuracy: 0.926220\n",
      ">> Epoch 1030 finished \tANN training loss 0.218977 Accuracy: 0.920545\n",
      ">> Epoch 1031 finished \tANN training loss 0.235581 Accuracy: 0.919788\n",
      ">> Epoch 1032 finished \tANN training loss 0.199888 Accuracy: 0.938706\n",
      ">> Epoch 1033 finished \tANN training loss 0.203684 Accuracy: 0.933409\n",
      ">> Epoch 1034 finished \tANN training loss 0.312308 Accuracy: 0.864926\n",
      ">> Epoch 1035 finished \tANN training loss 0.261869 Accuracy: 0.894816\n",
      ">> Epoch 1036 finished \tANN training loss 0.232865 Accuracy: 0.915248\n",
      ">> Epoch 1037 finished \tANN training loss 0.191473 Accuracy: 0.935679\n",
      ">> Epoch 1038 finished \tANN training loss 0.208151 Accuracy: 0.931139\n",
      ">> Epoch 1039 finished \tANN training loss 0.306994 Accuracy: 0.884979\n",
      ">> Epoch 1040 finished \tANN training loss 0.209876 Accuracy: 0.936814\n",
      ">> Epoch 1041 finished \tANN training loss 0.228489 Accuracy: 0.922437\n",
      ">> Epoch 1042 finished \tANN training loss 0.238180 Accuracy: 0.912978\n",
      ">> Epoch 1043 finished \tANN training loss 0.236450 Accuracy: 0.911843\n",
      ">> Epoch 1044 finished \tANN training loss 0.218340 Accuracy: 0.922815\n",
      ">> Epoch 1045 finished \tANN training loss 0.212681 Accuracy: 0.922437\n",
      ">> Epoch 1046 finished \tANN training loss 0.258476 Accuracy: 0.897087\n",
      ">> Epoch 1047 finished \tANN training loss 0.267544 Accuracy: 0.921302\n",
      ">> Epoch 1048 finished \tANN training loss 0.253155 Accuracy: 0.900492\n",
      ">> Epoch 1049 finished \tANN training loss 0.238252 Accuracy: 0.917896\n",
      ">> Epoch 1050 finished \tANN training loss 0.204235 Accuracy: 0.938328\n",
      ">> Epoch 1051 finished \tANN training loss 0.227862 Accuracy: 0.918653\n",
      ">> Epoch 1052 finished \tANN training loss 0.240181 Accuracy: 0.911464\n",
      ">> Epoch 1053 finished \tANN training loss 0.279080 Accuracy: 0.894438\n",
      ">> Epoch 1054 finished \tANN training loss 0.218824 Accuracy: 0.923572\n",
      ">> Epoch 1055 finished \tANN training loss 0.211056 Accuracy: 0.924328\n",
      ">> Epoch 1056 finished \tANN training loss 0.196194 Accuracy: 0.934166\n",
      ">> Epoch 1057 finished \tANN training loss 0.237947 Accuracy: 0.912599\n",
      ">> Epoch 1058 finished \tANN training loss 0.238468 Accuracy: 0.910329\n",
      ">> Epoch 1059 finished \tANN training loss 0.232026 Accuracy: 0.920545\n",
      ">> Epoch 1060 finished \tANN training loss 0.257961 Accuracy: 0.897465\n",
      ">> Epoch 1061 finished \tANN training loss 0.247017 Accuracy: 0.903519\n",
      ">> Epoch 1062 finished \tANN training loss 0.236718 Accuracy: 0.916761\n",
      ">> Epoch 1063 finished \tANN training loss 0.211516 Accuracy: 0.933787\n",
      ">> Epoch 1064 finished \tANN training loss 0.223228 Accuracy: 0.923572\n",
      ">> Epoch 1065 finished \tANN training loss 0.198365 Accuracy: 0.929625\n",
      ">> Epoch 1066 finished \tANN training loss 0.270394 Accuracy: 0.890655\n",
      ">> Epoch 1067 finished \tANN training loss 0.214968 Accuracy: 0.919031\n",
      ">> Epoch 1068 finished \tANN training loss 0.240094 Accuracy: 0.910708\n",
      ">> Epoch 1069 finished \tANN training loss 0.203814 Accuracy: 0.931517\n",
      ">> Epoch 1070 finished \tANN training loss 0.234553 Accuracy: 0.923193\n",
      ">> Epoch 1071 finished \tANN training loss 0.207551 Accuracy: 0.934922\n",
      ">> Epoch 1072 finished \tANN training loss 0.215271 Accuracy: 0.917518\n",
      ">> Epoch 1073 finished \tANN training loss 0.203748 Accuracy: 0.930382\n",
      ">> Epoch 1074 finished \tANN training loss 0.202913 Accuracy: 0.935301\n",
      ">> Epoch 1075 finished \tANN training loss 0.241671 Accuracy: 0.903519\n",
      ">> Epoch 1076 finished \tANN training loss 0.236097 Accuracy: 0.916761\n",
      ">> Epoch 1077 finished \tANN training loss 0.211930 Accuracy: 0.928112\n",
      ">> Epoch 1078 finished \tANN training loss 0.205667 Accuracy: 0.925842\n",
      ">> Epoch 1079 finished \tANN training loss 0.201580 Accuracy: 0.927734\n",
      ">> Epoch 1080 finished \tANN training loss 0.230950 Accuracy: 0.920166\n",
      ">> Epoch 1081 finished \tANN training loss 0.248709 Accuracy: 0.911464\n",
      ">> Epoch 1082 finished \tANN training loss 0.259546 Accuracy: 0.900114\n",
      ">> Epoch 1083 finished \tANN training loss 0.212635 Accuracy: 0.925842\n",
      ">> Epoch 1084 finished \tANN training loss 0.216120 Accuracy: 0.925085\n",
      ">> Epoch 1085 finished \tANN training loss 0.228989 Accuracy: 0.916005\n",
      ">> Epoch 1086 finished \tANN training loss 0.200201 Accuracy: 0.933787\n",
      ">> Epoch 1087 finished \tANN training loss 0.221113 Accuracy: 0.911464\n",
      ">> Epoch 1088 finished \tANN training loss 0.222225 Accuracy: 0.919410\n",
      ">> Epoch 1089 finished \tANN training loss 0.221004 Accuracy: 0.915248\n",
      ">> Epoch 1090 finished \tANN training loss 0.206997 Accuracy: 0.929247\n",
      ">> Epoch 1091 finished \tANN training loss 0.200797 Accuracy: 0.936436\n",
      ">> Epoch 1092 finished \tANN training loss 0.250486 Accuracy: 0.894060\n",
      ">> Epoch 1093 finished \tANN training loss 0.258418 Accuracy: 0.902005\n",
      ">> Epoch 1094 finished \tANN training loss 0.209048 Accuracy: 0.924707\n",
      ">> Epoch 1095 finished \tANN training loss 0.240344 Accuracy: 0.908816\n",
      ">> Epoch 1096 finished \tANN training loss 0.254897 Accuracy: 0.911086\n",
      ">> Epoch 1097 finished \tANN training loss 0.208387 Accuracy: 0.923572\n",
      ">> Epoch 1098 finished \tANN training loss 0.279534 Accuracy: 0.892168\n",
      ">> Epoch 1099 finished \tANN training loss 0.241559 Accuracy: 0.918653\n",
      ">> Epoch 1100 finished \tANN training loss 0.269745 Accuracy: 0.904275\n",
      ">> Epoch 1101 finished \tANN training loss 0.206269 Accuracy: 0.928112\n",
      ">> Epoch 1102 finished \tANN training loss 0.225506 Accuracy: 0.918653\n",
      ">> Epoch 1103 finished \tANN training loss 0.203221 Accuracy: 0.922437\n",
      ">> Epoch 1104 finished \tANN training loss 0.201611 Accuracy: 0.929625\n",
      ">> Epoch 1105 finished \tANN training loss 0.210566 Accuracy: 0.926220\n",
      ">> Epoch 1106 finished \tANN training loss 0.229347 Accuracy: 0.919788\n",
      ">> Epoch 1107 finished \tANN training loss 0.240407 Accuracy: 0.920923\n",
      ">> Epoch 1108 finished \tANN training loss 0.203349 Accuracy: 0.926977\n",
      ">> Epoch 1109 finished \tANN training loss 0.233370 Accuracy: 0.912599\n",
      ">> Epoch 1110 finished \tANN training loss 0.183312 Accuracy: 0.937571\n",
      ">> Epoch 1111 finished \tANN training loss 0.193932 Accuracy: 0.929247\n",
      ">> Epoch 1112 finished \tANN training loss 0.215037 Accuracy: 0.917518\n",
      ">> Epoch 1113 finished \tANN training loss 0.294296 Accuracy: 0.883844\n",
      ">> Epoch 1114 finished \tANN training loss 0.194255 Accuracy: 0.931139\n",
      ">> Epoch 1115 finished \tANN training loss 0.222324 Accuracy: 0.920166\n",
      ">> Epoch 1116 finished \tANN training loss 0.333839 Accuracy: 0.858872\n",
      ">> Epoch 1117 finished \tANN training loss 0.231279 Accuracy: 0.917896\n",
      ">> Epoch 1118 finished \tANN training loss 0.226477 Accuracy: 0.923193\n",
      ">> Epoch 1119 finished \tANN training loss 0.222375 Accuracy: 0.930760\n",
      ">> Epoch 1120 finished \tANN training loss 0.190551 Accuracy: 0.933031\n",
      ">> Epoch 1121 finished \tANN training loss 0.203812 Accuracy: 0.934166\n",
      ">> Epoch 1122 finished \tANN training loss 0.239396 Accuracy: 0.911086\n",
      ">> Epoch 1123 finished \tANN training loss 0.296299 Accuracy: 0.872872\n",
      ">> Epoch 1124 finished \tANN training loss 0.199293 Accuracy: 0.933787\n",
      ">> Epoch 1125 finished \tANN training loss 0.188637 Accuracy: 0.944003\n",
      ">> Epoch 1126 finished \tANN training loss 0.290192 Accuracy: 0.881574\n",
      ">> Epoch 1127 finished \tANN training loss 0.204229 Accuracy: 0.931139\n",
      ">> Epoch 1128 finished \tANN training loss 0.242680 Accuracy: 0.908437\n",
      ">> Epoch 1129 finished \tANN training loss 0.202299 Accuracy: 0.928112\n",
      ">> Epoch 1130 finished \tANN training loss 0.184449 Accuracy: 0.943625\n",
      ">> Epoch 1131 finished \tANN training loss 0.203808 Accuracy: 0.932652\n",
      ">> Epoch 1132 finished \tANN training loss 0.190049 Accuracy: 0.936436\n",
      ">> Epoch 1133 finished \tANN training loss 0.200078 Accuracy: 0.933787\n",
      ">> Epoch 1134 finished \tANN training loss 0.209163 Accuracy: 0.930004\n",
      ">> Epoch 1135 finished \tANN training loss 0.203113 Accuracy: 0.936436\n",
      ">> Epoch 1136 finished \tANN training loss 0.236995 Accuracy: 0.908059\n",
      ">> Epoch 1137 finished \tANN training loss 0.251097 Accuracy: 0.886871\n",
      ">> Epoch 1138 finished \tANN training loss 0.192991 Accuracy: 0.931517\n",
      ">> Epoch 1139 finished \tANN training loss 0.213774 Accuracy: 0.924707\n",
      ">> Epoch 1140 finished \tANN training loss 0.238012 Accuracy: 0.907302\n",
      ">> Epoch 1141 finished \tANN training loss 0.230726 Accuracy: 0.910708\n",
      ">> Epoch 1142 finished \tANN training loss 0.200546 Accuracy: 0.935679\n",
      ">> Epoch 1143 finished \tANN training loss 0.373598 Accuracy: 0.849414\n",
      ">> Epoch 1144 finished \tANN training loss 0.207275 Accuracy: 0.931139\n",
      ">> Epoch 1145 finished \tANN training loss 0.188961 Accuracy: 0.939084\n",
      ">> Epoch 1146 finished \tANN training loss 0.199986 Accuracy: 0.937193\n",
      ">> Epoch 1147 finished \tANN training loss 0.209718 Accuracy: 0.923950\n",
      ">> Epoch 1148 finished \tANN training loss 0.213298 Accuracy: 0.921302\n",
      ">> Epoch 1149 finished \tANN training loss 0.246241 Accuracy: 0.909951\n",
      ">> Epoch 1150 finished \tANN training loss 0.297357 Accuracy: 0.901249\n",
      ">> Epoch 1151 finished \tANN training loss 0.196545 Accuracy: 0.936436\n",
      ">> Epoch 1152 finished \tANN training loss 0.214203 Accuracy: 0.928490\n",
      ">> Epoch 1153 finished \tANN training loss 0.179544 Accuracy: 0.946273\n",
      ">> Epoch 1154 finished \tANN training loss 0.225567 Accuracy: 0.921680\n",
      ">> Epoch 1155 finished \tANN training loss 0.208693 Accuracy: 0.926599\n",
      ">> Epoch 1156 finished \tANN training loss 0.199441 Accuracy: 0.939841\n",
      ">> Epoch 1157 finished \tANN training loss 0.182491 Accuracy: 0.940598\n",
      ">> Epoch 1158 finished \tANN training loss 0.213492 Accuracy: 0.928112\n",
      ">> Epoch 1159 finished \tANN training loss 0.206695 Accuracy: 0.927355\n",
      ">> Epoch 1160 finished \tANN training loss 0.181696 Accuracy: 0.945138\n",
      ">> Epoch 1161 finished \tANN training loss 0.200512 Accuracy: 0.926220\n",
      ">> Epoch 1162 finished \tANN training loss 0.181099 Accuracy: 0.936814\n",
      ">> Epoch 1163 finished \tANN training loss 0.218656 Accuracy: 0.922815\n",
      ">> Epoch 1164 finished \tANN training loss 0.206992 Accuracy: 0.928112\n",
      ">> Epoch 1165 finished \tANN training loss 0.218202 Accuracy: 0.913356\n",
      ">> Epoch 1166 finished \tANN training loss 0.228348 Accuracy: 0.918275\n",
      ">> Epoch 1167 finished \tANN training loss 0.202020 Accuracy: 0.923950\n",
      ">> Epoch 1168 finished \tANN training loss 0.247696 Accuracy: 0.902384\n",
      ">> Epoch 1169 finished \tANN training loss 0.222304 Accuracy: 0.914869\n",
      ">> Epoch 1170 finished \tANN training loss 0.205712 Accuracy: 0.922437\n",
      ">> Epoch 1171 finished \tANN training loss 0.215145 Accuracy: 0.929247\n",
      ">> Epoch 1172 finished \tANN training loss 0.189318 Accuracy: 0.938706\n",
      ">> Epoch 1173 finished \tANN training loss 0.249320 Accuracy: 0.902762\n",
      ">> Epoch 1174 finished \tANN training loss 0.219381 Accuracy: 0.917140\n",
      ">> Epoch 1175 finished \tANN training loss 0.243699 Accuracy: 0.916005\n",
      ">> Epoch 1176 finished \tANN training loss 0.218704 Accuracy: 0.926220\n",
      ">> Epoch 1177 finished \tANN training loss 0.187948 Accuracy: 0.933031\n",
      ">> Epoch 1178 finished \tANN training loss 0.234372 Accuracy: 0.917518\n",
      ">> Epoch 1179 finished \tANN training loss 0.213320 Accuracy: 0.922815\n",
      ">> Epoch 1180 finished \tANN training loss 0.211278 Accuracy: 0.922058\n",
      ">> Epoch 1181 finished \tANN training loss 0.199110 Accuracy: 0.927734\n",
      ">> Epoch 1182 finished \tANN training loss 0.194989 Accuracy: 0.933031\n",
      ">> Epoch 1183 finished \tANN training loss 0.202564 Accuracy: 0.929247\n",
      ">> Epoch 1184 finished \tANN training loss 0.215131 Accuracy: 0.923950\n",
      ">> Epoch 1185 finished \tANN training loss 0.209844 Accuracy: 0.926599\n",
      ">> Epoch 1186 finished \tANN training loss 0.195949 Accuracy: 0.928869\n",
      ">> Epoch 1187 finished \tANN training loss 0.198973 Accuracy: 0.939463\n",
      ">> Epoch 1188 finished \tANN training loss 0.183758 Accuracy: 0.948165\n",
      ">> Epoch 1189 finished \tANN training loss 0.208816 Accuracy: 0.926220\n",
      ">> Epoch 1190 finished \tANN training loss 0.242757 Accuracy: 0.915626\n",
      ">> Epoch 1191 finished \tANN training loss 0.194600 Accuracy: 0.937193\n",
      ">> Epoch 1192 finished \tANN training loss 0.217162 Accuracy: 0.930760\n",
      ">> Epoch 1193 finished \tANN training loss 0.219845 Accuracy: 0.926977\n",
      ">> Epoch 1194 finished \tANN training loss 0.205294 Accuracy: 0.919410\n",
      ">> Epoch 1195 finished \tANN training loss 0.217662 Accuracy: 0.926220\n",
      ">> Epoch 1196 finished \tANN training loss 0.192468 Accuracy: 0.937571\n",
      ">> Epoch 1197 finished \tANN training loss 0.237668 Accuracy: 0.911843\n",
      ">> Epoch 1198 finished \tANN training loss 0.182116 Accuracy: 0.945895\n",
      ">> Epoch 1199 finished \tANN training loss 0.191445 Accuracy: 0.940976\n",
      ">> Epoch 1200 finished \tANN training loss 0.201432 Accuracy: 0.939084\n",
      ">> Epoch 1201 finished \tANN training loss 0.165768 Accuracy: 0.948543\n",
      ">> Epoch 1202 finished \tANN training loss 0.194542 Accuracy: 0.931517\n",
      ">> Epoch 1203 finished \tANN training loss 0.219166 Accuracy: 0.923193\n",
      ">> Epoch 1204 finished \tANN training loss 0.188974 Accuracy: 0.933787\n",
      ">> Epoch 1205 finished \tANN training loss 0.200596 Accuracy: 0.937949\n",
      ">> Epoch 1206 finished \tANN training loss 0.246931 Accuracy: 0.908059\n",
      ">> Epoch 1207 finished \tANN training loss 0.218959 Accuracy: 0.920923\n",
      ">> Epoch 1208 finished \tANN training loss 0.194988 Accuracy: 0.932652\n",
      ">> Epoch 1209 finished \tANN training loss 0.225992 Accuracy: 0.918275\n",
      ">> Epoch 1210 finished \tANN training loss 0.242142 Accuracy: 0.906167\n",
      ">> Epoch 1211 finished \tANN training loss 0.199088 Accuracy: 0.928112\n",
      ">> Epoch 1212 finished \tANN training loss 0.218911 Accuracy: 0.923572\n",
      ">> Epoch 1213 finished \tANN training loss 0.205852 Accuracy: 0.930004\n",
      ">> Epoch 1214 finished \tANN training loss 0.222027 Accuracy: 0.923950\n",
      ">> Epoch 1215 finished \tANN training loss 0.233273 Accuracy: 0.915626\n",
      ">> Epoch 1216 finished \tANN training loss 0.241112 Accuracy: 0.908437\n",
      ">> Epoch 1217 finished \tANN training loss 0.219295 Accuracy: 0.919788\n",
      ">> Epoch 1218 finished \tANN training loss 0.182422 Accuracy: 0.935301\n",
      ">> Epoch 1219 finished \tANN training loss 0.194672 Accuracy: 0.937949\n",
      ">> Epoch 1220 finished \tANN training loss 0.203690 Accuracy: 0.935679\n",
      ">> Epoch 1221 finished \tANN training loss 0.223433 Accuracy: 0.918275\n",
      ">> Epoch 1222 finished \tANN training loss 0.256598 Accuracy: 0.900492\n",
      ">> Epoch 1223 finished \tANN training loss 0.227926 Accuracy: 0.922058\n",
      ">> Epoch 1224 finished \tANN training loss 0.180515 Accuracy: 0.936814\n",
      ">> Epoch 1225 finished \tANN training loss 0.210647 Accuracy: 0.931139\n",
      ">> Epoch 1226 finished \tANN training loss 0.196009 Accuracy: 0.933031\n",
      ">> Epoch 1227 finished \tANN training loss 0.193687 Accuracy: 0.939841\n",
      ">> Epoch 1228 finished \tANN training loss 0.230747 Accuracy: 0.924328\n",
      ">> Epoch 1229 finished \tANN training loss 0.213962 Accuracy: 0.922058\n",
      ">> Epoch 1230 finished \tANN training loss 0.174180 Accuracy: 0.945138\n",
      ">> Epoch 1231 finished \tANN training loss 0.222920 Accuracy: 0.916005\n",
      ">> Epoch 1232 finished \tANN training loss 0.173964 Accuracy: 0.950813\n",
      ">> Epoch 1233 finished \tANN training loss 0.235913 Accuracy: 0.914869\n",
      ">> Epoch 1234 finished \tANN training loss 0.205791 Accuracy: 0.927734\n",
      ">> Epoch 1235 finished \tANN training loss 0.212198 Accuracy: 0.921302\n",
      ">> Epoch 1236 finished \tANN training loss 0.198437 Accuracy: 0.926977\n",
      ">> Epoch 1237 finished \tANN training loss 0.238887 Accuracy: 0.920923\n",
      ">> Epoch 1238 finished \tANN training loss 0.183518 Accuracy: 0.937193\n",
      ">> Epoch 1239 finished \tANN training loss 0.278351 Accuracy: 0.889898\n",
      ">> Epoch 1240 finished \tANN training loss 0.289022 Accuracy: 0.878925\n",
      ">> Epoch 1241 finished \tANN training loss 0.202451 Accuracy: 0.920545\n",
      ">> Epoch 1242 finished \tANN training loss 0.242884 Accuracy: 0.906924\n",
      ">> Epoch 1243 finished \tANN training loss 0.185179 Accuracy: 0.932274\n",
      ">> Epoch 1244 finished \tANN training loss 0.216786 Accuracy: 0.923572\n",
      ">> Epoch 1245 finished \tANN training loss 0.216951 Accuracy: 0.922437\n",
      ">> Epoch 1246 finished \tANN training loss 0.219852 Accuracy: 0.926220\n",
      ">> Epoch 1247 finished \tANN training loss 0.239982 Accuracy: 0.903140\n",
      ">> Epoch 1248 finished \tANN training loss 0.260530 Accuracy: 0.893303\n",
      ">> Epoch 1249 finished \tANN training loss 0.215911 Accuracy: 0.934922\n",
      ">> Epoch 1250 finished \tANN training loss 0.214799 Accuracy: 0.928490\n",
      ">> Epoch 1251 finished \tANN training loss 0.216737 Accuracy: 0.930760\n",
      ">> Epoch 1252 finished \tANN training loss 0.247331 Accuracy: 0.901249\n",
      ">> Epoch 1253 finished \tANN training loss 0.200253 Accuracy: 0.927355\n",
      ">> Epoch 1254 finished \tANN training loss 0.208397 Accuracy: 0.923193\n",
      ">> Epoch 1255 finished \tANN training loss 0.238538 Accuracy: 0.907302\n",
      ">> Epoch 1256 finished \tANN training loss 0.238986 Accuracy: 0.912978\n",
      ">> Epoch 1257 finished \tANN training loss 0.176027 Accuracy: 0.938328\n",
      ">> Epoch 1258 finished \tANN training loss 0.213464 Accuracy: 0.927734\n",
      ">> Epoch 1259 finished \tANN training loss 0.201755 Accuracy: 0.926599\n",
      ">> Epoch 1260 finished \tANN training loss 0.272692 Accuracy: 0.893303\n",
      ">> Epoch 1261 finished \tANN training loss 0.196959 Accuracy: 0.934544\n",
      ">> Epoch 1262 finished \tANN training loss 0.180658 Accuracy: 0.947030\n",
      ">> Epoch 1263 finished \tANN training loss 0.210213 Accuracy: 0.920166\n",
      ">> Epoch 1264 finished \tANN training loss 0.199192 Accuracy: 0.932274\n",
      ">> Epoch 1265 finished \tANN training loss 0.185749 Accuracy: 0.936058\n",
      ">> Epoch 1266 finished \tANN training loss 0.231276 Accuracy: 0.919410\n",
      ">> Epoch 1267 finished \tANN training loss 0.229447 Accuracy: 0.925842\n",
      ">> Epoch 1268 finished \tANN training loss 0.256302 Accuracy: 0.904654\n",
      ">> Epoch 1269 finished \tANN training loss 0.201728 Accuracy: 0.931139\n",
      ">> Epoch 1270 finished \tANN training loss 0.258675 Accuracy: 0.898600\n",
      ">> Epoch 1271 finished \tANN training loss 0.253654 Accuracy: 0.892546\n",
      ">> Epoch 1272 finished \tANN training loss 0.201212 Accuracy: 0.926599\n",
      ">> Epoch 1273 finished \tANN training loss 0.186625 Accuracy: 0.937571\n",
      ">> Epoch 1274 finished \tANN training loss 0.208156 Accuracy: 0.923193\n",
      ">> Epoch 1275 finished \tANN training loss 0.190624 Accuracy: 0.938328\n",
      ">> Epoch 1276 finished \tANN training loss 0.187479 Accuracy: 0.930004\n",
      ">> Epoch 1277 finished \tANN training loss 0.200549 Accuracy: 0.933787\n",
      ">> Epoch 1278 finished \tANN training loss 0.187660 Accuracy: 0.933787\n",
      ">> Epoch 1279 finished \tANN training loss 0.243501 Accuracy: 0.915626\n",
      ">> Epoch 1280 finished \tANN training loss 0.174668 Accuracy: 0.941355\n",
      ">> Epoch 1281 finished \tANN training loss 0.217111 Accuracy: 0.918275\n",
      ">> Epoch 1282 finished \tANN training loss 0.185172 Accuracy: 0.932652\n",
      ">> Epoch 1283 finished \tANN training loss 0.217655 Accuracy: 0.926977\n",
      ">> Epoch 1284 finished \tANN training loss 0.196148 Accuracy: 0.933787\n",
      ">> Epoch 1285 finished \tANN training loss 0.214868 Accuracy: 0.923193\n",
      ">> Epoch 1286 finished \tANN training loss 0.208504 Accuracy: 0.934544\n",
      ">> Epoch 1287 finished \tANN training loss 0.187833 Accuracy: 0.937193\n",
      ">> Epoch 1288 finished \tANN training loss 0.240368 Accuracy: 0.914491\n",
      ">> Epoch 1289 finished \tANN training loss 0.241266 Accuracy: 0.901627\n",
      ">> Epoch 1290 finished \tANN training loss 0.212379 Accuracy: 0.921302\n",
      ">> Epoch 1291 finished \tANN training loss 0.238262 Accuracy: 0.908816\n",
      ">> Epoch 1292 finished \tANN training loss 0.195721 Accuracy: 0.929247\n",
      ">> Epoch 1293 finished \tANN training loss 0.233038 Accuracy: 0.913734\n",
      ">> Epoch 1294 finished \tANN training loss 0.175875 Accuracy: 0.946652\n",
      ">> Epoch 1295 finished \tANN training loss 0.175234 Accuracy: 0.945895\n",
      ">> Epoch 1296 finished \tANN training loss 0.185756 Accuracy: 0.936814\n",
      ">> Epoch 1297 finished \tANN training loss 0.199963 Accuracy: 0.930760\n",
      ">> Epoch 1298 finished \tANN training loss 0.271833 Accuracy: 0.911843\n",
      ">> Epoch 1299 finished \tANN training loss 0.208568 Accuracy: 0.932274\n",
      ">> Epoch 1300 finished \tANN training loss 0.186091 Accuracy: 0.934544\n",
      ">> Epoch 1301 finished \tANN training loss 0.191303 Accuracy: 0.930760\n",
      ">> Epoch 1302 finished \tANN training loss 0.183524 Accuracy: 0.943246\n",
      ">> Epoch 1303 finished \tANN training loss 0.217585 Accuracy: 0.917518\n",
      ">> Epoch 1304 finished \tANN training loss 0.207162 Accuracy: 0.919788\n",
      ">> Epoch 1305 finished \tANN training loss 0.190014 Accuracy: 0.939084\n",
      ">> Epoch 1306 finished \tANN training loss 0.198956 Accuracy: 0.931896\n",
      ">> Epoch 1307 finished \tANN training loss 0.185148 Accuracy: 0.944003\n",
      ">> Epoch 1308 finished \tANN training loss 0.216538 Accuracy: 0.925842\n",
      ">> Epoch 1309 finished \tANN training loss 0.204415 Accuracy: 0.930004\n",
      ">> Epoch 1310 finished \tANN training loss 0.183842 Accuracy: 0.936436\n",
      ">> Epoch 1311 finished \tANN training loss 0.195871 Accuracy: 0.930760\n",
      ">> Epoch 1312 finished \tANN training loss 0.184161 Accuracy: 0.935679\n",
      ">> Epoch 1313 finished \tANN training loss 0.186632 Accuracy: 0.932652\n",
      ">> Epoch 1314 finished \tANN training loss 0.234103 Accuracy: 0.916005\n",
      ">> Epoch 1315 finished \tANN training loss 0.184189 Accuracy: 0.936814\n",
      ">> Epoch 1316 finished \tANN training loss 0.215472 Accuracy: 0.920166\n",
      ">> Epoch 1317 finished \tANN training loss 0.198664 Accuracy: 0.922058\n",
      ">> Epoch 1318 finished \tANN training loss 0.205285 Accuracy: 0.937571\n",
      ">> Epoch 1319 finished \tANN training loss 0.214613 Accuracy: 0.925842\n",
      ">> Epoch 1320 finished \tANN training loss 0.178644 Accuracy: 0.944381\n",
      ">> Epoch 1321 finished \tANN training loss 0.217278 Accuracy: 0.923950\n",
      ">> Epoch 1322 finished \tANN training loss 0.197533 Accuracy: 0.933787\n",
      ">> Epoch 1323 finished \tANN training loss 0.296696 Accuracy: 0.889141\n",
      ">> Epoch 1324 finished \tANN training loss 0.227577 Accuracy: 0.902005\n",
      ">> Epoch 1325 finished \tANN training loss 0.190798 Accuracy: 0.933031\n",
      ">> Epoch 1326 finished \tANN training loss 0.184062 Accuracy: 0.937949\n",
      ">> Epoch 1327 finished \tANN training loss 0.212623 Accuracy: 0.928490\n",
      ">> Epoch 1328 finished \tANN training loss 0.220994 Accuracy: 0.930004\n",
      ">> Epoch 1329 finished \tANN training loss 0.212434 Accuracy: 0.920166\n",
      ">> Epoch 1330 finished \tANN training loss 0.204149 Accuracy: 0.930382\n",
      ">> Epoch 1331 finished \tANN training loss 0.190606 Accuracy: 0.930004\n",
      ">> Epoch 1332 finished \tANN training loss 0.174181 Accuracy: 0.944003\n",
      ">> Epoch 1333 finished \tANN training loss 0.211089 Accuracy: 0.936436\n",
      ">> Epoch 1334 finished \tANN training loss 0.210725 Accuracy: 0.930382\n",
      ">> Epoch 1335 finished \tANN training loss 0.299900 Accuracy: 0.892925\n",
      ">> Epoch 1336 finished \tANN training loss 0.202984 Accuracy: 0.930760\n",
      ">> Epoch 1337 finished \tANN training loss 0.193987 Accuracy: 0.932652\n",
      ">> Epoch 1338 finished \tANN training loss 0.199499 Accuracy: 0.933787\n",
      ">> Epoch 1339 finished \tANN training loss 0.181193 Accuracy: 0.932274\n",
      ">> Epoch 1340 finished \tANN training loss 0.201642 Accuracy: 0.927355\n",
      ">> Epoch 1341 finished \tANN training loss 0.184327 Accuracy: 0.936436\n",
      ">> Epoch 1342 finished \tANN training loss 0.190189 Accuracy: 0.938706\n",
      ">> Epoch 1343 finished \tANN training loss 0.212468 Accuracy: 0.931517\n",
      ">> Epoch 1344 finished \tANN training loss 0.194303 Accuracy: 0.934922\n",
      ">> Epoch 1345 finished \tANN training loss 0.209254 Accuracy: 0.933031\n",
      ">> Epoch 1346 finished \tANN training loss 0.171453 Accuracy: 0.944381\n",
      ">> Epoch 1347 finished \tANN training loss 0.191296 Accuracy: 0.929247\n",
      ">> Epoch 1348 finished \tANN training loss 0.179806 Accuracy: 0.930382\n",
      ">> Epoch 1349 finished \tANN training loss 0.223024 Accuracy: 0.912221\n",
      ">> Epoch 1350 finished \tANN training loss 0.193377 Accuracy: 0.937193\n",
      ">> Epoch 1351 finished \tANN training loss 0.248796 Accuracy: 0.900870\n",
      ">> Epoch 1352 finished \tANN training loss 0.202605 Accuracy: 0.933787\n",
      ">> Epoch 1353 finished \tANN training loss 0.222632 Accuracy: 0.915626\n",
      ">> Epoch 1354 finished \tANN training loss 0.214948 Accuracy: 0.918275\n",
      ">> Epoch 1355 finished \tANN training loss 0.205736 Accuracy: 0.930382\n",
      ">> Epoch 1356 finished \tANN training loss 0.192800 Accuracy: 0.932652\n",
      ">> Epoch 1357 finished \tANN training loss 0.216415 Accuracy: 0.922058\n",
      ">> Epoch 1358 finished \tANN training loss 0.192542 Accuracy: 0.934922\n",
      ">> Epoch 1359 finished \tANN training loss 0.178797 Accuracy: 0.944381\n",
      ">> Epoch 1360 finished \tANN training loss 0.220575 Accuracy: 0.923572\n",
      ">> Epoch 1361 finished \tANN training loss 0.195234 Accuracy: 0.936436\n",
      ">> Epoch 1362 finished \tANN training loss 0.197093 Accuracy: 0.928490\n",
      ">> Epoch 1363 finished \tANN training loss 0.200911 Accuracy: 0.929625\n",
      ">> Epoch 1364 finished \tANN training loss 0.188541 Accuracy: 0.933409\n",
      ">> Epoch 1365 finished \tANN training loss 0.200613 Accuracy: 0.936436\n",
      ">> Epoch 1366 finished \tANN training loss 0.222464 Accuracy: 0.914491\n",
      ">> Epoch 1367 finished \tANN training loss 0.173401 Accuracy: 0.947030\n",
      ">> Epoch 1368 finished \tANN training loss 0.183805 Accuracy: 0.945516\n",
      ">> Epoch 1369 finished \tANN training loss 0.193312 Accuracy: 0.939084\n",
      ">> Epoch 1370 finished \tANN training loss 0.191618 Accuracy: 0.931139\n",
      ">> Epoch 1371 finished \tANN training loss 0.265510 Accuracy: 0.892925\n",
      ">> Epoch 1372 finished \tANN training loss 0.186920 Accuracy: 0.938706\n",
      ">> Epoch 1373 finished \tANN training loss 0.235755 Accuracy: 0.913356\n",
      ">> Epoch 1374 finished \tANN training loss 0.186022 Accuracy: 0.931896\n",
      ">> Epoch 1375 finished \tANN training loss 0.193574 Accuracy: 0.930004\n",
      ">> Epoch 1376 finished \tANN training loss 0.182910 Accuracy: 0.939841\n",
      ">> Epoch 1377 finished \tANN training loss 0.210423 Accuracy: 0.927355\n",
      ">> Epoch 1378 finished \tANN training loss 0.189052 Accuracy: 0.938328\n",
      ">> Epoch 1379 finished \tANN training loss 0.187525 Accuracy: 0.938328\n",
      ">> Epoch 1380 finished \tANN training loss 0.204317 Accuracy: 0.926220\n",
      ">> Epoch 1381 finished \tANN training loss 0.192414 Accuracy: 0.930760\n",
      ">> Epoch 1382 finished \tANN training loss 0.198589 Accuracy: 0.925085\n",
      ">> Epoch 1383 finished \tANN training loss 0.186831 Accuracy: 0.939084\n",
      ">> Epoch 1384 finished \tANN training loss 0.199946 Accuracy: 0.933787\n",
      ">> Epoch 1385 finished \tANN training loss 0.164390 Accuracy: 0.944381\n",
      ">> Epoch 1386 finished \tANN training loss 0.187353 Accuracy: 0.931139\n",
      ">> Epoch 1387 finished \tANN training loss 0.294784 Accuracy: 0.878169\n",
      ">> Epoch 1388 finished \tANN training loss 0.316203 Accuracy: 0.866818\n",
      ">> Epoch 1389 finished \tANN training loss 0.213050 Accuracy: 0.919410\n",
      ">> Epoch 1390 finished \tANN training loss 0.185097 Accuracy: 0.944760\n",
      ">> Epoch 1391 finished \tANN training loss 0.187111 Accuracy: 0.941355\n",
      ">> Epoch 1392 finished \tANN training loss 0.234165 Accuracy: 0.900870\n",
      ">> Epoch 1393 finished \tANN training loss 0.248970 Accuracy: 0.898222\n",
      ">> Epoch 1394 finished \tANN training loss 0.205825 Accuracy: 0.927355\n",
      ">> Epoch 1395 finished \tANN training loss 0.217039 Accuracy: 0.920923\n",
      ">> Epoch 1396 finished \tANN training loss 0.218102 Accuracy: 0.926220\n",
      ">> Epoch 1397 finished \tANN training loss 0.169172 Accuracy: 0.946273\n",
      ">> Epoch 1398 finished \tANN training loss 0.198511 Accuracy: 0.926220\n",
      ">> Epoch 1399 finished \tANN training loss 0.227606 Accuracy: 0.922815\n",
      ">> Epoch 1400 finished \tANN training loss 0.183379 Accuracy: 0.934922\n",
      ">> Epoch 1401 finished \tANN training loss 0.189644 Accuracy: 0.942111\n",
      ">> Epoch 1402 finished \tANN training loss 0.196261 Accuracy: 0.931517\n",
      ">> Epoch 1403 finished \tANN training loss 0.192943 Accuracy: 0.929247\n",
      ">> Epoch 1404 finished \tANN training loss 0.182326 Accuracy: 0.942868\n",
      ">> Epoch 1405 finished \tANN training loss 0.187202 Accuracy: 0.934544\n",
      ">> Epoch 1406 finished \tANN training loss 0.162790 Accuracy: 0.953462\n",
      ">> Epoch 1407 finished \tANN training loss 0.167825 Accuracy: 0.950435\n",
      ">> Epoch 1408 finished \tANN training loss 0.185445 Accuracy: 0.947030\n",
      ">> Epoch 1409 finished \tANN training loss 0.215428 Accuracy: 0.932652\n",
      ">> Epoch 1410 finished \tANN training loss 0.192691 Accuracy: 0.936058\n",
      ">> Epoch 1411 finished \tANN training loss 0.212438 Accuracy: 0.928112\n",
      ">> Epoch 1412 finished \tANN training loss 0.218390 Accuracy: 0.923950\n",
      ">> Epoch 1413 finished \tANN training loss 0.181402 Accuracy: 0.940598\n",
      ">> Epoch 1414 finished \tANN training loss 0.219454 Accuracy: 0.917140\n",
      ">> Epoch 1415 finished \tANN training loss 0.205051 Accuracy: 0.922058\n",
      ">> Epoch 1416 finished \tANN training loss 0.242320 Accuracy: 0.902762\n",
      ">> Epoch 1417 finished \tANN training loss 0.238302 Accuracy: 0.910329\n",
      ">> Epoch 1418 finished \tANN training loss 0.230192 Accuracy: 0.918653\n",
      ">> Epoch 1419 finished \tANN training loss 0.248761 Accuracy: 0.910329\n",
      ">> Epoch 1420 finished \tANN training loss 0.220970 Accuracy: 0.921680\n",
      ">> Epoch 1421 finished \tANN training loss 0.201445 Accuracy: 0.931517\n",
      ">> Epoch 1422 finished \tANN training loss 0.171906 Accuracy: 0.941733\n",
      ">> Epoch 1423 finished \tANN training loss 0.226843 Accuracy: 0.922437\n",
      ">> Epoch 1424 finished \tANN training loss 0.183701 Accuracy: 0.940219\n",
      ">> Epoch 1425 finished \tANN training loss 0.184873 Accuracy: 0.939463\n",
      ">> Epoch 1426 finished \tANN training loss 0.187906 Accuracy: 0.929625\n",
      ">> Epoch 1427 finished \tANN training loss 0.171493 Accuracy: 0.947030\n",
      ">> Epoch 1428 finished \tANN training loss 0.179005 Accuracy: 0.943625\n",
      ">> Epoch 1429 finished \tANN training loss 0.184434 Accuracy: 0.942111\n",
      ">> Epoch 1430 finished \tANN training loss 0.275184 Accuracy: 0.885358\n",
      ">> Epoch 1431 finished \tANN training loss 0.181350 Accuracy: 0.942111\n",
      ">> Epoch 1432 finished \tANN training loss 0.182676 Accuracy: 0.939084\n",
      ">> Epoch 1433 finished \tANN training loss 0.176243 Accuracy: 0.931139\n",
      ">> Epoch 1434 finished \tANN training loss 0.220414 Accuracy: 0.910708\n",
      ">> Epoch 1435 finished \tANN training loss 0.192416 Accuracy: 0.934544\n",
      ">> Epoch 1436 finished \tANN training loss 0.259287 Accuracy: 0.891411\n",
      ">> Epoch 1437 finished \tANN training loss 0.189534 Accuracy: 0.936814\n",
      ">> Epoch 1438 finished \tANN training loss 0.170421 Accuracy: 0.949678\n",
      ">> Epoch 1439 finished \tANN training loss 0.256684 Accuracy: 0.902005\n",
      ">> Epoch 1440 finished \tANN training loss 0.231519 Accuracy: 0.906924\n",
      ">> Epoch 1441 finished \tANN training loss 0.197729 Accuracy: 0.928869\n",
      ">> Epoch 1442 finished \tANN training loss 0.199464 Accuracy: 0.926220\n",
      ">> Epoch 1443 finished \tANN training loss 0.172244 Accuracy: 0.943246\n",
      ">> Epoch 1444 finished \tANN training loss 0.204168 Accuracy: 0.930004\n",
      ">> Epoch 1445 finished \tANN training loss 0.181614 Accuracy: 0.935679\n",
      ">> Epoch 1446 finished \tANN training loss 0.193395 Accuracy: 0.936436\n",
      ">> Epoch 1447 finished \tANN training loss 0.226330 Accuracy: 0.910708\n",
      ">> Epoch 1448 finished \tANN training loss 0.213618 Accuracy: 0.924328\n",
      ">> Epoch 1449 finished \tANN training loss 0.197037 Accuracy: 0.931517\n",
      ">> Epoch 1450 finished \tANN training loss 0.191085 Accuracy: 0.932274\n",
      ">> Epoch 1451 finished \tANN training loss 0.217463 Accuracy: 0.919410\n",
      ">> Epoch 1452 finished \tANN training loss 0.213639 Accuracy: 0.931517\n",
      ">> Epoch 1453 finished \tANN training loss 0.180271 Accuracy: 0.941733\n",
      ">> Epoch 1454 finished \tANN training loss 0.263729 Accuracy: 0.888384\n",
      ">> Epoch 1455 finished \tANN training loss 0.187635 Accuracy: 0.927734\n",
      ">> Epoch 1456 finished \tANN training loss 0.176660 Accuracy: 0.934544\n",
      ">> Epoch 1457 finished \tANN training loss 0.177776 Accuracy: 0.942111\n",
      ">> Epoch 1458 finished \tANN training loss 0.233555 Accuracy: 0.908059\n",
      ">> Epoch 1459 finished \tANN training loss 0.200303 Accuracy: 0.923572\n",
      ">> Epoch 1460 finished \tANN training loss 0.173764 Accuracy: 0.946273\n",
      ">> Epoch 1461 finished \tANN training loss 0.189592 Accuracy: 0.935301\n",
      ">> Epoch 1462 finished \tANN training loss 0.177229 Accuracy: 0.943625\n",
      ">> Epoch 1463 finished \tANN training loss 0.190931 Accuracy: 0.933409\n",
      ">> Epoch 1464 finished \tANN training loss 0.288853 Accuracy: 0.886114\n",
      ">> Epoch 1465 finished \tANN training loss 0.217492 Accuracy: 0.922437\n",
      ">> Epoch 1466 finished \tANN training loss 0.244610 Accuracy: 0.909194\n",
      ">> Epoch 1467 finished \tANN training loss 0.186832 Accuracy: 0.930004\n",
      ">> Epoch 1468 finished \tANN training loss 0.176063 Accuracy: 0.947030\n",
      ">> Epoch 1469 finished \tANN training loss 0.212196 Accuracy: 0.921680\n",
      ">> Epoch 1470 finished \tANN training loss 0.177696 Accuracy: 0.934166\n",
      ">> Epoch 1471 finished \tANN training loss 0.170084 Accuracy: 0.938328\n",
      ">> Epoch 1472 finished \tANN training loss 0.200050 Accuracy: 0.933409\n",
      ">> Epoch 1473 finished \tANN training loss 0.173105 Accuracy: 0.936058\n",
      ">> Epoch 1474 finished \tANN training loss 0.181556 Accuracy: 0.943246\n",
      ">> Epoch 1475 finished \tANN training loss 0.174617 Accuracy: 0.947787\n",
      ">> Epoch 1476 finished \tANN training loss 0.212180 Accuracy: 0.917896\n",
      ">> Epoch 1477 finished \tANN training loss 0.192675 Accuracy: 0.930382\n",
      ">> Epoch 1478 finished \tANN training loss 0.183400 Accuracy: 0.945138\n",
      ">> Epoch 1479 finished \tANN training loss 0.183562 Accuracy: 0.936436\n",
      ">> Epoch 1480 finished \tANN training loss 0.232877 Accuracy: 0.919788\n",
      ">> Epoch 1481 finished \tANN training loss 0.177237 Accuracy: 0.947030\n",
      ">> Epoch 1482 finished \tANN training loss 0.251278 Accuracy: 0.896708\n",
      ">> Epoch 1483 finished \tANN training loss 0.170415 Accuracy: 0.945895\n",
      ">> Epoch 1484 finished \tANN training loss 0.200796 Accuracy: 0.925085\n",
      ">> Epoch 1485 finished \tANN training loss 0.195372 Accuracy: 0.935301\n",
      ">> Epoch 1486 finished \tANN training loss 0.214751 Accuracy: 0.926977\n",
      ">> Epoch 1487 finished \tANN training loss 0.181589 Accuracy: 0.940598\n",
      ">> Epoch 1488 finished \tANN training loss 0.190578 Accuracy: 0.936814\n",
      ">> Epoch 1489 finished \tANN training loss 0.188087 Accuracy: 0.934922\n",
      ">> Epoch 1490 finished \tANN training loss 0.230024 Accuracy: 0.911086\n",
      ">> Epoch 1491 finished \tANN training loss 0.227422 Accuracy: 0.920545\n",
      ">> Epoch 1492 finished \tANN training loss 0.172410 Accuracy: 0.940976\n",
      ">> Epoch 1493 finished \tANN training loss 0.182063 Accuracy: 0.941733\n",
      ">> Epoch 1494 finished \tANN training loss 0.201335 Accuracy: 0.923193\n",
      ">> Epoch 1495 finished \tANN training loss 0.177817 Accuracy: 0.945895\n",
      ">> Epoch 1496 finished \tANN training loss 0.189081 Accuracy: 0.939084\n",
      ">> Epoch 1497 finished \tANN training loss 0.203253 Accuracy: 0.933031\n",
      ">> Epoch 1498 finished \tANN training loss 0.167843 Accuracy: 0.947408\n",
      ">> Epoch 1499 finished \tANN training loss 0.176407 Accuracy: 0.945895\n",
      ">> Epoch 1500 finished \tANN training loss 0.209177 Accuracy: 0.920545\n",
      ">> Epoch 1501 finished \tANN training loss 0.191353 Accuracy: 0.933787\n",
      ">> Epoch 1502 finished \tANN training loss 0.171747 Accuracy: 0.945138\n",
      ">> Epoch 1503 finished \tANN training loss 0.211820 Accuracy: 0.917518\n",
      ">> Epoch 1504 finished \tANN training loss 0.178128 Accuracy: 0.937193\n",
      ">> Epoch 1505 finished \tANN training loss 0.190378 Accuracy: 0.933787\n",
      ">> Epoch 1506 finished \tANN training loss 0.186652 Accuracy: 0.939841\n",
      ">> Epoch 1507 finished \tANN training loss 0.192159 Accuracy: 0.939463\n",
      ">> Epoch 1508 finished \tANN training loss 0.236049 Accuracy: 0.900114\n",
      ">> Epoch 1509 finished \tANN training loss 0.187972 Accuracy: 0.933787\n",
      ">> Epoch 1510 finished \tANN training loss 0.189764 Accuracy: 0.943246\n",
      ">> Epoch 1511 finished \tANN training loss 0.180940 Accuracy: 0.938706\n",
      ">> Epoch 1512 finished \tANN training loss 0.229314 Accuracy: 0.912599\n",
      ">> Epoch 1513 finished \tANN training loss 0.235309 Accuracy: 0.920545\n",
      ">> Epoch 1514 finished \tANN training loss 0.184431 Accuracy: 0.939084\n",
      ">> Epoch 1515 finished \tANN training loss 0.167144 Accuracy: 0.948543\n",
      ">> Epoch 1516 finished \tANN training loss 0.256979 Accuracy: 0.895573\n",
      ">> Epoch 1517 finished \tANN training loss 0.186704 Accuracy: 0.937949\n",
      ">> Epoch 1518 finished \tANN training loss 0.184866 Accuracy: 0.933409\n",
      ">> Epoch 1519 finished \tANN training loss 0.221964 Accuracy: 0.911086\n",
      ">> Epoch 1520 finished \tANN training loss 0.181065 Accuracy: 0.936814\n",
      ">> Epoch 1521 finished \tANN training loss 0.185004 Accuracy: 0.937571\n",
      ">> Epoch 1522 finished \tANN training loss 0.209042 Accuracy: 0.921302\n",
      ">> Epoch 1523 finished \tANN training loss 0.205592 Accuracy: 0.938706\n",
      ">> Epoch 1524 finished \tANN training loss 0.207806 Accuracy: 0.925842\n",
      ">> Epoch 1525 finished \tANN training loss 0.222438 Accuracy: 0.909572\n",
      ">> Epoch 1526 finished \tANN training loss 0.221769 Accuracy: 0.915248\n",
      ">> Epoch 1527 finished \tANN training loss 0.185161 Accuracy: 0.940219\n",
      ">> Epoch 1528 finished \tANN training loss 0.197391 Accuracy: 0.926977\n",
      ">> Epoch 1529 finished \tANN training loss 0.214747 Accuracy: 0.922815\n",
      ">> Epoch 1530 finished \tANN training loss 0.183515 Accuracy: 0.930760\n",
      ">> Epoch 1531 finished \tANN training loss 0.199481 Accuracy: 0.932274\n",
      ">> Epoch 1532 finished \tANN training loss 0.182626 Accuracy: 0.937949\n",
      ">> Epoch 1533 finished \tANN training loss 0.242214 Accuracy: 0.921302\n",
      ">> Epoch 1534 finished \tANN training loss 0.170323 Accuracy: 0.950813\n",
      ">> Epoch 1535 finished \tANN training loss 0.189064 Accuracy: 0.939463\n",
      ">> Epoch 1536 finished \tANN training loss 0.227955 Accuracy: 0.918275\n",
      ">> Epoch 1537 finished \tANN training loss 0.236392 Accuracy: 0.910708\n",
      ">> Epoch 1538 finished \tANN training loss 0.183179 Accuracy: 0.936814\n",
      ">> Epoch 1539 finished \tANN training loss 0.178807 Accuracy: 0.938328\n",
      ">> Epoch 1540 finished \tANN training loss 0.211720 Accuracy: 0.922815\n",
      ">> Epoch 1541 finished \tANN training loss 0.198297 Accuracy: 0.928112\n",
      ">> Epoch 1542 finished \tANN training loss 0.188395 Accuracy: 0.936814\n",
      ">> Epoch 1543 finished \tANN training loss 0.225851 Accuracy: 0.916005\n",
      ">> Epoch 1544 finished \tANN training loss 0.174509 Accuracy: 0.947408\n",
      ">> Epoch 1545 finished \tANN training loss 0.216347 Accuracy: 0.914491\n",
      ">> Epoch 1546 finished \tANN training loss 0.197766 Accuracy: 0.936058\n",
      ">> Epoch 1547 finished \tANN training loss 0.214172 Accuracy: 0.921302\n",
      ">> Epoch 1548 finished \tANN training loss 0.192576 Accuracy: 0.932652\n",
      ">> Epoch 1549 finished \tANN training loss 0.200690 Accuracy: 0.926599\n",
      ">> Epoch 1550 finished \tANN training loss 0.175531 Accuracy: 0.938706\n",
      ">> Epoch 1551 finished \tANN training loss 0.200368 Accuracy: 0.929625\n",
      ">> Epoch 1552 finished \tANN training loss 0.178752 Accuracy: 0.946652\n",
      ">> Epoch 1553 finished \tANN training loss 0.270216 Accuracy: 0.891411\n",
      ">> Epoch 1554 finished \tANN training loss 0.230275 Accuracy: 0.909572\n",
      ">> Epoch 1555 finished \tANN training loss 0.179928 Accuracy: 0.939463\n",
      ">> Epoch 1556 finished \tANN training loss 0.267957 Accuracy: 0.884979\n",
      ">> Epoch 1557 finished \tANN training loss 0.184305 Accuracy: 0.937193\n",
      ">> Epoch 1558 finished \tANN training loss 0.178692 Accuracy: 0.931139\n",
      ">> Epoch 1559 finished \tANN training loss 0.181301 Accuracy: 0.943246\n",
      ">> Epoch 1560 finished \tANN training loss 0.174820 Accuracy: 0.937193\n",
      ">> Epoch 1561 finished \tANN training loss 0.171779 Accuracy: 0.946652\n",
      ">> Epoch 1562 finished \tANN training loss 0.177318 Accuracy: 0.946652\n",
      ">> Epoch 1563 finished \tANN training loss 0.199672 Accuracy: 0.926599\n",
      ">> Epoch 1564 finished \tANN training loss 0.170598 Accuracy: 0.948165\n",
      ">> Epoch 1565 finished \tANN training loss 0.201165 Accuracy: 0.927355\n",
      ">> Epoch 1566 finished \tANN training loss 0.190132 Accuracy: 0.931517\n",
      ">> Epoch 1567 finished \tANN training loss 0.195207 Accuracy: 0.928490\n",
      ">> Epoch 1568 finished \tANN training loss 0.215843 Accuracy: 0.918653\n",
      ">> Epoch 1569 finished \tANN training loss 0.190765 Accuracy: 0.931896\n",
      ">> Epoch 1570 finished \tANN training loss 0.241525 Accuracy: 0.900870\n",
      ">> Epoch 1571 finished \tANN training loss 0.318089 Accuracy: 0.875899\n",
      ">> Epoch 1572 finished \tANN training loss 0.190057 Accuracy: 0.933031\n",
      ">> Epoch 1573 finished \tANN training loss 0.181076 Accuracy: 0.942111\n",
      ">> Epoch 1574 finished \tANN training loss 0.203504 Accuracy: 0.928490\n",
      ">> Epoch 1575 finished \tANN training loss 0.174255 Accuracy: 0.939841\n",
      ">> Epoch 1576 finished \tANN training loss 0.178644 Accuracy: 0.939463\n",
      ">> Epoch 1577 finished \tANN training loss 0.224146 Accuracy: 0.914869\n",
      ">> Epoch 1578 finished \tANN training loss 0.267403 Accuracy: 0.888006\n",
      ">> Epoch 1579 finished \tANN training loss 0.180483 Accuracy: 0.938706\n",
      ">> Epoch 1580 finished \tANN training loss 0.277818 Accuracy: 0.873250\n",
      ">> Epoch 1581 finished \tANN training loss 0.176657 Accuracy: 0.939841\n",
      ">> Epoch 1582 finished \tANN training loss 0.175548 Accuracy: 0.934544\n",
      ">> Epoch 1583 finished \tANN training loss 0.176959 Accuracy: 0.939084\n",
      ">> Epoch 1584 finished \tANN training loss 0.200760 Accuracy: 0.922058\n",
      ">> Epoch 1585 finished \tANN training loss 0.215456 Accuracy: 0.919410\n",
      ">> Epoch 1586 finished \tANN training loss 0.172408 Accuracy: 0.947030\n",
      ">> Epoch 1587 finished \tANN training loss 0.177441 Accuracy: 0.939084\n",
      ">> Epoch 1588 finished \tANN training loss 0.253228 Accuracy: 0.894438\n",
      ">> Epoch 1589 finished \tANN training loss 0.214682 Accuracy: 0.922437\n",
      ">> Epoch 1590 finished \tANN training loss 0.181562 Accuracy: 0.934166\n",
      ">> Epoch 1591 finished \tANN training loss 0.186850 Accuracy: 0.934544\n",
      ">> Epoch 1592 finished \tANN training loss 0.201851 Accuracy: 0.927734\n",
      ">> Epoch 1593 finished \tANN training loss 0.177643 Accuracy: 0.940598\n",
      ">> Epoch 1594 finished \tANN training loss 0.207533 Accuracy: 0.924707\n",
      ">> Epoch 1595 finished \tANN training loss 0.165628 Accuracy: 0.947408\n",
      ">> Epoch 1596 finished \tANN training loss 0.193041 Accuracy: 0.926599\n",
      ">> Epoch 1597 finished \tANN training loss 0.234991 Accuracy: 0.908816\n",
      ">> Epoch 1598 finished \tANN training loss 0.183292 Accuracy: 0.948543\n",
      ">> Epoch 1599 finished \tANN training loss 0.177427 Accuracy: 0.935679\n",
      ">> Epoch 1600 finished \tANN training loss 0.191993 Accuracy: 0.933409\n",
      ">> Epoch 1601 finished \tANN training loss 0.234635 Accuracy: 0.905032\n",
      ">> Epoch 1602 finished \tANN training loss 0.197567 Accuracy: 0.931896\n",
      ">> Epoch 1603 finished \tANN training loss 0.188868 Accuracy: 0.928869\n",
      ">> Epoch 1604 finished \tANN training loss 0.199982 Accuracy: 0.926977\n",
      ">> Epoch 1605 finished \tANN training loss 0.197250 Accuracy: 0.931139\n",
      ">> Epoch 1606 finished \tANN training loss 0.168136 Accuracy: 0.951949\n",
      ">> Epoch 1607 finished \tANN training loss 0.203469 Accuracy: 0.928112\n",
      ">> Epoch 1608 finished \tANN training loss 0.192603 Accuracy: 0.925842\n",
      ">> Epoch 1609 finished \tANN training loss 0.179927 Accuracy: 0.939463\n",
      ">> Epoch 1610 finished \tANN training loss 0.256071 Accuracy: 0.896708\n",
      ">> Epoch 1611 finished \tANN training loss 0.222966 Accuracy: 0.910708\n",
      ">> Epoch 1612 finished \tANN training loss 0.180886 Accuracy: 0.940219\n",
      ">> Epoch 1613 finished \tANN training loss 0.173863 Accuracy: 0.940976\n",
      ">> Epoch 1614 finished \tANN training loss 0.258389 Accuracy: 0.907302\n",
      ">> Epoch 1615 finished \tANN training loss 0.215254 Accuracy: 0.913356\n",
      ">> Epoch 1616 finished \tANN training loss 0.174061 Accuracy: 0.943625\n",
      ">> Epoch 1617 finished \tANN training loss 0.193612 Accuracy: 0.934922\n",
      ">> Epoch 1618 finished \tANN training loss 0.174271 Accuracy: 0.937949\n",
      ">> Epoch 1619 finished \tANN training loss 0.217324 Accuracy: 0.915626\n",
      ">> Epoch 1620 finished \tANN training loss 0.201866 Accuracy: 0.925463\n",
      ">> Epoch 1621 finished \tANN training loss 0.297748 Accuracy: 0.887628\n",
      ">> Epoch 1622 finished \tANN training loss 0.183862 Accuracy: 0.945138\n",
      ">> Epoch 1623 finished \tANN training loss 0.210906 Accuracy: 0.928112\n",
      ">> Epoch 1624 finished \tANN training loss 0.177606 Accuracy: 0.942868\n",
      ">> Epoch 1625 finished \tANN training loss 0.315393 Accuracy: 0.869088\n",
      ">> Epoch 1626 finished \tANN training loss 0.432165 Accuracy: 0.864170\n",
      ">> Epoch 1627 finished \tANN training loss 0.157234 Accuracy: 0.943246\n",
      ">> Epoch 1628 finished \tANN training loss 0.174971 Accuracy: 0.939463\n",
      ">> Epoch 1629 finished \tANN training loss 0.161319 Accuracy: 0.949678\n",
      ">> Epoch 1630 finished \tANN training loss 0.182614 Accuracy: 0.941355\n",
      ">> Epoch 1631 finished \tANN training loss 0.175730 Accuracy: 0.937949\n",
      ">> Epoch 1632 finished \tANN training loss 0.195458 Accuracy: 0.928869\n",
      ">> Epoch 1633 finished \tANN training loss 0.187291 Accuracy: 0.932274\n",
      ">> Epoch 1634 finished \tANN training loss 0.181797 Accuracy: 0.940976\n",
      ">> Epoch 1635 finished \tANN training loss 0.165177 Accuracy: 0.947030\n",
      ">> Epoch 1636 finished \tANN training loss 0.194491 Accuracy: 0.933031\n",
      ">> Epoch 1637 finished \tANN training loss 0.188854 Accuracy: 0.934166\n",
      ">> Epoch 1638 finished \tANN training loss 0.205440 Accuracy: 0.926977\n",
      ">> Epoch 1639 finished \tANN training loss 0.166467 Accuracy: 0.944760\n",
      ">> Epoch 1640 finished \tANN training loss 0.277901 Accuracy: 0.880817\n",
      ">> Epoch 1641 finished \tANN training loss 0.184535 Accuracy: 0.937571\n",
      ">> Epoch 1642 finished \tANN training loss 0.178886 Accuracy: 0.932652\n",
      ">> Epoch 1643 finished \tANN training loss 0.246973 Accuracy: 0.910708\n",
      ">> Epoch 1644 finished \tANN training loss 0.181567 Accuracy: 0.948922\n",
      ">> Epoch 1645 finished \tANN training loss 0.345461 Accuracy: 0.857737\n",
      ">> Epoch 1646 finished \tANN training loss 0.178862 Accuracy: 0.946652\n",
      ">> Epoch 1647 finished \tANN training loss 0.198013 Accuracy: 0.946652\n",
      ">> Epoch 1648 finished \tANN training loss 0.197655 Accuracy: 0.928490\n",
      ">> Epoch 1649 finished \tANN training loss 0.193485 Accuracy: 0.926977\n",
      ">> Epoch 1650 finished \tANN training loss 0.217182 Accuracy: 0.924328\n",
      ">> Epoch 1651 finished \tANN training loss 0.191224 Accuracy: 0.932274\n",
      ">> Epoch 1652 finished \tANN training loss 0.162481 Accuracy: 0.951570\n",
      ">> Epoch 1653 finished \tANN training loss 0.226693 Accuracy: 0.911086\n",
      ">> Epoch 1654 finished \tANN training loss 0.225729 Accuracy: 0.913356\n",
      ">> Epoch 1655 finished \tANN training loss 0.180248 Accuracy: 0.934922\n",
      ">> Epoch 1656 finished \tANN training loss 0.197704 Accuracy: 0.915626\n",
      ">> Epoch 1657 finished \tANN training loss 0.168780 Accuracy: 0.945895\n",
      ">> Epoch 1658 finished \tANN training loss 0.204595 Accuracy: 0.926220\n",
      ">> Epoch 1659 finished \tANN training loss 0.210656 Accuracy: 0.918275\n",
      ">> Epoch 1660 finished \tANN training loss 0.226910 Accuracy: 0.921302\n",
      ">> Epoch 1661 finished \tANN training loss 0.184582 Accuracy: 0.941355\n",
      ">> Epoch 1662 finished \tANN training loss 0.215807 Accuracy: 0.909194\n",
      ">> Epoch 1663 finished \tANN training loss 0.177963 Accuracy: 0.938328\n",
      ">> Epoch 1664 finished \tANN training loss 0.194785 Accuracy: 0.929247\n",
      ">> Epoch 1665 finished \tANN training loss 0.175998 Accuracy: 0.936436\n",
      ">> Epoch 1666 finished \tANN training loss 0.219748 Accuracy: 0.918275\n",
      ">> Epoch 1667 finished \tANN training loss 0.186197 Accuracy: 0.937949\n",
      ">> Epoch 1668 finished \tANN training loss 0.194308 Accuracy: 0.931139\n",
      ">> Epoch 1669 finished \tANN training loss 0.183385 Accuracy: 0.935301\n",
      ">> Epoch 1670 finished \tANN training loss 0.187770 Accuracy: 0.930382\n",
      ">> Epoch 1671 finished \tANN training loss 0.182358 Accuracy: 0.936436\n",
      ">> Epoch 1672 finished \tANN training loss 0.186136 Accuracy: 0.930382\n",
      ">> Epoch 1673 finished \tANN training loss 0.197328 Accuracy: 0.931139\n",
      ">> Epoch 1674 finished \tANN training loss 0.166118 Accuracy: 0.948165\n",
      ">> Epoch 1675 finished \tANN training loss 0.190554 Accuracy: 0.942490\n",
      ">> Epoch 1676 finished \tANN training loss 0.177421 Accuracy: 0.942111\n",
      ">> Epoch 1677 finished \tANN training loss 0.182031 Accuracy: 0.933031\n",
      ">> Epoch 1678 finished \tANN training loss 0.210006 Accuracy: 0.925842\n",
      ">> Epoch 1679 finished \tANN training loss 0.179202 Accuracy: 0.948922\n",
      ">> Epoch 1680 finished \tANN training loss 0.220454 Accuracy: 0.919410\n",
      ">> Epoch 1681 finished \tANN training loss 0.183264 Accuracy: 0.932652\n",
      ">> Epoch 1682 finished \tANN training loss 0.174424 Accuracy: 0.945138\n",
      ">> Epoch 1683 finished \tANN training loss 0.262603 Accuracy: 0.892546\n",
      ">> Epoch 1684 finished \tANN training loss 0.182222 Accuracy: 0.933409\n",
      ">> Epoch 1685 finished \tANN training loss 0.189673 Accuracy: 0.934166\n",
      ">> Epoch 1686 finished \tANN training loss 0.223510 Accuracy: 0.913356\n",
      ">> Epoch 1687 finished \tANN training loss 0.181085 Accuracy: 0.931139\n",
      ">> Epoch 1688 finished \tANN training loss 0.195903 Accuracy: 0.932652\n",
      ">> Epoch 1689 finished \tANN training loss 0.194280 Accuracy: 0.930382\n",
      ">> Epoch 1690 finished \tANN training loss 0.184096 Accuracy: 0.934544\n",
      ">> Epoch 1691 finished \tANN training loss 0.165951 Accuracy: 0.944381\n",
      ">> Epoch 1692 finished \tANN training loss 0.182038 Accuracy: 0.933787\n",
      ">> Epoch 1693 finished \tANN training loss 0.215437 Accuracy: 0.928112\n",
      ">> Epoch 1694 finished \tANN training loss 0.204092 Accuracy: 0.920923\n",
      ">> Epoch 1695 finished \tANN training loss 0.198146 Accuracy: 0.935301\n",
      ">> Epoch 1696 finished \tANN training loss 0.180673 Accuracy: 0.943625\n",
      ">> Epoch 1697 finished \tANN training loss 0.179410 Accuracy: 0.933031\n",
      ">> Epoch 1698 finished \tANN training loss 0.204447 Accuracy: 0.927355\n",
      ">> Epoch 1699 finished \tANN training loss 0.208610 Accuracy: 0.918275\n",
      ">> Epoch 1700 finished \tANN training loss 0.203007 Accuracy: 0.928112\n",
      ">> Epoch 1701 finished \tANN training loss 0.166547 Accuracy: 0.944381\n",
      ">> Epoch 1702 finished \tANN training loss 0.189611 Accuracy: 0.941733\n",
      ">> Epoch 1703 finished \tANN training loss 0.213502 Accuracy: 0.923572\n",
      ">> Epoch 1704 finished \tANN training loss 0.244331 Accuracy: 0.899735\n",
      ">> Epoch 1705 finished \tANN training loss 0.206007 Accuracy: 0.926977\n",
      ">> Epoch 1706 finished \tANN training loss 0.243855 Accuracy: 0.905032\n",
      ">> Epoch 1707 finished \tANN training loss 0.209586 Accuracy: 0.920923\n",
      ">> Epoch 1708 finished \tANN training loss 0.175397 Accuracy: 0.937193\n",
      ">> Epoch 1709 finished \tANN training loss 0.243247 Accuracy: 0.905032\n",
      ">> Epoch 1710 finished \tANN training loss 0.166251 Accuracy: 0.949678\n",
      ">> Epoch 1711 finished \tANN training loss 0.219211 Accuracy: 0.918653\n",
      ">> Epoch 1712 finished \tANN training loss 0.203333 Accuracy: 0.922815\n",
      ">> Epoch 1713 finished \tANN training loss 0.175534 Accuracy: 0.943246\n",
      ">> Epoch 1714 finished \tANN training loss 0.174073 Accuracy: 0.946652\n",
      ">> Epoch 1715 finished \tANN training loss 0.165200 Accuracy: 0.943246\n",
      ">> Epoch 1716 finished \tANN training loss 0.181944 Accuracy: 0.930760\n",
      ">> Epoch 1717 finished \tANN training loss 0.204373 Accuracy: 0.914869\n",
      ">> Epoch 1718 finished \tANN training loss 0.181653 Accuracy: 0.933031\n",
      ">> Epoch 1719 finished \tANN training loss 0.231615 Accuracy: 0.923950\n",
      ">> Epoch 1720 finished \tANN training loss 0.159984 Accuracy: 0.940976\n",
      ">> Epoch 1721 finished \tANN training loss 0.175011 Accuracy: 0.945516\n",
      ">> Epoch 1722 finished \tANN training loss 0.217351 Accuracy: 0.918275\n",
      ">> Epoch 1723 finished \tANN training loss 0.192125 Accuracy: 0.942868\n",
      ">> Epoch 1724 finished \tANN training loss 0.209439 Accuracy: 0.920166\n",
      ">> Epoch 1725 finished \tANN training loss 0.195227 Accuracy: 0.926220\n",
      ">> Epoch 1726 finished \tANN training loss 0.274525 Accuracy: 0.891790\n",
      ">> Epoch 1727 finished \tANN training loss 0.170921 Accuracy: 0.933031\n",
      ">> Epoch 1728 finished \tANN training loss 0.238691 Accuracy: 0.904275\n",
      ">> Epoch 1729 finished \tANN training loss 0.181846 Accuracy: 0.932274\n",
      ">> Epoch 1730 finished \tANN training loss 0.172416 Accuracy: 0.947787\n",
      ">> Epoch 1731 finished \tANN training loss 0.171016 Accuracy: 0.950057\n",
      ">> Epoch 1732 finished \tANN training loss 0.197026 Accuracy: 0.934922\n",
      ">> Epoch 1733 finished \tANN training loss 0.270756 Accuracy: 0.884979\n",
      ">> Epoch 1734 finished \tANN training loss 0.276636 Accuracy: 0.900870\n",
      ">> Epoch 1735 finished \tANN training loss 0.206254 Accuracy: 0.932652\n",
      ">> Epoch 1736 finished \tANN training loss 0.202959 Accuracy: 0.926977\n",
      ">> Epoch 1737 finished \tANN training loss 0.198655 Accuracy: 0.925842\n",
      ">> Epoch 1738 finished \tANN training loss 0.214870 Accuracy: 0.919788\n",
      ">> Epoch 1739 finished \tANN training loss 0.215708 Accuracy: 0.931517\n",
      ">> Epoch 1740 finished \tANN training loss 0.189670 Accuracy: 0.933031\n",
      ">> Epoch 1741 finished \tANN training loss 0.195928 Accuracy: 0.937949\n",
      ">> Epoch 1742 finished \tANN training loss 0.221453 Accuracy: 0.925463\n",
      ">> Epoch 1743 finished \tANN training loss 0.191817 Accuracy: 0.929247\n",
      ">> Epoch 1744 finished \tANN training loss 0.216071 Accuracy: 0.925085\n",
      ">> Epoch 1745 finished \tANN training loss 0.171035 Accuracy: 0.946652\n",
      ">> Epoch 1746 finished \tANN training loss 0.186784 Accuracy: 0.940219\n",
      ">> Epoch 1747 finished \tANN training loss 0.174753 Accuracy: 0.938328\n",
      ">> Epoch 1748 finished \tANN training loss 0.236272 Accuracy: 0.905032\n",
      ">> Epoch 1749 finished \tANN training loss 0.198681 Accuracy: 0.930004\n",
      ">> Epoch 1750 finished \tANN training loss 0.174965 Accuracy: 0.940976\n",
      ">> Epoch 1751 finished \tANN training loss 0.180190 Accuracy: 0.930760\n",
      ">> Epoch 1752 finished \tANN training loss 0.208866 Accuracy: 0.928490\n",
      ">> Epoch 1753 finished \tANN training loss 0.193567 Accuracy: 0.929625\n",
      ">> Epoch 1754 finished \tANN training loss 0.172229 Accuracy: 0.939084\n",
      ">> Epoch 1755 finished \tANN training loss 0.200489 Accuracy: 0.929247\n",
      ">> Epoch 1756 finished \tANN training loss 0.188177 Accuracy: 0.938328\n",
      ">> Epoch 1757 finished \tANN training loss 0.222737 Accuracy: 0.914869\n",
      ">> Epoch 1758 finished \tANN training loss 0.166633 Accuracy: 0.944003\n",
      ">> Epoch 1759 finished \tANN training loss 0.169848 Accuracy: 0.945895\n",
      ">> Epoch 1760 finished \tANN training loss 0.177197 Accuracy: 0.941733\n",
      ">> Epoch 1761 finished \tANN training loss 0.176652 Accuracy: 0.934922\n",
      ">> Epoch 1762 finished \tANN training loss 0.173539 Accuracy: 0.943625\n",
      ">> Epoch 1763 finished \tANN training loss 0.197113 Accuracy: 0.922815\n",
      ">> Epoch 1764 finished \tANN training loss 0.165625 Accuracy: 0.941355\n",
      ">> Epoch 1765 finished \tANN training loss 0.210895 Accuracy: 0.916005\n",
      ">> Epoch 1766 finished \tANN training loss 0.244580 Accuracy: 0.911843\n",
      ">> Epoch 1767 finished \tANN training loss 0.182152 Accuracy: 0.930382\n",
      ">> Epoch 1768 finished \tANN training loss 0.161476 Accuracy: 0.948543\n",
      ">> Epoch 1769 finished \tANN training loss 0.291778 Accuracy: 0.858872\n",
      ">> Epoch 1770 finished \tANN training loss 0.221849 Accuracy: 0.920545\n",
      ">> Epoch 1771 finished \tANN training loss 0.192805 Accuracy: 0.928112\n",
      ">> Epoch 1772 finished \tANN training loss 0.179561 Accuracy: 0.930382\n",
      ">> Epoch 1773 finished \tANN training loss 0.185327 Accuracy: 0.945516\n",
      ">> Epoch 1774 finished \tANN training loss 0.215925 Accuracy: 0.923572\n",
      ">> Epoch 1775 finished \tANN training loss 0.205961 Accuracy: 0.932652\n",
      ">> Epoch 1776 finished \tANN training loss 0.189084 Accuracy: 0.934544\n",
      ">> Epoch 1777 finished \tANN training loss 0.182908 Accuracy: 0.933031\n",
      ">> Epoch 1778 finished \tANN training loss 0.178620 Accuracy: 0.938328\n",
      ">> Epoch 1779 finished \tANN training loss 0.172569 Accuracy: 0.944003\n",
      ">> Epoch 1780 finished \tANN training loss 0.166477 Accuracy: 0.938328\n",
      ">> Epoch 1781 finished \tANN training loss 0.235823 Accuracy: 0.906924\n",
      ">> Epoch 1782 finished \tANN training loss 0.224779 Accuracy: 0.919788\n",
      ">> Epoch 1783 finished \tANN training loss 0.198437 Accuracy: 0.931517\n",
      ">> Epoch 1784 finished \tANN training loss 0.191876 Accuracy: 0.943246\n",
      ">> Epoch 1785 finished \tANN training loss 0.233813 Accuracy: 0.917896\n",
      ">> Epoch 1786 finished \tANN training loss 0.208305 Accuracy: 0.935301\n",
      ">> Epoch 1787 finished \tANN training loss 0.173797 Accuracy: 0.942490\n",
      ">> Epoch 1788 finished \tANN training loss 0.189567 Accuracy: 0.928490\n",
      ">> Epoch 1789 finished \tANN training loss 0.188365 Accuracy: 0.932652\n",
      ">> Epoch 1790 finished \tANN training loss 0.188406 Accuracy: 0.931139\n",
      ">> Epoch 1791 finished \tANN training loss 0.187813 Accuracy: 0.928869\n",
      ">> Epoch 1792 finished \tANN training loss 0.281066 Accuracy: 0.883844\n",
      ">> Epoch 1793 finished \tANN training loss 0.171685 Accuracy: 0.941355\n",
      ">> Epoch 1794 finished \tANN training loss 0.213967 Accuracy: 0.913734\n",
      ">> Epoch 1795 finished \tANN training loss 0.184094 Accuracy: 0.936058\n",
      ">> Epoch 1796 finished \tANN training loss 0.183241 Accuracy: 0.935679\n",
      ">> Epoch 1797 finished \tANN training loss 0.180742 Accuracy: 0.934544\n",
      ">> Epoch 1798 finished \tANN training loss 0.188333 Accuracy: 0.937193\n",
      ">> Epoch 1799 finished \tANN training loss 0.250053 Accuracy: 0.901249\n",
      ">> Epoch 1800 finished \tANN training loss 0.174814 Accuracy: 0.940598\n",
      ">> Epoch 1801 finished \tANN training loss 0.162665 Accuracy: 0.945138\n",
      ">> Epoch 1802 finished \tANN training loss 0.256224 Accuracy: 0.895195\n",
      ">> Epoch 1803 finished \tANN training loss 0.247457 Accuracy: 0.893681\n",
      ">> Epoch 1804 finished \tANN training loss 0.179011 Accuracy: 0.930382\n",
      ">> Epoch 1805 finished \tANN training loss 0.167714 Accuracy: 0.947030\n",
      ">> Epoch 1806 finished \tANN training loss 0.258288 Accuracy: 0.889141\n",
      ">> Epoch 1807 finished \tANN training loss 0.251632 Accuracy: 0.892168\n",
      ">> Epoch 1808 finished \tANN training loss 0.175777 Accuracy: 0.938328\n",
      ">> Epoch 1809 finished \tANN training loss 0.164346 Accuracy: 0.948922\n",
      ">> Epoch 1810 finished \tANN training loss 0.206717 Accuracy: 0.926977\n",
      ">> Epoch 1811 finished \tANN training loss 0.195104 Accuracy: 0.939084\n",
      ">> Epoch 1812 finished \tANN training loss 0.328345 Accuracy: 0.893303\n",
      ">> Epoch 1813 finished \tANN training loss 0.197065 Accuracy: 0.925463\n",
      ">> Epoch 1814 finished \tANN training loss 0.212840 Accuracy: 0.920923\n",
      ">> Epoch 1815 finished \tANN training loss 0.198215 Accuracy: 0.929247\n",
      ">> Epoch 1816 finished \tANN training loss 0.177871 Accuracy: 0.940598\n",
      ">> Epoch 1817 finished \tANN training loss 0.165431 Accuracy: 0.943625\n",
      ">> Epoch 1818 finished \tANN training loss 0.179858 Accuracy: 0.941733\n",
      ">> Epoch 1819 finished \tANN training loss 0.188577 Accuracy: 0.932274\n",
      ">> Epoch 1820 finished \tANN training loss 0.172943 Accuracy: 0.943625\n",
      ">> Epoch 1821 finished \tANN training loss 0.165224 Accuracy: 0.940219\n",
      ">> Epoch 1822 finished \tANN training loss 0.178001 Accuracy: 0.937193\n",
      ">> Epoch 1823 finished \tANN training loss 0.178226 Accuracy: 0.936436\n",
      ">> Epoch 1824 finished \tANN training loss 0.184317 Accuracy: 0.934166\n",
      ">> Epoch 1825 finished \tANN training loss 0.166758 Accuracy: 0.938706\n",
      ">> Epoch 1826 finished \tANN training loss 0.220166 Accuracy: 0.908816\n",
      ">> Epoch 1827 finished \tANN training loss 0.205494 Accuracy: 0.921680\n",
      ">> Epoch 1828 finished \tANN training loss 0.201985 Accuracy: 0.922437\n",
      ">> Epoch 1829 finished \tANN training loss 0.194352 Accuracy: 0.926599\n",
      ">> Epoch 1830 finished \tANN training loss 0.208959 Accuracy: 0.924328\n",
      ">> Epoch 1831 finished \tANN training loss 0.172244 Accuracy: 0.937193\n",
      ">> Epoch 1832 finished \tANN training loss 0.157274 Accuracy: 0.940976\n",
      ">> Epoch 1833 finished \tANN training loss 0.173429 Accuracy: 0.943246\n",
      ">> Epoch 1834 finished \tANN training loss 0.152248 Accuracy: 0.951949\n",
      ">> Epoch 1835 finished \tANN training loss 0.200688 Accuracy: 0.928112\n",
      ">> Epoch 1836 finished \tANN training loss 0.258465 Accuracy: 0.893681\n",
      ">> Epoch 1837 finished \tANN training loss 0.230808 Accuracy: 0.901627\n",
      ">> Epoch 1838 finished \tANN training loss 0.168314 Accuracy: 0.949678\n",
      ">> Epoch 1839 finished \tANN training loss 0.171214 Accuracy: 0.945138\n",
      ">> Epoch 1840 finished \tANN training loss 0.196726 Accuracy: 0.928869\n",
      ">> Epoch 1841 finished \tANN training loss 0.190743 Accuracy: 0.931896\n",
      ">> Epoch 1842 finished \tANN training loss 0.191825 Accuracy: 0.931896\n",
      ">> Epoch 1843 finished \tANN training loss 0.186825 Accuracy: 0.929247\n",
      ">> Epoch 1844 finished \tANN training loss 0.176355 Accuracy: 0.935679\n",
      ">> Epoch 1845 finished \tANN training loss 0.202554 Accuracy: 0.928112\n",
      ">> Epoch 1846 finished \tANN training loss 0.181306 Accuracy: 0.935679\n",
      ">> Epoch 1847 finished \tANN training loss 0.180582 Accuracy: 0.935301\n",
      ">> Epoch 1848 finished \tANN training loss 0.220486 Accuracy: 0.914113\n",
      ">> Epoch 1849 finished \tANN training loss 0.269735 Accuracy: 0.883466\n",
      ">> Epoch 1850 finished \tANN training loss 0.200642 Accuracy: 0.933409\n",
      ">> Epoch 1851 finished \tANN training loss 0.240208 Accuracy: 0.901249\n",
      ">> Epoch 1852 finished \tANN training loss 0.189701 Accuracy: 0.930004\n",
      ">> Epoch 1853 finished \tANN training loss 0.187196 Accuracy: 0.930760\n",
      ">> Epoch 1854 finished \tANN training loss 0.183381 Accuracy: 0.929247\n",
      ">> Epoch 1855 finished \tANN training loss 0.183837 Accuracy: 0.931139\n",
      ">> Epoch 1856 finished \tANN training loss 0.169241 Accuracy: 0.937193\n",
      ">> Epoch 1857 finished \tANN training loss 0.166895 Accuracy: 0.941355\n",
      ">> Epoch 1858 finished \tANN training loss 0.185742 Accuracy: 0.929625\n",
      ">> Epoch 1859 finished \tANN training loss 0.200390 Accuracy: 0.931517\n",
      ">> Epoch 1860 finished \tANN training loss 0.176748 Accuracy: 0.936436\n",
      ">> Epoch 1861 finished \tANN training loss 0.221920 Accuracy: 0.916761\n",
      ">> Epoch 1862 finished \tANN training loss 0.167814 Accuracy: 0.936814\n",
      ">> Epoch 1863 finished \tANN training loss 0.183673 Accuracy: 0.932274\n",
      ">> Epoch 1864 finished \tANN training loss 0.179040 Accuracy: 0.937193\n",
      ">> Epoch 1865 finished \tANN training loss 0.187265 Accuracy: 0.937949\n",
      ">> Epoch 1866 finished \tANN training loss 0.195959 Accuracy: 0.926977\n",
      ">> Epoch 1867 finished \tANN training loss 0.206338 Accuracy: 0.914869\n",
      ">> Epoch 1868 finished \tANN training loss 0.152200 Accuracy: 0.949678\n",
      ">> Epoch 1869 finished \tANN training loss 0.228160 Accuracy: 0.908437\n",
      ">> Epoch 1870 finished \tANN training loss 0.266612 Accuracy: 0.894816\n",
      ">> Epoch 1871 finished \tANN training loss 0.275547 Accuracy: 0.890276\n",
      ">> Epoch 1872 finished \tANN training loss 0.174487 Accuracy: 0.936814\n",
      ">> Epoch 1873 finished \tANN training loss 0.186031 Accuracy: 0.944003\n",
      ">> Epoch 1874 finished \tANN training loss 0.187291 Accuracy: 0.938706\n",
      ">> Epoch 1875 finished \tANN training loss 0.245052 Accuracy: 0.906546\n",
      ">> Epoch 1876 finished \tANN training loss 0.225718 Accuracy: 0.919788\n",
      ">> Epoch 1877 finished \tANN training loss 0.167656 Accuracy: 0.942111\n",
      ">> Epoch 1878 finished \tANN training loss 0.177388 Accuracy: 0.935301\n",
      ">> Epoch 1879 finished \tANN training loss 0.220962 Accuracy: 0.920545\n",
      ">> Epoch 1880 finished \tANN training loss 0.184681 Accuracy: 0.937193\n",
      ">> Epoch 1881 finished \tANN training loss 0.175927 Accuracy: 0.936436\n",
      ">> Epoch 1882 finished \tANN training loss 0.261379 Accuracy: 0.895195\n",
      ">> Epoch 1883 finished \tANN training loss 0.213298 Accuracy: 0.909572\n",
      ">> Epoch 1884 finished \tANN training loss 0.178388 Accuracy: 0.945138\n",
      ">> Epoch 1885 finished \tANN training loss 0.183250 Accuracy: 0.942111\n",
      ">> Epoch 1886 finished \tANN training loss 0.219233 Accuracy: 0.917518\n",
      ">> Epoch 1887 finished \tANN training loss 0.168833 Accuracy: 0.942490\n",
      ">> Epoch 1888 finished \tANN training loss 0.172261 Accuracy: 0.937949\n",
      ">> Epoch 1889 finished \tANN training loss 0.177368 Accuracy: 0.939084\n",
      ">> Epoch 1890 finished \tANN training loss 0.162710 Accuracy: 0.951192\n",
      ">> Epoch 1891 finished \tANN training loss 0.292337 Accuracy: 0.894060\n",
      ">> Epoch 1892 finished \tANN training loss 0.175923 Accuracy: 0.942490\n",
      ">> Epoch 1893 finished \tANN training loss 0.180697 Accuracy: 0.937571\n",
      ">> Epoch 1894 finished \tANN training loss 0.200769 Accuracy: 0.930004\n",
      ">> Epoch 1895 finished \tANN training loss 0.173544 Accuracy: 0.938328\n",
      ">> Epoch 1896 finished \tANN training loss 0.211953 Accuracy: 0.923572\n",
      ">> Epoch 1897 finished \tANN training loss 0.165633 Accuracy: 0.945138\n",
      ">> Epoch 1898 finished \tANN training loss 0.164284 Accuracy: 0.949678\n",
      ">> Epoch 1899 finished \tANN training loss 0.164749 Accuracy: 0.950435\n",
      ">> Epoch 1900 finished \tANN training loss 0.194831 Accuracy: 0.937949\n",
      ">> Epoch 1901 finished \tANN training loss 0.208782 Accuracy: 0.930382\n",
      ">> Epoch 1902 finished \tANN training loss 0.201321 Accuracy: 0.932274\n",
      ">> Epoch 1903 finished \tANN training loss 0.203749 Accuracy: 0.924328\n",
      ">> Epoch 1904 finished \tANN training loss 0.215149 Accuracy: 0.915626\n",
      ">> Epoch 1905 finished \tANN training loss 0.191499 Accuracy: 0.939084\n",
      ">> Epoch 1906 finished \tANN training loss 0.179256 Accuracy: 0.949300\n",
      ">> Epoch 1907 finished \tANN training loss 0.162242 Accuracy: 0.953084\n",
      ">> Epoch 1908 finished \tANN training loss 0.197337 Accuracy: 0.929625\n",
      ">> Epoch 1909 finished \tANN training loss 0.215540 Accuracy: 0.924707\n",
      ">> Epoch 1910 finished \tANN training loss 0.180316 Accuracy: 0.929247\n",
      ">> Epoch 1911 finished \tANN training loss 0.207312 Accuracy: 0.926599\n",
      ">> Epoch 1912 finished \tANN training loss 0.202312 Accuracy: 0.931896\n",
      ">> Epoch 1913 finished \tANN training loss 0.224395 Accuracy: 0.909194\n",
      ">> Epoch 1914 finished \tANN training loss 0.210891 Accuracy: 0.920545\n",
      ">> Epoch 1915 finished \tANN training loss 0.183556 Accuracy: 0.933409\n",
      ">> Epoch 1916 finished \tANN training loss 0.171660 Accuracy: 0.940219\n",
      ">> Epoch 1917 finished \tANN training loss 0.188697 Accuracy: 0.927355\n",
      ">> Epoch 1918 finished \tANN training loss 0.180073 Accuracy: 0.939084\n",
      ">> Epoch 1919 finished \tANN training loss 0.195170 Accuracy: 0.931517\n",
      ">> Epoch 1920 finished \tANN training loss 0.215920 Accuracy: 0.909194\n",
      ">> Epoch 1921 finished \tANN training loss 0.237997 Accuracy: 0.908437\n",
      ">> Epoch 1922 finished \tANN training loss 0.171742 Accuracy: 0.940976\n",
      ">> Epoch 1923 finished \tANN training loss 0.189960 Accuracy: 0.931896\n",
      ">> Epoch 1924 finished \tANN training loss 0.197627 Accuracy: 0.932274\n",
      ">> Epoch 1925 finished \tANN training loss 0.172626 Accuracy: 0.944381\n",
      ">> Epoch 1926 finished \tANN training loss 0.172808 Accuracy: 0.940598\n",
      ">> Epoch 1927 finished \tANN training loss 0.173405 Accuracy: 0.948543\n",
      ">> Epoch 1928 finished \tANN training loss 0.177610 Accuracy: 0.939084\n",
      ">> Epoch 1929 finished \tANN training loss 0.235733 Accuracy: 0.913356\n",
      ">> Epoch 1930 finished \tANN training loss 0.184550 Accuracy: 0.934544\n",
      ">> Epoch 1931 finished \tANN training loss 0.242001 Accuracy: 0.912978\n",
      ">> Epoch 1932 finished \tANN training loss 0.167181 Accuracy: 0.941733\n",
      ">> Epoch 1933 finished \tANN training loss 0.177457 Accuracy: 0.940976\n",
      ">> Epoch 1934 finished \tANN training loss 0.178178 Accuracy: 0.933787\n",
      ">> Epoch 1935 finished \tANN training loss 0.188711 Accuracy: 0.934922\n",
      ">> Epoch 1936 finished \tANN training loss 0.192757 Accuracy: 0.930004\n",
      ">> Epoch 1937 finished \tANN training loss 0.164560 Accuracy: 0.945895\n",
      ">> Epoch 1938 finished \tANN training loss 0.197380 Accuracy: 0.923572\n",
      ">> Epoch 1939 finished \tANN training loss 0.167027 Accuracy: 0.939841\n",
      ">> Epoch 1940 finished \tANN training loss 0.186758 Accuracy: 0.936814\n",
      ">> Epoch 1941 finished \tANN training loss 0.167822 Accuracy: 0.944003\n",
      ">> Epoch 1942 finished \tANN training loss 0.177586 Accuracy: 0.941733\n",
      ">> Epoch 1943 finished \tANN training loss 0.210037 Accuracy: 0.923572\n",
      ">> Epoch 1944 finished \tANN training loss 0.272711 Accuracy: 0.885736\n",
      ">> Epoch 1945 finished \tANN training loss 0.208452 Accuracy: 0.928869\n",
      ">> Epoch 1946 finished \tANN training loss 0.164365 Accuracy: 0.940976\n",
      ">> Epoch 1947 finished \tANN training loss 0.163605 Accuracy: 0.941733\n",
      ">> Epoch 1948 finished \tANN training loss 0.157591 Accuracy: 0.944760\n",
      ">> Epoch 1949 finished \tANN training loss 0.211045 Accuracy: 0.916383\n",
      ">> Epoch 1950 finished \tANN training loss 0.262897 Accuracy: 0.897843\n",
      ">> Epoch 1951 finished \tANN training loss 0.172740 Accuracy: 0.943246\n",
      ">> Epoch 1952 finished \tANN training loss 0.202663 Accuracy: 0.926599\n",
      ">> Epoch 1953 finished \tANN training loss 0.189908 Accuracy: 0.929625\n",
      ">> Epoch 1954 finished \tANN training loss 0.203279 Accuracy: 0.929247\n",
      ">> Epoch 1955 finished \tANN training loss 0.152960 Accuracy: 0.948165\n",
      ">> Epoch 1956 finished \tANN training loss 0.170206 Accuracy: 0.940976\n",
      ">> Epoch 1957 finished \tANN training loss 0.188595 Accuracy: 0.931517\n",
      ">> Epoch 1958 finished \tANN training loss 0.180658 Accuracy: 0.937571\n",
      ">> Epoch 1959 finished \tANN training loss 0.166225 Accuracy: 0.941733\n",
      ">> Epoch 1960 finished \tANN training loss 0.168713 Accuracy: 0.937193\n",
      ">> Epoch 1961 finished \tANN training loss 0.195948 Accuracy: 0.931896\n",
      ">> Epoch 1962 finished \tANN training loss 0.150081 Accuracy: 0.945138\n",
      ">> Epoch 1963 finished \tANN training loss 0.220928 Accuracy: 0.922437\n",
      ">> Epoch 1964 finished \tANN training loss 0.278861 Accuracy: 0.874764\n",
      ">> Epoch 1965 finished \tANN training loss 0.170025 Accuracy: 0.941733\n",
      ">> Epoch 1966 finished \tANN training loss 0.175322 Accuracy: 0.942490\n",
      ">> Epoch 1967 finished \tANN training loss 0.181920 Accuracy: 0.941733\n",
      ">> Epoch 1968 finished \tANN training loss 0.179245 Accuracy: 0.937571\n",
      ">> Epoch 1969 finished \tANN training loss 0.171426 Accuracy: 0.937571\n",
      ">> Epoch 1970 finished \tANN training loss 0.168476 Accuracy: 0.943246\n",
      ">> Epoch 1971 finished \tANN training loss 0.195115 Accuracy: 0.931896\n",
      ">> Epoch 1972 finished \tANN training loss 0.180392 Accuracy: 0.939463\n",
      ">> Epoch 1973 finished \tANN training loss 0.197831 Accuracy: 0.928112\n",
      ">> Epoch 1974 finished \tANN training loss 0.227034 Accuracy: 0.912599\n",
      ">> Epoch 1975 finished \tANN training loss 0.256155 Accuracy: 0.903519\n",
      ">> Epoch 1976 finished \tANN training loss 0.184991 Accuracy: 0.934544\n",
      ">> Epoch 1977 finished \tANN training loss 0.340256 Accuracy: 0.866061\n",
      ">> Epoch 1978 finished \tANN training loss 0.193206 Accuracy: 0.930382\n",
      ">> Epoch 1979 finished \tANN training loss 0.173587 Accuracy: 0.944760\n",
      ">> Epoch 1980 finished \tANN training loss 0.226738 Accuracy: 0.915626\n",
      ">> Epoch 1981 finished \tANN training loss 0.224645 Accuracy: 0.920166\n",
      ">> Epoch 1982 finished \tANN training loss 0.177907 Accuracy: 0.936814\n",
      ">> Epoch 1983 finished \tANN training loss 0.236236 Accuracy: 0.912221\n",
      ">> Epoch 1984 finished \tANN training loss 0.191075 Accuracy: 0.935679\n",
      ">> Epoch 1985 finished \tANN training loss 0.317529 Accuracy: 0.880817\n",
      ">> Epoch 1986 finished \tANN training loss 0.200475 Accuracy: 0.928490\n",
      ">> Epoch 1987 finished \tANN training loss 0.208812 Accuracy: 0.924707\n",
      ">> Epoch 1988 finished \tANN training loss 0.180814 Accuracy: 0.937193\n",
      ">> Epoch 1989 finished \tANN training loss 0.174911 Accuracy: 0.941733\n",
      ">> Epoch 1990 finished \tANN training loss 0.226654 Accuracy: 0.908437\n",
      ">> Epoch 1991 finished \tANN training loss 0.171954 Accuracy: 0.945138\n",
      ">> Epoch 1992 finished \tANN training loss 0.173100 Accuracy: 0.943625\n",
      ">> Epoch 1993 finished \tANN training loss 0.240065 Accuracy: 0.920166\n",
      ">> Epoch 1994 finished \tANN training loss 0.230713 Accuracy: 0.923193\n",
      ">> Epoch 1995 finished \tANN training loss 0.195721 Accuracy: 0.933787\n",
      ">> Epoch 1996 finished \tANN training loss 0.184949 Accuracy: 0.940219\n",
      ">> Epoch 1997 finished \tANN training loss 0.180329 Accuracy: 0.931896\n",
      ">> Epoch 1998 finished \tANN training loss 0.253861 Accuracy: 0.894816\n",
      ">> Epoch 1999 finished \tANN training loss 0.182172 Accuracy: 0.934166\n",
      ">> Epoch 2000 finished \tANN training loss 0.170510 Accuracy: 0.944003\n",
      ">> Epoch 2001 finished \tANN training loss 0.188024 Accuracy: 0.939841\n",
      ">> Epoch 2002 finished \tANN training loss 0.203102 Accuracy: 0.921680\n",
      ">> Epoch 2003 finished \tANN training loss 0.255539 Accuracy: 0.906546\n",
      ">> Epoch 2004 finished \tANN training loss 0.191224 Accuracy: 0.931517\n",
      ">> Epoch 2005 finished \tANN training loss 0.191449 Accuracy: 0.930004\n",
      ">> Epoch 2006 finished \tANN training loss 0.192729 Accuracy: 0.928869\n",
      ">> Epoch 2007 finished \tANN training loss 0.161049 Accuracy: 0.942868\n",
      ">> Epoch 2008 finished \tANN training loss 0.191154 Accuracy: 0.928112\n",
      ">> Epoch 2009 finished \tANN training loss 0.183481 Accuracy: 0.936058\n",
      ">> Epoch 2010 finished \tANN training loss 0.248282 Accuracy: 0.901627\n",
      ">> Epoch 2011 finished \tANN training loss 0.163000 Accuracy: 0.947030\n",
      ">> Epoch 2012 finished \tANN training loss 0.290376 Accuracy: 0.914113\n",
      ">> Epoch 2013 finished \tANN training loss 0.176015 Accuracy: 0.938328\n",
      ">> Epoch 2014 finished \tANN training loss 0.211176 Accuracy: 0.917518\n",
      ">> Epoch 2015 finished \tANN training loss 0.152214 Accuracy: 0.950813\n",
      ">> Epoch 2016 finished \tANN training loss 0.202556 Accuracy: 0.921680\n",
      ">> Epoch 2017 finished \tANN training loss 0.186104 Accuracy: 0.928112\n",
      ">> Epoch 2018 finished \tANN training loss 0.178763 Accuracy: 0.937571\n",
      ">> Epoch 2019 finished \tANN training loss 0.179775 Accuracy: 0.940598\n",
      ">> Epoch 2020 finished \tANN training loss 0.202768 Accuracy: 0.925842\n",
      ">> Epoch 2021 finished \tANN training loss 0.174274 Accuracy: 0.936814\n",
      ">> Epoch 2022 finished \tANN training loss 0.156887 Accuracy: 0.945138\n",
      ">> Epoch 2023 finished \tANN training loss 0.175849 Accuracy: 0.938706\n",
      ">> Epoch 2024 finished \tANN training loss 0.189309 Accuracy: 0.931896\n",
      ">> Epoch 2025 finished \tANN training loss 0.172484 Accuracy: 0.942111\n",
      ">> Epoch 2026 finished \tANN training loss 0.175840 Accuracy: 0.937571\n",
      ">> Epoch 2027 finished \tANN training loss 0.237867 Accuracy: 0.910708\n",
      ">> Epoch 2028 finished \tANN training loss 0.174541 Accuracy: 0.943625\n",
      ">> Epoch 2029 finished \tANN training loss 0.248845 Accuracy: 0.908059\n",
      ">> Epoch 2030 finished \tANN training loss 0.161539 Accuracy: 0.945516\n",
      ">> Epoch 2031 finished \tANN training loss 0.193311 Accuracy: 0.932274\n",
      ">> Epoch 2032 finished \tANN training loss 0.213069 Accuracy: 0.919410\n",
      ">> Epoch 2033 finished \tANN training loss 0.278101 Accuracy: 0.884222\n",
      ">> Epoch 2034 finished \tANN training loss 0.164976 Accuracy: 0.941355\n",
      ">> Epoch 2035 finished \tANN training loss 0.288744 Accuracy: 0.888763\n",
      ">> Epoch 2036 finished \tANN training loss 0.188923 Accuracy: 0.934922\n",
      ">> Epoch 2037 finished \tANN training loss 0.157315 Accuracy: 0.948922\n",
      ">> Epoch 2038 finished \tANN training loss 0.161775 Accuracy: 0.945516\n",
      ">> Epoch 2039 finished \tANN training loss 0.184382 Accuracy: 0.930004\n",
      ">> Epoch 2040 finished \tANN training loss 0.156919 Accuracy: 0.947787\n",
      ">> Epoch 2041 finished \tANN training loss 0.185083 Accuracy: 0.931896\n",
      ">> Epoch 2042 finished \tANN training loss 0.168418 Accuracy: 0.946273\n",
      ">> Epoch 2043 finished \tANN training loss 0.204820 Accuracy: 0.926599\n",
      ">> Epoch 2044 finished \tANN training loss 0.177655 Accuracy: 0.935679\n",
      ">> Epoch 2045 finished \tANN training loss 0.186469 Accuracy: 0.927734\n",
      ">> Epoch 2046 finished \tANN training loss 0.180408 Accuracy: 0.927355\n",
      ">> Epoch 2047 finished \tANN training loss 0.178043 Accuracy: 0.937571\n",
      ">> Epoch 2048 finished \tANN training loss 0.210886 Accuracy: 0.930382\n",
      ">> Epoch 2049 finished \tANN training loss 0.181206 Accuracy: 0.939841\n",
      ">> Epoch 2050 finished \tANN training loss 0.199538 Accuracy: 0.923950\n",
      ">> Epoch 2051 finished \tANN training loss 0.186755 Accuracy: 0.935301\n",
      ">> Epoch 2052 finished \tANN training loss 0.241784 Accuracy: 0.896330\n",
      ">> Epoch 2053 finished \tANN training loss 0.150458 Accuracy: 0.942490\n",
      ">> Epoch 2054 finished \tANN training loss 0.155828 Accuracy: 0.945516\n",
      ">> Epoch 2055 finished \tANN training loss 0.185352 Accuracy: 0.936058\n",
      ">> Epoch 2056 finished \tANN training loss 0.270210 Accuracy: 0.896330\n",
      ">> Epoch 2057 finished \tANN training loss 0.233128 Accuracy: 0.940219\n",
      ">> Epoch 2058 finished \tANN training loss 0.177734 Accuracy: 0.931517\n",
      ">> Epoch 2059 finished \tANN training loss 0.188464 Accuracy: 0.935301\n",
      ">> Epoch 2060 finished \tANN training loss 0.160905 Accuracy: 0.939463\n",
      ">> Epoch 2061 finished \tANN training loss 0.181324 Accuracy: 0.939841\n",
      ">> Epoch 2062 finished \tANN training loss 0.158867 Accuracy: 0.947030\n",
      ">> Epoch 2063 finished \tANN training loss 0.166224 Accuracy: 0.942490\n",
      ">> Epoch 2064 finished \tANN training loss 0.222901 Accuracy: 0.912221\n",
      ">> Epoch 2065 finished \tANN training loss 0.149921 Accuracy: 0.953462\n",
      ">> Epoch 2066 finished \tANN training loss 0.192669 Accuracy: 0.931896\n",
      ">> Epoch 2067 finished \tANN training loss 0.200876 Accuracy: 0.919788\n",
      ">> Epoch 2068 finished \tANN training loss 0.161867 Accuracy: 0.946652\n",
      ">> Epoch 2069 finished \tANN training loss 0.190287 Accuracy: 0.938706\n",
      ">> Epoch 2070 finished \tANN training loss 0.203110 Accuracy: 0.925842\n",
      ">> Epoch 2071 finished \tANN training loss 0.243885 Accuracy: 0.904654\n",
      ">> Epoch 2072 finished \tANN training loss 0.191084 Accuracy: 0.932652\n",
      ">> Epoch 2073 finished \tANN training loss 0.185479 Accuracy: 0.940219\n",
      ">> Epoch 2074 finished \tANN training loss 0.236256 Accuracy: 0.920166\n",
      ">> Epoch 2075 finished \tANN training loss 0.169798 Accuracy: 0.947787\n",
      ">> Epoch 2076 finished \tANN training loss 0.271145 Accuracy: 0.885358\n",
      ">> Epoch 2077 finished \tANN training loss 0.157778 Accuracy: 0.945895\n",
      ">> Epoch 2078 finished \tANN training loss 0.183917 Accuracy: 0.939084\n",
      ">> Epoch 2079 finished \tANN training loss 0.178388 Accuracy: 0.942111\n",
      ">> Epoch 2080 finished \tANN training loss 0.185386 Accuracy: 0.934544\n",
      ">> Epoch 2081 finished \tANN training loss 0.211726 Accuracy: 0.922437\n",
      ">> Epoch 2082 finished \tANN training loss 0.145295 Accuracy: 0.956110\n",
      ">> Epoch 2083 finished \tANN training loss 0.171539 Accuracy: 0.942111\n",
      ">> Epoch 2084 finished \tANN training loss 0.154824 Accuracy: 0.954597\n",
      ">> Epoch 2085 finished \tANN training loss 0.172582 Accuracy: 0.944003\n",
      ">> Epoch 2086 finished \tANN training loss 0.165437 Accuracy: 0.945895\n",
      ">> Epoch 2087 finished \tANN training loss 0.188075 Accuracy: 0.931896\n",
      ">> Epoch 2088 finished \tANN training loss 0.205246 Accuracy: 0.925463\n",
      ">> Epoch 2089 finished \tANN training loss 0.186031 Accuracy: 0.931517\n",
      ">> Epoch 2090 finished \tANN training loss 0.173650 Accuracy: 0.928490\n",
      ">> Epoch 2091 finished \tANN training loss 0.242954 Accuracy: 0.899357\n",
      ">> Epoch 2092 finished \tANN training loss 0.195912 Accuracy: 0.930760\n",
      ">> Epoch 2093 finished \tANN training loss 0.192971 Accuracy: 0.930760\n",
      ">> Epoch 2094 finished \tANN training loss 0.184695 Accuracy: 0.931517\n",
      ">> Epoch 2095 finished \tANN training loss 0.155418 Accuracy: 0.947030\n",
      ">> Epoch 2096 finished \tANN training loss 0.178057 Accuracy: 0.936058\n",
      ">> Epoch 2097 finished \tANN training loss 0.219864 Accuracy: 0.907681\n",
      ">> Epoch 2098 finished \tANN training loss 0.238281 Accuracy: 0.910708\n",
      ">> Epoch 2099 finished \tANN training loss 0.199526 Accuracy: 0.923572\n",
      ">> Epoch 2100 finished \tANN training loss 0.197577 Accuracy: 0.928490\n",
      ">> Epoch 2101 finished \tANN training loss 0.180789 Accuracy: 0.944760\n",
      ">> Epoch 2102 finished \tANN training loss 0.163945 Accuracy: 0.949678\n",
      ">> Epoch 2103 finished \tANN training loss 0.259651 Accuracy: 0.893303\n",
      ">> Epoch 2104 finished \tANN training loss 0.219931 Accuracy: 0.923193\n",
      ">> Epoch 2105 finished \tANN training loss 0.206021 Accuracy: 0.923572\n",
      ">> Epoch 2106 finished \tANN training loss 0.179757 Accuracy: 0.940598\n",
      ">> Epoch 2107 finished \tANN training loss 0.201219 Accuracy: 0.931517\n",
      ">> Epoch 2108 finished \tANN training loss 0.174450 Accuracy: 0.938706\n",
      ">> Epoch 2109 finished \tANN training loss 0.178710 Accuracy: 0.946652\n",
      ">> Epoch 2110 finished \tANN training loss 0.191234 Accuracy: 0.931896\n",
      ">> Epoch 2111 finished \tANN training loss 0.219998 Accuracy: 0.923950\n",
      ">> Epoch 2112 finished \tANN training loss 0.227748 Accuracy: 0.919788\n",
      ">> Epoch 2113 finished \tANN training loss 0.178783 Accuracy: 0.938706\n",
      ">> Epoch 2114 finished \tANN training loss 0.233689 Accuracy: 0.903897\n",
      ">> Epoch 2115 finished \tANN training loss 0.180915 Accuracy: 0.940219\n",
      ">> Epoch 2116 finished \tANN training loss 0.169302 Accuracy: 0.948165\n",
      ">> Epoch 2117 finished \tANN training loss 0.165896 Accuracy: 0.943625\n",
      ">> Epoch 2118 finished \tANN training loss 0.250467 Accuracy: 0.896708\n",
      ">> Epoch 2119 finished \tANN training loss 0.151535 Accuracy: 0.943246\n",
      ">> Epoch 2120 finished \tANN training loss 0.234171 Accuracy: 0.896708\n",
      ">> Epoch 2121 finished \tANN training loss 0.165434 Accuracy: 0.944381\n",
      ">> Epoch 2122 finished \tANN training loss 0.171407 Accuracy: 0.945516\n",
      ">> Epoch 2123 finished \tANN training loss 0.184363 Accuracy: 0.936058\n",
      ">> Epoch 2124 finished \tANN training loss 0.197815 Accuracy: 0.934166\n",
      ">> Epoch 2125 finished \tANN training loss 0.196812 Accuracy: 0.938328\n",
      ">> Epoch 2126 finished \tANN training loss 0.216754 Accuracy: 0.927734\n",
      ">> Epoch 2127 finished \tANN training loss 0.182289 Accuracy: 0.938328\n",
      ">> Epoch 2128 finished \tANN training loss 0.193870 Accuracy: 0.922815\n",
      ">> Epoch 2129 finished \tANN training loss 0.175195 Accuracy: 0.942111\n",
      ">> Epoch 2130 finished \tANN training loss 0.184437 Accuracy: 0.935679\n",
      ">> Epoch 2131 finished \tANN training loss 0.189865 Accuracy: 0.927734\n",
      ">> Epoch 2132 finished \tANN training loss 0.199255 Accuracy: 0.923572\n",
      ">> Epoch 2133 finished \tANN training loss 0.191235 Accuracy: 0.934166\n",
      ">> Epoch 2134 finished \tANN training loss 0.155937 Accuracy: 0.951192\n",
      ">> Epoch 2135 finished \tANN training loss 0.163279 Accuracy: 0.948165\n",
      ">> Epoch 2136 finished \tANN training loss 0.197895 Accuracy: 0.934544\n",
      ">> Epoch 2137 finished \tANN training loss 0.192923 Accuracy: 0.927734\n",
      ">> Epoch 2138 finished \tANN training loss 0.203420 Accuracy: 0.927355\n",
      ">> Epoch 2139 finished \tANN training loss 0.215025 Accuracy: 0.917896\n",
      ">> Epoch 2140 finished \tANN training loss 0.233884 Accuracy: 0.913356\n",
      ">> Epoch 2141 finished \tANN training loss 0.183703 Accuracy: 0.941355\n",
      ">> Epoch 2142 finished \tANN training loss 0.183982 Accuracy: 0.940976\n",
      ">> Epoch 2143 finished \tANN training loss 0.175136 Accuracy: 0.938706\n",
      ">> Epoch 2144 finished \tANN training loss 0.164277 Accuracy: 0.947030\n",
      ">> Epoch 2145 finished \tANN training loss 0.209829 Accuracy: 0.927355\n",
      ">> Epoch 2146 finished \tANN training loss 0.172812 Accuracy: 0.940219\n",
      ">> Epoch 2147 finished \tANN training loss 0.164175 Accuracy: 0.943246\n",
      ">> Epoch 2148 finished \tANN training loss 0.184028 Accuracy: 0.930382\n",
      ">> Epoch 2149 finished \tANN training loss 0.160682 Accuracy: 0.943625\n",
      ">> Epoch 2150 finished \tANN training loss 0.165752 Accuracy: 0.945895\n",
      ">> Epoch 2151 finished \tANN training loss 0.166350 Accuracy: 0.944003\n",
      ">> Epoch 2152 finished \tANN training loss 0.260558 Accuracy: 0.894438\n",
      ">> Epoch 2153 finished \tANN training loss 0.192106 Accuracy: 0.928112\n",
      ">> Epoch 2154 finished \tANN training loss 0.173812 Accuracy: 0.937193\n",
      ">> Epoch 2155 finished \tANN training loss 0.225171 Accuracy: 0.926977\n",
      ">> Epoch 2156 finished \tANN training loss 0.178362 Accuracy: 0.933409\n",
      ">> Epoch 2157 finished \tANN training loss 0.303106 Accuracy: 0.878547\n",
      ">> Epoch 2158 finished \tANN training loss 0.151136 Accuracy: 0.950435\n",
      ">> Epoch 2159 finished \tANN training loss 0.471493 Accuracy: 0.835414\n",
      ">> Epoch 2160 finished \tANN training loss 0.171870 Accuracy: 0.939084\n",
      ">> Epoch 2161 finished \tANN training loss 0.165848 Accuracy: 0.938706\n",
      ">> Epoch 2162 finished \tANN training loss 0.179431 Accuracy: 0.936058\n",
      ">> Epoch 2163 finished \tANN training loss 0.179576 Accuracy: 0.942111\n",
      ">> Epoch 2164 finished \tANN training loss 0.200629 Accuracy: 0.925842\n",
      ">> Epoch 2165 finished \tANN training loss 0.201319 Accuracy: 0.919031\n",
      ">> Epoch 2166 finished \tANN training loss 0.172785 Accuracy: 0.937571\n",
      ">> Epoch 2167 finished \tANN training loss 0.197241 Accuracy: 0.931896\n",
      ">> Epoch 2168 finished \tANN training loss 0.174064 Accuracy: 0.944003\n",
      ">> Epoch 2169 finished \tANN training loss 0.196788 Accuracy: 0.933787\n",
      ">> Epoch 2170 finished \tANN training loss 0.195960 Accuracy: 0.931139\n",
      ">> Epoch 2171 finished \tANN training loss 0.193047 Accuracy: 0.924328\n",
      ">> Epoch 2172 finished \tANN training loss 0.260109 Accuracy: 0.902384\n",
      ">> Epoch 2173 finished \tANN training loss 0.176050 Accuracy: 0.936814\n",
      ">> Epoch 2174 finished \tANN training loss 0.176614 Accuracy: 0.941355\n",
      ">> Epoch 2175 finished \tANN training loss 0.179855 Accuracy: 0.936814\n",
      ">> Epoch 2176 finished \tANN training loss 0.242264 Accuracy: 0.908437\n",
      ">> Epoch 2177 finished \tANN training loss 0.172065 Accuracy: 0.947408\n",
      ">> Epoch 2178 finished \tANN training loss 0.195082 Accuracy: 0.931139\n",
      ">> Epoch 2179 finished \tANN training loss 0.223636 Accuracy: 0.922815\n",
      ">> Epoch 2180 finished \tANN training loss 0.238399 Accuracy: 0.902762\n",
      ">> Epoch 2181 finished \tANN training loss 0.174142 Accuracy: 0.937949\n",
      ">> Epoch 2182 finished \tANN training loss 0.150598 Accuracy: 0.950057\n",
      ">> Epoch 2183 finished \tANN training loss 0.155313 Accuracy: 0.946273\n",
      ">> Epoch 2184 finished \tANN training loss 0.189082 Accuracy: 0.936436\n",
      ">> Epoch 2185 finished \tANN training loss 0.192103 Accuracy: 0.923193\n",
      ">> Epoch 2186 finished \tANN training loss 0.161786 Accuracy: 0.940219\n",
      ">> Epoch 2187 finished \tANN training loss 0.187011 Accuracy: 0.936058\n",
      ">> Epoch 2188 finished \tANN training loss 0.182788 Accuracy: 0.929625\n",
      ">> Epoch 2189 finished \tANN training loss 0.169527 Accuracy: 0.943625\n",
      ">> Epoch 2190 finished \tANN training loss 0.176360 Accuracy: 0.936814\n",
      ">> Epoch 2191 finished \tANN training loss 0.250227 Accuracy: 0.900870\n",
      ">> Epoch 2192 finished \tANN training loss 0.218826 Accuracy: 0.915248\n",
      ">> Epoch 2193 finished \tANN training loss 0.154144 Accuracy: 0.950057\n",
      ">> Epoch 2194 finished \tANN training loss 0.136847 Accuracy: 0.956489\n",
      ">> Epoch 2195 finished \tANN training loss 0.228289 Accuracy: 0.910329\n",
      ">> Epoch 2196 finished \tANN training loss 0.189725 Accuracy: 0.930382\n",
      ">> Epoch 2197 finished \tANN training loss 0.170575 Accuracy: 0.937193\n",
      ">> Epoch 2198 finished \tANN training loss 0.206070 Accuracy: 0.913734\n",
      ">> Epoch 2199 finished \tANN training loss 0.252221 Accuracy: 0.891033\n",
      ">> Epoch 2200 finished \tANN training loss 0.177405 Accuracy: 0.941355\n",
      ">> Epoch 2201 finished \tANN training loss 0.155936 Accuracy: 0.942868\n",
      ">> Epoch 2202 finished \tANN training loss 0.187443 Accuracy: 0.933031\n",
      ">> Epoch 2203 finished \tANN training loss 0.206204 Accuracy: 0.927355\n",
      ">> Epoch 2204 finished \tANN training loss 0.238196 Accuracy: 0.907302\n",
      ">> Epoch 2205 finished \tANN training loss 0.197915 Accuracy: 0.925463\n",
      ">> Epoch 2206 finished \tANN training loss 0.207106 Accuracy: 0.925463\n",
      ">> Epoch 2207 finished \tANN training loss 0.172009 Accuracy: 0.944760\n",
      ">> Epoch 2208 finished \tANN training loss 0.163269 Accuracy: 0.943625\n",
      ">> Epoch 2209 finished \tANN training loss 0.243214 Accuracy: 0.896708\n",
      ">> Epoch 2210 finished \tANN training loss 0.180671 Accuracy: 0.937193\n",
      ">> Epoch 2211 finished \tANN training loss 0.185932 Accuracy: 0.931896\n",
      ">> Epoch 2212 finished \tANN training loss 0.204238 Accuracy: 0.926599\n",
      ">> Epoch 2213 finished \tANN training loss 0.186227 Accuracy: 0.934544\n",
      ">> Epoch 2214 finished \tANN training loss 0.177459 Accuracy: 0.937949\n",
      ">> Epoch 2215 finished \tANN training loss 0.175475 Accuracy: 0.938706\n",
      ">> Epoch 2216 finished \tANN training loss 0.193567 Accuracy: 0.937949\n",
      ">> Epoch 2217 finished \tANN training loss 0.187198 Accuracy: 0.928869\n",
      ">> Epoch 2218 finished \tANN training loss 0.169970 Accuracy: 0.944381\n",
      ">> Epoch 2219 finished \tANN training loss 0.213416 Accuracy: 0.923572\n",
      ">> Epoch 2220 finished \tANN training loss 0.181769 Accuracy: 0.940598\n",
      ">> Epoch 2221 finished \tANN training loss 0.177762 Accuracy: 0.935679\n",
      ">> Epoch 2222 finished \tANN training loss 0.164898 Accuracy: 0.937571\n",
      ">> Epoch 2223 finished \tANN training loss 0.192790 Accuracy: 0.928869\n",
      ">> Epoch 2224 finished \tANN training loss 0.210622 Accuracy: 0.923572\n",
      ">> Epoch 2225 finished \tANN training loss 0.196562 Accuracy: 0.935679\n",
      ">> Epoch 2226 finished \tANN training loss 0.213594 Accuracy: 0.915626\n",
      ">> Epoch 2227 finished \tANN training loss 0.241110 Accuracy: 0.906924\n",
      ">> Epoch 2228 finished \tANN training loss 0.180291 Accuracy: 0.930760\n",
      ">> Epoch 2229 finished \tANN training loss 0.194333 Accuracy: 0.929247\n",
      ">> Epoch 2230 finished \tANN training loss 0.254559 Accuracy: 0.901249\n",
      ">> Epoch 2231 finished \tANN training loss 0.202181 Accuracy: 0.932274\n",
      ">> Epoch 2232 finished \tANN training loss 0.154607 Accuracy: 0.953084\n",
      ">> Epoch 2233 finished \tANN training loss 0.152052 Accuracy: 0.947408\n",
      ">> Epoch 2234 finished \tANN training loss 0.177140 Accuracy: 0.940598\n",
      ">> Epoch 2235 finished \tANN training loss 0.171421 Accuracy: 0.937949\n",
      ">> Epoch 2236 finished \tANN training loss 0.170561 Accuracy: 0.934166\n",
      ">> Epoch 2237 finished \tANN training loss 0.167334 Accuracy: 0.944381\n",
      ">> Epoch 2238 finished \tANN training loss 0.175045 Accuracy: 0.938328\n",
      ">> Epoch 2239 finished \tANN training loss 0.175716 Accuracy: 0.937571\n",
      ">> Epoch 2240 finished \tANN training loss 0.252778 Accuracy: 0.896708\n",
      ">> Epoch 2241 finished \tANN training loss 0.177499 Accuracy: 0.945516\n",
      ">> Epoch 2242 finished \tANN training loss 0.219848 Accuracy: 0.908816\n",
      ">> Epoch 2243 finished \tANN training loss 0.197471 Accuracy: 0.923572\n",
      ">> Epoch 2244 finished \tANN training loss 0.186857 Accuracy: 0.930760\n",
      ">> Epoch 2245 finished \tANN training loss 0.161720 Accuracy: 0.944760\n",
      ">> Epoch 2246 finished \tANN training loss 0.183423 Accuracy: 0.931517\n",
      ">> Epoch 2247 finished \tANN training loss 0.195816 Accuracy: 0.927734\n",
      ">> Epoch 2248 finished \tANN training loss 0.154769 Accuracy: 0.950435\n",
      ">> Epoch 2249 finished \tANN training loss 0.186328 Accuracy: 0.933787\n",
      ">> Epoch 2250 finished \tANN training loss 0.173203 Accuracy: 0.933409\n",
      ">> Epoch 2251 finished \tANN training loss 0.200214 Accuracy: 0.922437\n",
      ">> Epoch 2252 finished \tANN training loss 0.215658 Accuracy: 0.913734\n",
      ">> Epoch 2253 finished \tANN training loss 0.182499 Accuracy: 0.937571\n",
      ">> Epoch 2254 finished \tANN training loss 0.167099 Accuracy: 0.942490\n",
      ">> Epoch 2255 finished \tANN training loss 0.164460 Accuracy: 0.940598\n",
      ">> Epoch 2256 finished \tANN training loss 0.195125 Accuracy: 0.925085\n",
      ">> Epoch 2257 finished \tANN training loss 0.168061 Accuracy: 0.939463\n",
      ">> Epoch 2258 finished \tANN training loss 0.203512 Accuracy: 0.920545\n",
      ">> Epoch 2259 finished \tANN training loss 0.166114 Accuracy: 0.938328\n",
      ">> Epoch 2260 finished \tANN training loss 0.190427 Accuracy: 0.928112\n",
      ">> Epoch 2261 finished \tANN training loss 0.166628 Accuracy: 0.938706\n",
      ">> Epoch 2262 finished \tANN training loss 0.215456 Accuracy: 0.916383\n",
      ">> Epoch 2263 finished \tANN training loss 0.205198 Accuracy: 0.924328\n",
      ">> Epoch 2264 finished \tANN training loss 0.211311 Accuracy: 0.919031\n",
      ">> Epoch 2265 finished \tANN training loss 0.204792 Accuracy: 0.920166\n",
      ">> Epoch 2266 finished \tANN training loss 0.181434 Accuracy: 0.942111\n",
      ">> Epoch 2267 finished \tANN training loss 0.211443 Accuracy: 0.927355\n",
      ">> Epoch 2268 finished \tANN training loss 0.264001 Accuracy: 0.903140\n",
      ">> Epoch 2269 finished \tANN training loss 0.230312 Accuracy: 0.913356\n",
      ">> Epoch 2270 finished \tANN training loss 0.291143 Accuracy: 0.881952\n",
      ">> Epoch 2271 finished \tANN training loss 0.182015 Accuracy: 0.938706\n",
      ">> Epoch 2272 finished \tANN training loss 0.172249 Accuracy: 0.942868\n",
      ">> Epoch 2273 finished \tANN training loss 0.168500 Accuracy: 0.945516\n",
      ">> Epoch 2274 finished \tANN training loss 0.198718 Accuracy: 0.925085\n",
      ">> Epoch 2275 finished \tANN training loss 0.207232 Accuracy: 0.928869\n",
      ">> Epoch 2276 finished \tANN training loss 0.223950 Accuracy: 0.915248\n",
      ">> Epoch 2277 finished \tANN training loss 0.159529 Accuracy: 0.948543\n",
      ">> Epoch 2278 finished \tANN training loss 0.188782 Accuracy: 0.932652\n",
      ">> Epoch 2279 finished \tANN training loss 0.249643 Accuracy: 0.909572\n",
      ">> Epoch 2280 finished \tANN training loss 0.199935 Accuracy: 0.925842\n",
      ">> Epoch 2281 finished \tANN training loss 0.209144 Accuracy: 0.916383\n",
      ">> Epoch 2282 finished \tANN training loss 0.160183 Accuracy: 0.947787\n",
      ">> Epoch 2283 finished \tANN training loss 0.221445 Accuracy: 0.928112\n",
      ">> Epoch 2284 finished \tANN training loss 0.181433 Accuracy: 0.940219\n",
      ">> Epoch 2285 finished \tANN training loss 0.307824 Accuracy: 0.870602\n",
      ">> Epoch 2286 finished \tANN training loss 0.262542 Accuracy: 0.912599\n",
      ">> Epoch 2287 finished \tANN training loss 0.174865 Accuracy: 0.948922\n",
      ">> Epoch 2288 finished \tANN training loss 0.162659 Accuracy: 0.940976\n",
      ">> Epoch 2289 finished \tANN training loss 0.184538 Accuracy: 0.930760\n",
      ">> Epoch 2290 finished \tANN training loss 0.172769 Accuracy: 0.941733\n",
      ">> Epoch 2291 finished \tANN training loss 0.171168 Accuracy: 0.936814\n",
      ">> Epoch 2292 finished \tANN training loss 0.176172 Accuracy: 0.939463\n",
      ">> Epoch 2293 finished \tANN training loss 0.221635 Accuracy: 0.914869\n",
      ">> Epoch 2294 finished \tANN training loss 0.190191 Accuracy: 0.930760\n",
      ">> Epoch 2295 finished \tANN training loss 0.151824 Accuracy: 0.947787\n",
      ">> Epoch 2296 finished \tANN training loss 0.183014 Accuracy: 0.937571\n",
      ">> Epoch 2297 finished \tANN training loss 0.169274 Accuracy: 0.940976\n",
      ">> Epoch 2298 finished \tANN training loss 0.191878 Accuracy: 0.928869\n",
      ">> Epoch 2299 finished \tANN training loss 0.180821 Accuracy: 0.936436\n",
      ">> Epoch 2300 finished \tANN training loss 0.241249 Accuracy: 0.906546\n",
      ">> Epoch 2301 finished \tANN training loss 0.161156 Accuracy: 0.945138\n",
      ">> Epoch 2302 finished \tANN training loss 0.177860 Accuracy: 0.937571\n",
      ">> Epoch 2303 finished \tANN training loss 0.188269 Accuracy: 0.938328\n",
      ">> Epoch 2304 finished \tANN training loss 0.159682 Accuracy: 0.942868\n",
      ">> Epoch 2305 finished \tANN training loss 0.187832 Accuracy: 0.928490\n",
      ">> Epoch 2306 finished \tANN training loss 0.226441 Accuracy: 0.915626\n",
      ">> Epoch 2307 finished \tANN training loss 0.182976 Accuracy: 0.924707\n",
      ">> Epoch 2308 finished \tANN training loss 0.173198 Accuracy: 0.940598\n",
      ">> Epoch 2309 finished \tANN training loss 0.343353 Accuracy: 0.853954\n",
      ">> Epoch 2310 finished \tANN training loss 0.232049 Accuracy: 0.913356\n",
      ">> Epoch 2311 finished \tANN training loss 0.215650 Accuracy: 0.926977\n",
      ">> Epoch 2312 finished \tANN training loss 0.217083 Accuracy: 0.919788\n",
      ">> Epoch 2313 finished \tANN training loss 0.198579 Accuracy: 0.926977\n",
      ">> Epoch 2314 finished \tANN training loss 0.171768 Accuracy: 0.934166\n",
      ">> Epoch 2315 finished \tANN training loss 0.220022 Accuracy: 0.910708\n",
      ">> Epoch 2316 finished \tANN training loss 0.208219 Accuracy: 0.920923\n",
      ">> Epoch 2317 finished \tANN training loss 0.169772 Accuracy: 0.947787\n",
      ">> Epoch 2318 finished \tANN training loss 0.173974 Accuracy: 0.936058\n",
      ">> Epoch 2319 finished \tANN training loss 0.206358 Accuracy: 0.928869\n",
      ">> Epoch 2320 finished \tANN training loss 0.186641 Accuracy: 0.932652\n",
      ">> Epoch 2321 finished \tANN training loss 0.166160 Accuracy: 0.950057\n",
      ">> Epoch 2322 finished \tANN training loss 0.237946 Accuracy: 0.903519\n",
      ">> Epoch 2323 finished \tANN training loss 0.176755 Accuracy: 0.942111\n",
      ">> Epoch 2324 finished \tANN training loss 0.189607 Accuracy: 0.934544\n",
      ">> Epoch 2325 finished \tANN training loss 0.152940 Accuracy: 0.950813\n",
      ">> Epoch 2326 finished \tANN training loss 0.172058 Accuracy: 0.936436\n",
      ">> Epoch 2327 finished \tANN training loss 0.143877 Accuracy: 0.951949\n",
      ">> Epoch 2328 finished \tANN training loss 0.281510 Accuracy: 0.890655\n",
      ">> Epoch 2329 finished \tANN training loss 0.176687 Accuracy: 0.933409\n",
      ">> Epoch 2330 finished \tANN training loss 0.162512 Accuracy: 0.944381\n",
      ">> Epoch 2331 finished \tANN training loss 0.230868 Accuracy: 0.909194\n",
      ">> Epoch 2332 finished \tANN training loss 0.190864 Accuracy: 0.921302\n",
      ">> Epoch 2333 finished \tANN training loss 0.181020 Accuracy: 0.934166\n",
      ">> Epoch 2334 finished \tANN training loss 0.172880 Accuracy: 0.940976\n",
      ">> Epoch 2335 finished \tANN training loss 0.148582 Accuracy: 0.950435\n",
      ">> Epoch 2336 finished \tANN training loss 0.170152 Accuracy: 0.943625\n",
      ">> Epoch 2337 finished \tANN training loss 0.270982 Accuracy: 0.894438\n",
      ">> Epoch 2338 finished \tANN training loss 0.179802 Accuracy: 0.930004\n",
      ">> Epoch 2339 finished \tANN training loss 0.158707 Accuracy: 0.949678\n",
      ">> Epoch 2340 finished \tANN training loss 0.210668 Accuracy: 0.929625\n",
      ">> Epoch 2341 finished \tANN training loss 0.169936 Accuracy: 0.943246\n",
      ">> Epoch 2342 finished \tANN training loss 0.146208 Accuracy: 0.946652\n",
      ">> Epoch 2343 finished \tANN training loss 0.161096 Accuracy: 0.950813\n",
      ">> Epoch 2344 finished \tANN training loss 0.150121 Accuracy: 0.951192\n",
      ">> Epoch 2345 finished \tANN training loss 0.177262 Accuracy: 0.928112\n",
      ">> Epoch 2346 finished \tANN training loss 0.190869 Accuracy: 0.925842\n",
      ">> Epoch 2347 finished \tANN training loss 0.167366 Accuracy: 0.937949\n",
      ">> Epoch 2348 finished \tANN training loss 0.164330 Accuracy: 0.941355\n",
      ">> Epoch 2349 finished \tANN training loss 0.226002 Accuracy: 0.907681\n",
      ">> Epoch 2350 finished \tANN training loss 0.168396 Accuracy: 0.943625\n",
      ">> Epoch 2351 finished \tANN training loss 0.146362 Accuracy: 0.956867\n",
      ">> Epoch 2352 finished \tANN training loss 0.218529 Accuracy: 0.904275\n",
      ">> Epoch 2353 finished \tANN training loss 0.253294 Accuracy: 0.901249\n",
      ">> Epoch 2354 finished \tANN training loss 0.157743 Accuracy: 0.943246\n",
      ">> Epoch 2355 finished \tANN training loss 0.152146 Accuracy: 0.946652\n",
      ">> Epoch 2356 finished \tANN training loss 0.179340 Accuracy: 0.937949\n",
      ">> Epoch 2357 finished \tANN training loss 0.182656 Accuracy: 0.936436\n",
      ">> Epoch 2358 finished \tANN training loss 0.175837 Accuracy: 0.938706\n",
      ">> Epoch 2359 finished \tANN training loss 0.253058 Accuracy: 0.901627\n",
      ">> Epoch 2360 finished \tANN training loss 0.166572 Accuracy: 0.947787\n",
      ">> Epoch 2361 finished \tANN training loss 0.186399 Accuracy: 0.930382\n",
      ">> Epoch 2362 finished \tANN training loss 0.195375 Accuracy: 0.926977\n",
      ">> Epoch 2363 finished \tANN training loss 0.136360 Accuracy: 0.950813\n",
      ">> Epoch 2364 finished \tANN training loss 0.180778 Accuracy: 0.936436\n",
      ">> Epoch 2365 finished \tANN training loss 0.185969 Accuracy: 0.936814\n",
      ">> Epoch 2366 finished \tANN training loss 0.194861 Accuracy: 0.933409\n",
      ">> Epoch 2367 finished \tANN training loss 0.171750 Accuracy: 0.942111\n",
      ">> Epoch 2368 finished \tANN training loss 0.181967 Accuracy: 0.939084\n",
      ">> Epoch 2369 finished \tANN training loss 0.242395 Accuracy: 0.907681\n",
      ">> Epoch 2370 finished \tANN training loss 0.200601 Accuracy: 0.931517\n",
      ">> Epoch 2371 finished \tANN training loss 0.174872 Accuracy: 0.948543\n",
      ">> Epoch 2372 finished \tANN training loss 0.269178 Accuracy: 0.893681\n",
      ">> Epoch 2373 finished \tANN training loss 0.161895 Accuracy: 0.944760\n",
      ">> Epoch 2374 finished \tANN training loss 0.195316 Accuracy: 0.925842\n",
      ">> Epoch 2375 finished \tANN training loss 0.222094 Accuracy: 0.914113\n",
      ">> Epoch 2376 finished \tANN training loss 0.178355 Accuracy: 0.942111\n",
      ">> Epoch 2377 finished \tANN training loss 0.149194 Accuracy: 0.950813\n",
      ">> Epoch 2378 finished \tANN training loss 0.173234 Accuracy: 0.937571\n",
      ">> Epoch 2379 finished \tANN training loss 0.169803 Accuracy: 0.939084\n",
      ">> Epoch 2380 finished \tANN training loss 0.244986 Accuracy: 0.899357\n",
      ">> Epoch 2381 finished \tANN training loss 0.211731 Accuracy: 0.916005\n",
      ">> Epoch 2382 finished \tANN training loss 0.270624 Accuracy: 0.891790\n",
      ">> Epoch 2383 finished \tANN training loss 0.157772 Accuracy: 0.953462\n",
      ">> Epoch 2384 finished \tANN training loss 0.179367 Accuracy: 0.939841\n",
      ">> Epoch 2385 finished \tANN training loss 0.172690 Accuracy: 0.940598\n",
      ">> Epoch 2386 finished \tANN training loss 0.179615 Accuracy: 0.934922\n",
      ">> Epoch 2387 finished \tANN training loss 0.191566 Accuracy: 0.929247\n",
      ">> Epoch 2388 finished \tANN training loss 0.160640 Accuracy: 0.951949\n",
      ">> Epoch 2389 finished \tANN training loss 0.205846 Accuracy: 0.924707\n",
      ">> Epoch 2390 finished \tANN training loss 0.188339 Accuracy: 0.935679\n",
      ">> Epoch 2391 finished \tANN training loss 0.165791 Accuracy: 0.947030\n",
      ">> Epoch 2392 finished \tANN training loss 0.169906 Accuracy: 0.944381\n",
      ">> Epoch 2393 finished \tANN training loss 0.179710 Accuracy: 0.943625\n",
      ">> Epoch 2394 finished \tANN training loss 0.173092 Accuracy: 0.946652\n",
      ">> Epoch 2395 finished \tANN training loss 0.234196 Accuracy: 0.909572\n",
      ">> Epoch 2396 finished \tANN training loss 0.165923 Accuracy: 0.953084\n",
      ">> Epoch 2397 finished \tANN training loss 0.159791 Accuracy: 0.947408\n",
      ">> Epoch 2398 finished \tANN training loss 0.303778 Accuracy: 0.880817\n",
      ">> Epoch 2399 finished \tANN training loss 0.169580 Accuracy: 0.937571\n",
      ">> Epoch 2400 finished \tANN training loss 0.274953 Accuracy: 0.888384\n",
      ">> Epoch 2401 finished \tANN training loss 0.231983 Accuracy: 0.909194\n",
      ">> Epoch 2402 finished \tANN training loss 0.156893 Accuracy: 0.950435\n",
      ">> Epoch 2403 finished \tANN training loss 0.175016 Accuracy: 0.933409\n",
      ">> Epoch 2404 finished \tANN training loss 0.168515 Accuracy: 0.937571\n",
      ">> Epoch 2405 finished \tANN training loss 0.252488 Accuracy: 0.897087\n",
      ">> Epoch 2406 finished \tANN training loss 0.191554 Accuracy: 0.927734\n",
      ">> Epoch 2407 finished \tANN training loss 0.155544 Accuracy: 0.945516\n",
      ">> Epoch 2408 finished \tANN training loss 0.212690 Accuracy: 0.911086\n",
      ">> Epoch 2409 finished \tANN training loss 0.172873 Accuracy: 0.937949\n",
      ">> Epoch 2410 finished \tANN training loss 0.230122 Accuracy: 0.907681\n",
      ">> Epoch 2411 finished \tANN training loss 0.259724 Accuracy: 0.898222\n",
      ">> Epoch 2412 finished \tANN training loss 0.234725 Accuracy: 0.908059\n",
      ">> Epoch 2413 finished \tANN training loss 0.157948 Accuracy: 0.940598\n",
      ">> Epoch 2414 finished \tANN training loss 0.171122 Accuracy: 0.934922\n",
      ">> Epoch 2415 finished \tANN training loss 0.177609 Accuracy: 0.940598\n",
      ">> Epoch 2416 finished \tANN training loss 0.229380 Accuracy: 0.904654\n",
      ">> Epoch 2417 finished \tANN training loss 0.181787 Accuracy: 0.937949\n",
      ">> Epoch 2418 finished \tANN training loss 0.196636 Accuracy: 0.933409\n",
      ">> Epoch 2419 finished \tANN training loss 0.165491 Accuracy: 0.944003\n",
      ">> Epoch 2420 finished \tANN training loss 0.185773 Accuracy: 0.931517\n",
      ">> Epoch 2421 finished \tANN training loss 0.192216 Accuracy: 0.933787\n",
      ">> Epoch 2422 finished \tANN training loss 0.190918 Accuracy: 0.930382\n",
      ">> Epoch 2423 finished \tANN training loss 0.151783 Accuracy: 0.949300\n",
      ">> Epoch 2424 finished \tANN training loss 0.184983 Accuracy: 0.932274\n",
      ">> Epoch 2425 finished \tANN training loss 0.221084 Accuracy: 0.913356\n",
      ">> Epoch 2426 finished \tANN training loss 0.168733 Accuracy: 0.947787\n",
      ">> Epoch 2427 finished \tANN training loss 0.214340 Accuracy: 0.922058\n",
      ">> Epoch 2428 finished \tANN training loss 0.179301 Accuracy: 0.933409\n",
      ">> Epoch 2429 finished \tANN training loss 0.188198 Accuracy: 0.931139\n",
      ">> Epoch 2430 finished \tANN training loss 0.258665 Accuracy: 0.905411\n",
      ">> Epoch 2431 finished \tANN training loss 0.180638 Accuracy: 0.937571\n",
      ">> Epoch 2432 finished \tANN training loss 0.191145 Accuracy: 0.931896\n",
      ">> Epoch 2433 finished \tANN training loss 0.204061 Accuracy: 0.919410\n",
      ">> Epoch 2434 finished \tANN training loss 0.183381 Accuracy: 0.931896\n",
      ">> Epoch 2435 finished \tANN training loss 0.170957 Accuracy: 0.940598\n",
      ">> Epoch 2436 finished \tANN training loss 0.173135 Accuracy: 0.938328\n",
      ">> Epoch 2437 finished \tANN training loss 0.173180 Accuracy: 0.941733\n",
      ">> Epoch 2438 finished \tANN training loss 0.263418 Accuracy: 0.905032\n",
      ">> Epoch 2439 finished \tANN training loss 0.227978 Accuracy: 0.909951\n",
      ">> Epoch 2440 finished \tANN training loss 0.199577 Accuracy: 0.916761\n",
      ">> Epoch 2441 finished \tANN training loss 0.211339 Accuracy: 0.919410\n",
      ">> Epoch 2442 finished \tANN training loss 0.194438 Accuracy: 0.932652\n",
      ">> Epoch 2443 finished \tANN training loss 0.229642 Accuracy: 0.906546\n",
      ">> Epoch 2444 finished \tANN training loss 0.178497 Accuracy: 0.935301\n",
      ">> Epoch 2445 finished \tANN training loss 0.171413 Accuracy: 0.936058\n",
      ">> Epoch 2446 finished \tANN training loss 0.225612 Accuracy: 0.912599\n",
      ">> Epoch 2447 finished \tANN training loss 0.162656 Accuracy: 0.942111\n",
      ">> Epoch 2448 finished \tANN training loss 0.163590 Accuracy: 0.944381\n",
      ">> Epoch 2449 finished \tANN training loss 0.172298 Accuracy: 0.937193\n",
      ">> Epoch 2450 finished \tANN training loss 0.181787 Accuracy: 0.928869\n",
      ">> Epoch 2451 finished \tANN training loss 0.189177 Accuracy: 0.930760\n",
      ">> Epoch 2452 finished \tANN training loss 0.215677 Accuracy: 0.919031\n",
      ">> Epoch 2453 finished \tANN training loss 0.217331 Accuracy: 0.920545\n",
      ">> Epoch 2454 finished \tANN training loss 0.151541 Accuracy: 0.952705\n",
      ">> Epoch 2455 finished \tANN training loss 0.161961 Accuracy: 0.944003\n",
      ">> Epoch 2456 finished \tANN training loss 0.233762 Accuracy: 0.904654\n",
      ">> Epoch 2457 finished \tANN training loss 0.169895 Accuracy: 0.937193\n",
      ">> Epoch 2458 finished \tANN training loss 0.206541 Accuracy: 0.926220\n",
      ">> Epoch 2459 finished \tANN training loss 0.216056 Accuracy: 0.914113\n",
      ">> Epoch 2460 finished \tANN training loss 0.161199 Accuracy: 0.940598\n",
      ">> Epoch 2461 finished \tANN training loss 0.175233 Accuracy: 0.939463\n",
      ">> Epoch 2462 finished \tANN training loss 0.169986 Accuracy: 0.934544\n",
      ">> Epoch 2463 finished \tANN training loss 0.227350 Accuracy: 0.917896\n",
      ">> Epoch 2464 finished \tANN training loss 0.205828 Accuracy: 0.922058\n",
      ">> Epoch 2465 finished \tANN training loss 0.176904 Accuracy: 0.934166\n",
      ">> Epoch 2466 finished \tANN training loss 0.192270 Accuracy: 0.927734\n",
      ">> Epoch 2467 finished \tANN training loss 0.222986 Accuracy: 0.916005\n",
      ">> Epoch 2468 finished \tANN training loss 0.168420 Accuracy: 0.940219\n",
      ">> Epoch 2469 finished \tANN training loss 0.200801 Accuracy: 0.924328\n",
      ">> Epoch 2470 finished \tANN training loss 0.197770 Accuracy: 0.930004\n",
      ">> Epoch 2471 finished \tANN training loss 0.161448 Accuracy: 0.943246\n",
      ">> Epoch 2472 finished \tANN training loss 0.153367 Accuracy: 0.947787\n",
      ">> Epoch 2473 finished \tANN training loss 0.160026 Accuracy: 0.942868\n",
      ">> Epoch 2474 finished \tANN training loss 0.176786 Accuracy: 0.939084\n",
      ">> Epoch 2475 finished \tANN training loss 0.172224 Accuracy: 0.941355\n",
      ">> Epoch 2476 finished \tANN training loss 0.159003 Accuracy: 0.947408\n",
      ">> Epoch 2477 finished \tANN training loss 0.182708 Accuracy: 0.931139\n",
      ">> Epoch 2478 finished \tANN training loss 0.181478 Accuracy: 0.935679\n",
      ">> Epoch 2479 finished \tANN training loss 0.152319 Accuracy: 0.951192\n",
      ">> Epoch 2480 finished \tANN training loss 0.176385 Accuracy: 0.933787\n",
      ">> Epoch 2481 finished \tANN training loss 0.205218 Accuracy: 0.919410\n",
      ">> Epoch 2482 finished \tANN training loss 0.199900 Accuracy: 0.922058\n",
      ">> Epoch 2483 finished \tANN training loss 0.159237 Accuracy: 0.944003\n",
      ">> Epoch 2484 finished \tANN training loss 0.164918 Accuracy: 0.944760\n",
      ">> Epoch 2485 finished \tANN training loss 0.150999 Accuracy: 0.952327\n",
      ">> Epoch 2486 finished \tANN training loss 0.164716 Accuracy: 0.949300\n",
      ">> Epoch 2487 finished \tANN training loss 0.153872 Accuracy: 0.949678\n",
      ">> Epoch 2488 finished \tANN training loss 0.160402 Accuracy: 0.950435\n",
      ">> Epoch 2489 finished \tANN training loss 0.211026 Accuracy: 0.915626\n",
      ">> Epoch 2490 finished \tANN training loss 0.181031 Accuracy: 0.931517\n",
      ">> Epoch 2491 finished \tANN training loss 0.151653 Accuracy: 0.945895\n",
      ">> Epoch 2492 finished \tANN training loss 0.204544 Accuracy: 0.925842\n",
      ">> Epoch 2493 finished \tANN training loss 0.256775 Accuracy: 0.898222\n",
      ">> Epoch 2494 finished \tANN training loss 0.224603 Accuracy: 0.922815\n",
      ">> Epoch 2495 finished \tANN training loss 0.156890 Accuracy: 0.951570\n",
      ">> Epoch 2496 finished \tANN training loss 0.181705 Accuracy: 0.933409\n",
      ">> Epoch 2497 finished \tANN training loss 0.149104 Accuracy: 0.953462\n",
      ">> Epoch 2498 finished \tANN training loss 0.218040 Accuracy: 0.920545\n",
      ">> Epoch 2499 finished \tANN training loss 0.254681 Accuracy: 0.894438\n",
      ">> Epoch 2500 finished \tANN training loss 0.219559 Accuracy: 0.916005\n",
      ">> Epoch 2501 finished \tANN training loss 0.171154 Accuracy: 0.946652\n",
      ">> Epoch 2502 finished \tANN training loss 0.214482 Accuracy: 0.920166\n",
      ">> Epoch 2503 finished \tANN training loss 0.201128 Accuracy: 0.925463\n",
      ">> Epoch 2504 finished \tANN training loss 0.160138 Accuracy: 0.943625\n",
      ">> Epoch 2505 finished \tANN training loss 0.196067 Accuracy: 0.931139\n",
      ">> Epoch 2506 finished \tANN training loss 0.148554 Accuracy: 0.952327\n",
      ">> Epoch 2507 finished \tANN training loss 0.224904 Accuracy: 0.911843\n",
      ">> Epoch 2508 finished \tANN training loss 0.213237 Accuracy: 0.916005\n",
      ">> Epoch 2509 finished \tANN training loss 0.174533 Accuracy: 0.942490\n",
      ">> Epoch 2510 finished \tANN training loss 0.170231 Accuracy: 0.934922\n",
      ">> Epoch 2511 finished \tANN training loss 0.160326 Accuracy: 0.944381\n",
      ">> Epoch 2512 finished \tANN training loss 0.187835 Accuracy: 0.928869\n",
      ">> Epoch 2513 finished \tANN training loss 0.156376 Accuracy: 0.950057\n",
      ">> Epoch 2514 finished \tANN training loss 0.182218 Accuracy: 0.936436\n",
      ">> Epoch 2515 finished \tANN training loss 0.177347 Accuracy: 0.937193\n",
      ">> Epoch 2516 finished \tANN training loss 0.160624 Accuracy: 0.948165\n",
      ">> Epoch 2517 finished \tANN training loss 0.170865 Accuracy: 0.937949\n",
      ">> Epoch 2518 finished \tANN training loss 0.176703 Accuracy: 0.940976\n",
      ">> Epoch 2519 finished \tANN training loss 0.168699 Accuracy: 0.942868\n",
      ">> Epoch 2520 finished \tANN training loss 0.167611 Accuracy: 0.941355\n",
      ">> Epoch 2521 finished \tANN training loss 0.153509 Accuracy: 0.945895\n",
      ">> Epoch 2522 finished \tANN training loss 0.168159 Accuracy: 0.939841\n",
      ">> Epoch 2523 finished \tANN training loss 0.221692 Accuracy: 0.905789\n",
      ">> Epoch 2524 finished \tANN training loss 0.153717 Accuracy: 0.952705\n",
      ">> Epoch 2525 finished \tANN training loss 0.177039 Accuracy: 0.944003\n",
      ">> Epoch 2526 finished \tANN training loss 0.151934 Accuracy: 0.951949\n",
      ">> Epoch 2527 finished \tANN training loss 0.273002 Accuracy: 0.881196\n",
      ">> Epoch 2528 finished \tANN training loss 0.180186 Accuracy: 0.934166\n",
      ">> Epoch 2529 finished \tANN training loss 0.160497 Accuracy: 0.937193\n",
      ">> Epoch 2530 finished \tANN training loss 0.186457 Accuracy: 0.936436\n",
      ">> Epoch 2531 finished \tANN training loss 0.193688 Accuracy: 0.929247\n",
      ">> Epoch 2532 finished \tANN training loss 0.186014 Accuracy: 0.925842\n",
      ">> Epoch 2533 finished \tANN training loss 0.222868 Accuracy: 0.913734\n",
      ">> Epoch 2534 finished \tANN training loss 0.196721 Accuracy: 0.921680\n",
      ">> Epoch 2535 finished \tANN training loss 0.177361 Accuracy: 0.932274\n",
      ">> Epoch 2536 finished \tANN training loss 0.169943 Accuracy: 0.939084\n",
      ">> Epoch 2537 finished \tANN training loss 0.178216 Accuracy: 0.938706\n",
      ">> Epoch 2538 finished \tANN training loss 0.155550 Accuracy: 0.943625\n",
      ">> Epoch 2539 finished \tANN training loss 0.149198 Accuracy: 0.954597\n",
      ">> Epoch 2540 finished \tANN training loss 0.170336 Accuracy: 0.940219\n",
      ">> Epoch 2541 finished \tANN training loss 0.213399 Accuracy: 0.917896\n",
      ">> Epoch 2542 finished \tANN training loss 0.222038 Accuracy: 0.918653\n",
      ">> Epoch 2543 finished \tANN training loss 0.160209 Accuracy: 0.935301\n",
      ">> Epoch 2544 finished \tANN training loss 0.197347 Accuracy: 0.937193\n",
      ">> Epoch 2545 finished \tANN training loss 0.162344 Accuracy: 0.940598\n",
      ">> Epoch 2546 finished \tANN training loss 0.178313 Accuracy: 0.939084\n",
      ">> Epoch 2547 finished \tANN training loss 0.220477 Accuracy: 0.920923\n",
      ">> Epoch 2548 finished \tANN training loss 0.168711 Accuracy: 0.941355\n",
      ">> Epoch 2549 finished \tANN training loss 0.211147 Accuracy: 0.918275\n",
      ">> Epoch 2550 finished \tANN training loss 0.353677 Accuracy: 0.859251\n",
      ">> Epoch 2551 finished \tANN training loss 0.180611 Accuracy: 0.936436\n",
      ">> Epoch 2552 finished \tANN training loss 0.167712 Accuracy: 0.941355\n",
      ">> Epoch 2553 finished \tANN training loss 0.179154 Accuracy: 0.936436\n",
      ">> Epoch 2554 finished \tANN training loss 0.176196 Accuracy: 0.937571\n",
      ">> Epoch 2555 finished \tANN training loss 0.260141 Accuracy: 0.895573\n",
      ">> Epoch 2556 finished \tANN training loss 0.192680 Accuracy: 0.923193\n",
      ">> Epoch 2557 finished \tANN training loss 0.190392 Accuracy: 0.927734\n",
      ">> Epoch 2558 finished \tANN training loss 0.169296 Accuracy: 0.944760\n",
      ">> Epoch 2559 finished \tANN training loss 0.156834 Accuracy: 0.948165\n",
      ">> Epoch 2560 finished \tANN training loss 0.198810 Accuracy: 0.945138\n",
      ">> Epoch 2561 finished \tANN training loss 0.148319 Accuracy: 0.947408\n",
      ">> Epoch 2562 finished \tANN training loss 0.156163 Accuracy: 0.946652\n",
      ">> Epoch 2563 finished \tANN training loss 0.155750 Accuracy: 0.947408\n",
      ">> Epoch 2564 finished \tANN training loss 0.159477 Accuracy: 0.941355\n",
      ">> Epoch 2565 finished \tANN training loss 0.241588 Accuracy: 0.905032\n",
      ">> Epoch 2566 finished \tANN training loss 0.236381 Accuracy: 0.916383\n",
      ">> Epoch 2567 finished \tANN training loss 0.162348 Accuracy: 0.942111\n",
      ">> Epoch 2568 finished \tANN training loss 0.182082 Accuracy: 0.935301\n",
      ">> Epoch 2569 finished \tANN training loss 0.148473 Accuracy: 0.948543\n",
      ">> Epoch 2570 finished \tANN training loss 0.149634 Accuracy: 0.942490\n",
      ">> Epoch 2571 finished \tANN training loss 0.166380 Accuracy: 0.939463\n",
      ">> Epoch 2572 finished \tANN training loss 0.172692 Accuracy: 0.935679\n",
      ">> Epoch 2573 finished \tANN training loss 0.215558 Accuracy: 0.916383\n",
      ">> Epoch 2574 finished \tANN training loss 0.211260 Accuracy: 0.917518\n",
      ">> Epoch 2575 finished \tANN training loss 0.164792 Accuracy: 0.944003\n",
      ">> Epoch 2576 finished \tANN training loss 0.156425 Accuracy: 0.944760\n",
      ">> Epoch 2577 finished \tANN training loss 0.194395 Accuracy: 0.929247\n",
      ">> Epoch 2578 finished \tANN training loss 0.165928 Accuracy: 0.936058\n",
      ">> Epoch 2579 finished \tANN training loss 0.160000 Accuracy: 0.946652\n",
      ">> Epoch 2580 finished \tANN training loss 0.197327 Accuracy: 0.925085\n",
      ">> Epoch 2581 finished \tANN training loss 0.206927 Accuracy: 0.921302\n",
      ">> Epoch 2582 finished \tANN training loss 0.265406 Accuracy: 0.895195\n",
      ">> Epoch 2583 finished \tANN training loss 0.174763 Accuracy: 0.939084\n",
      ">> Epoch 2584 finished \tANN training loss 0.245899 Accuracy: 0.900492\n",
      ">> Epoch 2585 finished \tANN training loss 0.221319 Accuracy: 0.911086\n",
      ">> Epoch 2586 finished \tANN training loss 0.165599 Accuracy: 0.944003\n",
      ">> Epoch 2587 finished \tANN training loss 0.155451 Accuracy: 0.947030\n",
      ">> Epoch 2588 finished \tANN training loss 0.196559 Accuracy: 0.932274\n",
      ">> Epoch 2589 finished \tANN training loss 0.219467 Accuracy: 0.917518\n",
      ">> Epoch 2590 finished \tANN training loss 0.263092 Accuracy: 0.891411\n",
      ">> Epoch 2591 finished \tANN training loss 0.181827 Accuracy: 0.939084\n",
      ">> Epoch 2592 finished \tANN training loss 0.168853 Accuracy: 0.946652\n",
      ">> Epoch 2593 finished \tANN training loss 0.177346 Accuracy: 0.941355\n",
      ">> Epoch 2594 finished \tANN training loss 0.198760 Accuracy: 0.926977\n",
      ">> Epoch 2595 finished \tANN training loss 0.158346 Accuracy: 0.943246\n",
      ">> Epoch 2596 finished \tANN training loss 0.166740 Accuracy: 0.944760\n",
      ">> Epoch 2597 finished \tANN training loss 0.191018 Accuracy: 0.929625\n",
      ">> Epoch 2598 finished \tANN training loss 0.190425 Accuracy: 0.930382\n",
      ">> Epoch 2599 finished \tANN training loss 0.176112 Accuracy: 0.940976\n",
      ">> Epoch 2600 finished \tANN training loss 0.244763 Accuracy: 0.908059\n",
      ">> Epoch 2601 finished \tANN training loss 0.181583 Accuracy: 0.941733\n",
      ">> Epoch 2602 finished \tANN training loss 0.188178 Accuracy: 0.936436\n",
      ">> Epoch 2603 finished \tANN training loss 0.218076 Accuracy: 0.919031\n",
      ">> Epoch 2604 finished \tANN training loss 0.183134 Accuracy: 0.936058\n",
      ">> Epoch 2605 finished \tANN training loss 0.161902 Accuracy: 0.938328\n",
      ">> Epoch 2606 finished \tANN training loss 0.213742 Accuracy: 0.915248\n",
      ">> Epoch 2607 finished \tANN training loss 0.173873 Accuracy: 0.938706\n",
      ">> Epoch 2608 finished \tANN training loss 0.180133 Accuracy: 0.938706\n",
      ">> Epoch 2609 finished \tANN training loss 0.153237 Accuracy: 0.948543\n",
      ">> Epoch 2610 finished \tANN training loss 0.184481 Accuracy: 0.936058\n",
      ">> Epoch 2611 finished \tANN training loss 0.209282 Accuracy: 0.918275\n",
      ">> Epoch 2612 finished \tANN training loss 0.227858 Accuracy: 0.906924\n",
      ">> Epoch 2613 finished \tANN training loss 0.170078 Accuracy: 0.933787\n",
      ">> Epoch 2614 finished \tANN training loss 0.174542 Accuracy: 0.937571\n",
      ">> Epoch 2615 finished \tANN training loss 0.177247 Accuracy: 0.935301\n",
      ">> Epoch 2616 finished \tANN training loss 0.193542 Accuracy: 0.933031\n",
      ">> Epoch 2617 finished \tANN training loss 0.182348 Accuracy: 0.934922\n",
      ">> Epoch 2618 finished \tANN training loss 0.239426 Accuracy: 0.908816\n",
      ">> Epoch 2619 finished \tANN training loss 0.188727 Accuracy: 0.933031\n",
      ">> Epoch 2620 finished \tANN training loss 0.169760 Accuracy: 0.944381\n",
      ">> Epoch 2621 finished \tANN training loss 0.170008 Accuracy: 0.936436\n",
      ">> Epoch 2622 finished \tANN training loss 0.168542 Accuracy: 0.944760\n",
      ">> Epoch 2623 finished \tANN training loss 0.173103 Accuracy: 0.937193\n",
      ">> Epoch 2624 finished \tANN training loss 0.164755 Accuracy: 0.943625\n",
      ">> Epoch 2625 finished \tANN training loss 0.200495 Accuracy: 0.928112\n",
      ">> Epoch 2626 finished \tANN training loss 0.184513 Accuracy: 0.928490\n",
      ">> Epoch 2627 finished \tANN training loss 0.203575 Accuracy: 0.923950\n",
      ">> Epoch 2628 finished \tANN training loss 0.196590 Accuracy: 0.925463\n",
      ">> Epoch 2629 finished \tANN training loss 0.197577 Accuracy: 0.923193\n",
      ">> Epoch 2630 finished \tANN training loss 0.223833 Accuracy: 0.913734\n",
      ">> Epoch 2631 finished \tANN training loss 0.206765 Accuracy: 0.929247\n",
      ">> Epoch 2632 finished \tANN training loss 0.199876 Accuracy: 0.930382\n",
      ">> Epoch 2633 finished \tANN training loss 0.204365 Accuracy: 0.926599\n",
      ">> Epoch 2634 finished \tANN training loss 0.255037 Accuracy: 0.908816\n",
      ">> Epoch 2635 finished \tANN training loss 0.239051 Accuracy: 0.909951\n",
      ">> Epoch 2636 finished \tANN training loss 0.143032 Accuracy: 0.955732\n",
      ">> Epoch 2637 finished \tANN training loss 0.164312 Accuracy: 0.943246\n",
      ">> Epoch 2638 finished \tANN training loss 0.187937 Accuracy: 0.928869\n",
      ">> Epoch 2639 finished \tANN training loss 0.177487 Accuracy: 0.931517\n",
      ">> Epoch 2640 finished \tANN training loss 0.183223 Accuracy: 0.930382\n",
      ">> Epoch 2641 finished \tANN training loss 0.179896 Accuracy: 0.938328\n",
      ">> Epoch 2642 finished \tANN training loss 0.170803 Accuracy: 0.939841\n",
      ">> Epoch 2643 finished \tANN training loss 0.185631 Accuracy: 0.926977\n",
      ">> Epoch 2644 finished \tANN training loss 0.181379 Accuracy: 0.936058\n",
      ">> Epoch 2645 finished \tANN training loss 0.168091 Accuracy: 0.942868\n",
      ">> Epoch 2646 finished \tANN training loss 0.202274 Accuracy: 0.924328\n",
      ">> Epoch 2647 finished \tANN training loss 0.153719 Accuracy: 0.944381\n",
      ">> Epoch 2648 finished \tANN training loss 0.225751 Accuracy: 0.901249\n",
      ">> Epoch 2649 finished \tANN training loss 0.219822 Accuracy: 0.916761\n",
      ">> Epoch 2650 finished \tANN training loss 0.191933 Accuracy: 0.933031\n",
      ">> Epoch 2651 finished \tANN training loss 0.205640 Accuracy: 0.931139\n",
      ">> Epoch 2652 finished \tANN training loss 0.156042 Accuracy: 0.951570\n",
      ">> Epoch 2653 finished \tANN training loss 0.168796 Accuracy: 0.941355\n",
      ">> Epoch 2654 finished \tANN training loss 0.188458 Accuracy: 0.929625\n",
      ">> Epoch 2655 finished \tANN training loss 0.196316 Accuracy: 0.924707\n",
      ">> Epoch 2656 finished \tANN training loss 0.179912 Accuracy: 0.933787\n",
      ">> Epoch 2657 finished \tANN training loss 0.203651 Accuracy: 0.919410\n",
      ">> Epoch 2658 finished \tANN training loss 0.231374 Accuracy: 0.914869\n",
      ">> Epoch 2659 finished \tANN training loss 0.169279 Accuracy: 0.942111\n",
      ">> Epoch 2660 finished \tANN training loss 0.188215 Accuracy: 0.926599\n",
      ">> Epoch 2661 finished \tANN training loss 0.169846 Accuracy: 0.939463\n",
      ">> Epoch 2662 finished \tANN training loss 0.308364 Accuracy: 0.872872\n",
      ">> Epoch 2663 finished \tANN training loss 0.208442 Accuracy: 0.912599\n",
      ">> Epoch 2664 finished \tANN training loss 0.155306 Accuracy: 0.949678\n",
      ">> Epoch 2665 finished \tANN training loss 0.164290 Accuracy: 0.942868\n",
      ">> Epoch 2666 finished \tANN training loss 0.180751 Accuracy: 0.933787\n",
      ">> Epoch 2667 finished \tANN training loss 0.225724 Accuracy: 0.919410\n",
      ">> Epoch 2668 finished \tANN training loss 0.204278 Accuracy: 0.922058\n",
      ">> Epoch 2669 finished \tANN training loss 0.192486 Accuracy: 0.930760\n",
      ">> Epoch 2670 finished \tANN training loss 0.261501 Accuracy: 0.899735\n",
      ">> Epoch 2671 finished \tANN training loss 0.169768 Accuracy: 0.943246\n",
      ">> Epoch 2672 finished \tANN training loss 0.238452 Accuracy: 0.911086\n",
      ">> Epoch 2673 finished \tANN training loss 0.228045 Accuracy: 0.916005\n",
      ">> Epoch 2674 finished \tANN training loss 0.148444 Accuracy: 0.949678\n",
      ">> Epoch 2675 finished \tANN training loss 0.187103 Accuracy: 0.929247\n",
      ">> Epoch 2676 finished \tANN training loss 0.225838 Accuracy: 0.914113\n",
      ">> Epoch 2677 finished \tANN training loss 0.242990 Accuracy: 0.902762\n",
      ">> Epoch 2678 finished \tANN training loss 0.221039 Accuracy: 0.916383\n",
      ">> Epoch 2679 finished \tANN training loss 0.164867 Accuracy: 0.938328\n",
      ">> Epoch 2680 finished \tANN training loss 0.186857 Accuracy: 0.933031\n",
      ">> Epoch 2681 finished \tANN training loss 0.184287 Accuracy: 0.931517\n",
      ">> Epoch 2682 finished \tANN training loss 0.162756 Accuracy: 0.943246\n",
      ">> Epoch 2683 finished \tANN training loss 0.156542 Accuracy: 0.945516\n",
      ">> Epoch 2684 finished \tANN training loss 0.144611 Accuracy: 0.946652\n",
      ">> Epoch 2685 finished \tANN training loss 0.204169 Accuracy: 0.922437\n",
      ">> Epoch 2686 finished \tANN training loss 0.202407 Accuracy: 0.924707\n",
      ">> Epoch 2687 finished \tANN training loss 0.185277 Accuracy: 0.933409\n",
      ">> Epoch 2688 finished \tANN training loss 0.211880 Accuracy: 0.920545\n",
      ">> Epoch 2689 finished \tANN training loss 0.162858 Accuracy: 0.939084\n",
      ">> Epoch 2690 finished \tANN training loss 0.186675 Accuracy: 0.931517\n",
      ">> Epoch 2691 finished \tANN training loss 0.237906 Accuracy: 0.908437\n",
      ">> Epoch 2692 finished \tANN training loss 0.202659 Accuracy: 0.929625\n",
      ">> Epoch 2693 finished \tANN training loss 0.152732 Accuracy: 0.945138\n",
      ">> Epoch 2694 finished \tANN training loss 0.248121 Accuracy: 0.899357\n",
      ">> Epoch 2695 finished \tANN training loss 0.161062 Accuracy: 0.944381\n",
      ">> Epoch 2696 finished \tANN training loss 0.159652 Accuracy: 0.946273\n",
      ">> Epoch 2697 finished \tANN training loss 0.193075 Accuracy: 0.935301\n",
      ">> Epoch 2698 finished \tANN training loss 0.162687 Accuracy: 0.941733\n",
      ">> Epoch 2699 finished \tANN training loss 0.161024 Accuracy: 0.944760\n",
      ">> Epoch 2700 finished \tANN training loss 0.155135 Accuracy: 0.948922\n",
      ">> Epoch 2701 finished \tANN training loss 0.238443 Accuracy: 0.913356\n",
      ">> Epoch 2702 finished \tANN training loss 0.297469 Accuracy: 0.898600\n",
      ">> Epoch 2703 finished \tANN training loss 0.214070 Accuracy: 0.924328\n",
      ">> Epoch 2704 finished \tANN training loss 0.168958 Accuracy: 0.942868\n",
      ">> Epoch 2705 finished \tANN training loss 0.203977 Accuracy: 0.925463\n",
      ">> Epoch 2706 finished \tANN training loss 0.281140 Accuracy: 0.898222\n",
      ">> Epoch 2707 finished \tANN training loss 0.307233 Accuracy: 0.880061\n",
      ">> Epoch 2708 finished \tANN training loss 0.163821 Accuracy: 0.944381\n",
      ">> Epoch 2709 finished \tANN training loss 0.210692 Accuracy: 0.920923\n",
      ">> Epoch 2710 finished \tANN training loss 0.218229 Accuracy: 0.913356\n",
      ">> Epoch 2711 finished \tANN training loss 0.243723 Accuracy: 0.908059\n",
      ">> Epoch 2712 finished \tANN training loss 0.198968 Accuracy: 0.927734\n",
      ">> Epoch 2713 finished \tANN training loss 0.147799 Accuracy: 0.954975\n",
      ">> Epoch 2714 finished \tANN training loss 0.184697 Accuracy: 0.927355\n",
      ">> Epoch 2715 finished \tANN training loss 0.168224 Accuracy: 0.943625\n",
      ">> Epoch 2716 finished \tANN training loss 0.174649 Accuracy: 0.939084\n",
      ">> Epoch 2717 finished \tANN training loss 0.184508 Accuracy: 0.929625\n",
      ">> Epoch 2718 finished \tANN training loss 0.163183 Accuracy: 0.945895\n",
      ">> Epoch 2719 finished \tANN training loss 0.159784 Accuracy: 0.938706\n",
      ">> Epoch 2720 finished \tANN training loss 0.171012 Accuracy: 0.942490\n",
      ">> Epoch 2721 finished \tANN training loss 0.185503 Accuracy: 0.931896\n",
      ">> Epoch 2722 finished \tANN training loss 0.158015 Accuracy: 0.940219\n",
      ">> Epoch 2723 finished \tANN training loss 0.200542 Accuracy: 0.923950\n",
      ">> Epoch 2724 finished \tANN training loss 0.189244 Accuracy: 0.926220\n",
      ">> Epoch 2725 finished \tANN training loss 0.205184 Accuracy: 0.924328\n",
      ">> Epoch 2726 finished \tANN training loss 0.170328 Accuracy: 0.943625\n",
      ">> Epoch 2727 finished \tANN training loss 0.164395 Accuracy: 0.942868\n",
      ">> Epoch 2728 finished \tANN training loss 0.225438 Accuracy: 0.912221\n",
      ">> Epoch 2729 finished \tANN training loss 0.220629 Accuracy: 0.916005\n",
      ">> Epoch 2730 finished \tANN training loss 0.218587 Accuracy: 0.910708\n",
      ">> Epoch 2731 finished \tANN training loss 0.174177 Accuracy: 0.940976\n",
      ">> Epoch 2732 finished \tANN training loss 0.197263 Accuracy: 0.928490\n",
      ">> Epoch 2733 finished \tANN training loss 0.262947 Accuracy: 0.896330\n",
      ">> Epoch 2734 finished \tANN training loss 0.200537 Accuracy: 0.916761\n",
      ">> Epoch 2735 finished \tANN training loss 0.153382 Accuracy: 0.947030\n",
      ">> Epoch 2736 finished \tANN training loss 0.219247 Accuracy: 0.915626\n",
      ">> Epoch 2737 finished \tANN training loss 0.182814 Accuracy: 0.930760\n",
      ">> Epoch 2738 finished \tANN training loss 0.147427 Accuracy: 0.948922\n",
      ">> Epoch 2739 finished \tANN training loss 0.203805 Accuracy: 0.925842\n",
      ">> Epoch 2740 finished \tANN training loss 0.206995 Accuracy: 0.935679\n",
      ">> Epoch 2741 finished \tANN training loss 0.265043 Accuracy: 0.895952\n",
      ">> Epoch 2742 finished \tANN training loss 0.175155 Accuracy: 0.935301\n",
      ">> Epoch 2743 finished \tANN training loss 0.210636 Accuracy: 0.923950\n",
      ">> Epoch 2744 finished \tANN training loss 0.180639 Accuracy: 0.934166\n",
      ">> Epoch 2745 finished \tANN training loss 0.253170 Accuracy: 0.911464\n",
      ">> Epoch 2746 finished \tANN training loss 0.240958 Accuracy: 0.909572\n",
      ">> Epoch 2747 finished \tANN training loss 0.182889 Accuracy: 0.938328\n",
      ">> Epoch 2748 finished \tANN training loss 0.207116 Accuracy: 0.925842\n",
      ">> Epoch 2749 finished \tANN training loss 0.194137 Accuracy: 0.933409\n",
      ">> Epoch 2750 finished \tANN training loss 0.180664 Accuracy: 0.936436\n",
      ">> Epoch 2751 finished \tANN training loss 0.186505 Accuracy: 0.936058\n",
      ">> Epoch 2752 finished \tANN training loss 0.185457 Accuracy: 0.931896\n",
      ">> Epoch 2753 finished \tANN training loss 0.183842 Accuracy: 0.933787\n",
      ">> Epoch 2754 finished \tANN training loss 0.171828 Accuracy: 0.936814\n",
      ">> Epoch 2755 finished \tANN training loss 0.163534 Accuracy: 0.944381\n",
      ">> Epoch 2756 finished \tANN training loss 0.154633 Accuracy: 0.947408\n",
      ">> Epoch 2757 finished \tANN training loss 0.204273 Accuracy: 0.921302\n",
      ">> Epoch 2758 finished \tANN training loss 0.196850 Accuracy: 0.933031\n",
      ">> Epoch 2759 finished \tANN training loss 0.218066 Accuracy: 0.909572\n",
      ">> Epoch 2760 finished \tANN training loss 0.228339 Accuracy: 0.904654\n",
      ">> Epoch 2761 finished \tANN training loss 0.142574 Accuracy: 0.950435\n",
      ">> Epoch 2762 finished \tANN training loss 0.208487 Accuracy: 0.920923\n",
      ">> Epoch 2763 finished \tANN training loss 0.215380 Accuracy: 0.916383\n",
      ">> Epoch 2764 finished \tANN training loss 0.173449 Accuracy: 0.937949\n",
      ">> Epoch 2765 finished \tANN training loss 0.167125 Accuracy: 0.940219\n",
      ">> Epoch 2766 finished \tANN training loss 0.204329 Accuracy: 0.921302\n",
      ">> Epoch 2767 finished \tANN training loss 0.155882 Accuracy: 0.944003\n",
      ">> Epoch 2768 finished \tANN training loss 0.191335 Accuracy: 0.931139\n",
      ">> Epoch 2769 finished \tANN training loss 0.150131 Accuracy: 0.953084\n",
      ">> Epoch 2770 finished \tANN training loss 0.162409 Accuracy: 0.943625\n",
      ">> Epoch 2771 finished \tANN training loss 0.180191 Accuracy: 0.932274\n",
      ">> Epoch 2772 finished \tANN training loss 0.261754 Accuracy: 0.891790\n",
      ">> Epoch 2773 finished \tANN training loss 0.180622 Accuracy: 0.933409\n",
      ">> Epoch 2774 finished \tANN training loss 0.166531 Accuracy: 0.940976\n",
      ">> Epoch 2775 finished \tANN training loss 0.163302 Accuracy: 0.945895\n",
      ">> Epoch 2776 finished \tANN training loss 0.183218 Accuracy: 0.933031\n",
      ">> Epoch 2777 finished \tANN training loss 0.188123 Accuracy: 0.926599\n",
      ">> Epoch 2778 finished \tANN training loss 0.172129 Accuracy: 0.934544\n",
      ">> Epoch 2779 finished \tANN training loss 0.200108 Accuracy: 0.931896\n",
      ">> Epoch 2780 finished \tANN training loss 0.190992 Accuracy: 0.925085\n",
      ">> Epoch 2781 finished \tANN training loss 0.192794 Accuracy: 0.933031\n",
      ">> Epoch 2782 finished \tANN training loss 0.190797 Accuracy: 0.934544\n",
      ">> Epoch 2783 finished \tANN training loss 0.147553 Accuracy: 0.948165\n",
      ">> Epoch 2784 finished \tANN training loss 0.217940 Accuracy: 0.917896\n",
      ">> Epoch 2785 finished \tANN training loss 0.142407 Accuracy: 0.950813\n",
      ">> Epoch 2786 finished \tANN training loss 0.160397 Accuracy: 0.940976\n",
      ">> Epoch 2787 finished \tANN training loss 0.210994 Accuracy: 0.917140\n",
      ">> Epoch 2788 finished \tANN training loss 0.206103 Accuracy: 0.923572\n",
      ">> Epoch 2789 finished \tANN training loss 0.205636 Accuracy: 0.919410\n",
      ">> Epoch 2790 finished \tANN training loss 0.173753 Accuracy: 0.935301\n",
      ">> Epoch 2791 finished \tANN training loss 0.198562 Accuracy: 0.927355\n",
      ">> Epoch 2792 finished \tANN training loss 0.172250 Accuracy: 0.941355\n",
      ">> Epoch 2793 finished \tANN training loss 0.172211 Accuracy: 0.939463\n",
      ">> Epoch 2794 finished \tANN training loss 0.225665 Accuracy: 0.912221\n",
      ">> Epoch 2795 finished \tANN training loss 0.160358 Accuracy: 0.940219\n",
      ">> Epoch 2796 finished \tANN training loss 0.203298 Accuracy: 0.925842\n",
      ">> Epoch 2797 finished \tANN training loss 0.187730 Accuracy: 0.932652\n",
      ">> Epoch 2798 finished \tANN training loss 0.177659 Accuracy: 0.939463\n",
      ">> Epoch 2799 finished \tANN training loss 0.171689 Accuracy: 0.940219\n",
      ">> Epoch 2800 finished \tANN training loss 0.155392 Accuracy: 0.945895\n",
      ">> Epoch 2801 finished \tANN training loss 0.183890 Accuracy: 0.937193\n",
      ">> Epoch 2802 finished \tANN training loss 0.176502 Accuracy: 0.942868\n",
      ">> Epoch 2803 finished \tANN training loss 0.194340 Accuracy: 0.921302\n",
      ">> Epoch 2804 finished \tANN training loss 0.158518 Accuracy: 0.943625\n",
      ">> Epoch 2805 finished \tANN training loss 0.140590 Accuracy: 0.954975\n",
      ">> Epoch 2806 finished \tANN training loss 0.251661 Accuracy: 0.905789\n",
      ">> Epoch 2807 finished \tANN training loss 0.167144 Accuracy: 0.942490\n",
      ">> Epoch 2808 finished \tANN training loss 0.176350 Accuracy: 0.938328\n",
      ">> Epoch 2809 finished \tANN training loss 0.195145 Accuracy: 0.923950\n",
      ">> Epoch 2810 finished \tANN training loss 0.258722 Accuracy: 0.898600\n",
      ">> Epoch 2811 finished \tANN training loss 0.196889 Accuracy: 0.919788\n",
      ">> Epoch 2812 finished \tANN training loss 0.215553 Accuracy: 0.926977\n",
      ">> Epoch 2813 finished \tANN training loss 0.157492 Accuracy: 0.944760\n",
      ">> Epoch 2814 finished \tANN training loss 0.173453 Accuracy: 0.930004\n",
      ">> Epoch 2815 finished \tANN training loss 0.173218 Accuracy: 0.936814\n",
      ">> Epoch 2816 finished \tANN training loss 0.236258 Accuracy: 0.904275\n",
      ">> Epoch 2817 finished \tANN training loss 0.181758 Accuracy: 0.931896\n",
      ">> Epoch 2818 finished \tANN training loss 0.159701 Accuracy: 0.940976\n",
      ">> Epoch 2819 finished \tANN training loss 0.149436 Accuracy: 0.947787\n",
      ">> Epoch 2820 finished \tANN training loss 0.173609 Accuracy: 0.936814\n",
      ">> Epoch 2821 finished \tANN training loss 0.194224 Accuracy: 0.930760\n",
      ">> Epoch 2822 finished \tANN training loss 0.235804 Accuracy: 0.914491\n",
      ">> Epoch 2823 finished \tANN training loss 0.171866 Accuracy: 0.939463\n",
      ">> Epoch 2824 finished \tANN training loss 0.171321 Accuracy: 0.937571\n",
      ">> Epoch 2825 finished \tANN training loss 0.196744 Accuracy: 0.929247\n",
      ">> Epoch 2826 finished \tANN training loss 0.178944 Accuracy: 0.937571\n",
      ">> Epoch 2827 finished \tANN training loss 0.166568 Accuracy: 0.936814\n",
      ">> Epoch 2828 finished \tANN training loss 0.164481 Accuracy: 0.936814\n",
      ">> Epoch 2829 finished \tANN training loss 0.177096 Accuracy: 0.926977\n",
      ">> Epoch 2830 finished \tANN training loss 0.187102 Accuracy: 0.937193\n",
      ">> Epoch 2831 finished \tANN training loss 0.155928 Accuracy: 0.945516\n",
      ">> Epoch 2832 finished \tANN training loss 0.208728 Accuracy: 0.933031\n",
      ">> Epoch 2833 finished \tANN training loss 0.197588 Accuracy: 0.927734\n",
      ">> Epoch 2834 finished \tANN training loss 0.157987 Accuracy: 0.946273\n",
      ">> Epoch 2835 finished \tANN training loss 0.153215 Accuracy: 0.941733\n",
      ">> Epoch 2836 finished \tANN training loss 0.226531 Accuracy: 0.909951\n",
      ">> Epoch 2837 finished \tANN training loss 0.219359 Accuracy: 0.921302\n",
      ">> Epoch 2838 finished \tANN training loss 0.133815 Accuracy: 0.957246\n",
      ">> Epoch 2839 finished \tANN training loss 0.183617 Accuracy: 0.931517\n",
      ">> Epoch 2840 finished \tANN training loss 0.166131 Accuracy: 0.940976\n",
      ">> Epoch 2841 finished \tANN training loss 0.210387 Accuracy: 0.922058\n",
      ">> Epoch 2842 finished \tANN training loss 0.158027 Accuracy: 0.944760\n",
      ">> Epoch 2843 finished \tANN training loss 0.232597 Accuracy: 0.919788\n",
      ">> Epoch 2844 finished \tANN training loss 0.161744 Accuracy: 0.945895\n",
      ">> Epoch 2845 finished \tANN training loss 0.198304 Accuracy: 0.920166\n",
      ">> Epoch 2846 finished \tANN training loss 0.177809 Accuracy: 0.936814\n",
      ">> Epoch 2847 finished \tANN training loss 0.195153 Accuracy: 0.928490\n",
      ">> Epoch 2848 finished \tANN training loss 0.261140 Accuracy: 0.894060\n",
      ">> Epoch 2849 finished \tANN training loss 0.175790 Accuracy: 0.937571\n",
      ">> Epoch 2850 finished \tANN training loss 0.190427 Accuracy: 0.935301\n",
      ">> Epoch 2851 finished \tANN training loss 0.217363 Accuracy: 0.916761\n",
      ">> Epoch 2852 finished \tANN training loss 0.269469 Accuracy: 0.898978\n",
      ">> Epoch 2853 finished \tANN training loss 0.233763 Accuracy: 0.912978\n",
      ">> Epoch 2854 finished \tANN training loss 0.176859 Accuracy: 0.939841\n",
      ">> Epoch 2855 finished \tANN training loss 0.168542 Accuracy: 0.941733\n",
      ">> Epoch 2856 finished \tANN training loss 0.165991 Accuracy: 0.941355\n",
      ">> Epoch 2857 finished \tANN training loss 0.182403 Accuracy: 0.928490\n",
      ">> Epoch 2858 finished \tANN training loss 0.181795 Accuracy: 0.932274\n",
      ">> Epoch 2859 finished \tANN training loss 0.227130 Accuracy: 0.911464\n",
      ">> Epoch 2860 finished \tANN training loss 0.197761 Accuracy: 0.929247\n",
      ">> Epoch 2861 finished \tANN training loss 0.257481 Accuracy: 0.892925\n",
      ">> Epoch 2862 finished \tANN training loss 0.223436 Accuracy: 0.912221\n",
      ">> Epoch 2863 finished \tANN training loss 0.241559 Accuracy: 0.899357\n",
      ">> Epoch 2864 finished \tANN training loss 0.193454 Accuracy: 0.926599\n",
      ">> Epoch 2865 finished \tANN training loss 0.165037 Accuracy: 0.941733\n",
      ">> Epoch 2866 finished \tANN training loss 0.143345 Accuracy: 0.948165\n",
      ">> Epoch 2867 finished \tANN training loss 0.157564 Accuracy: 0.942111\n",
      ">> Epoch 2868 finished \tANN training loss 0.145117 Accuracy: 0.951192\n",
      ">> Epoch 2869 finished \tANN training loss 0.202943 Accuracy: 0.931517\n",
      ">> Epoch 2870 finished \tANN training loss 0.182503 Accuracy: 0.926220\n",
      ">> Epoch 2871 finished \tANN training loss 0.161466 Accuracy: 0.938706\n",
      ">> Epoch 2872 finished \tANN training loss 0.165530 Accuracy: 0.940598\n",
      ">> Epoch 2873 finished \tANN training loss 0.179783 Accuracy: 0.939463\n",
      ">> Epoch 2874 finished \tANN training loss 0.203513 Accuracy: 0.917518\n",
      ">> Epoch 2875 finished \tANN training loss 0.223439 Accuracy: 0.914869\n",
      ">> Epoch 2876 finished \tANN training loss 0.159230 Accuracy: 0.946273\n",
      ">> Epoch 2877 finished \tANN training loss 0.203606 Accuracy: 0.928112\n",
      ">> Epoch 2878 finished \tANN training loss 0.208086 Accuracy: 0.920923\n",
      ">> Epoch 2879 finished \tANN training loss 0.234938 Accuracy: 0.907681\n",
      ">> Epoch 2880 finished \tANN training loss 0.143763 Accuracy: 0.949300\n",
      ">> Epoch 2881 finished \tANN training loss 0.185829 Accuracy: 0.923572\n",
      ">> Epoch 2882 finished \tANN training loss 0.150195 Accuracy: 0.950435\n",
      ">> Epoch 2883 finished \tANN training loss 0.167762 Accuracy: 0.940219\n",
      ">> Epoch 2884 finished \tANN training loss 0.164576 Accuracy: 0.944003\n",
      ">> Epoch 2885 finished \tANN training loss 0.161975 Accuracy: 0.940976\n",
      ">> Epoch 2886 finished \tANN training loss 0.163514 Accuracy: 0.943625\n",
      ">> Epoch 2887 finished \tANN training loss 0.171660 Accuracy: 0.940598\n",
      ">> Epoch 2888 finished \tANN training loss 0.191260 Accuracy: 0.926977\n",
      ">> Epoch 2889 finished \tANN training loss 0.174933 Accuracy: 0.933031\n",
      ">> Epoch 2890 finished \tANN training loss 0.140718 Accuracy: 0.955732\n",
      ">> Epoch 2891 finished \tANN training loss 0.216517 Accuracy: 0.928869\n",
      ">> Epoch 2892 finished \tANN training loss 0.200653 Accuracy: 0.929247\n",
      ">> Epoch 2893 finished \tANN training loss 0.168997 Accuracy: 0.936058\n",
      ">> Epoch 2894 finished \tANN training loss 0.169755 Accuracy: 0.943625\n",
      ">> Epoch 2895 finished \tANN training loss 0.193155 Accuracy: 0.930760\n",
      ">> Epoch 2896 finished \tANN training loss 0.162131 Accuracy: 0.939463\n",
      ">> Epoch 2897 finished \tANN training loss 0.203805 Accuracy: 0.916761\n",
      ">> Epoch 2898 finished \tANN training loss 0.194447 Accuracy: 0.928490\n",
      ">> Epoch 2899 finished \tANN training loss 0.184096 Accuracy: 0.936436\n",
      ">> Epoch 2900 finished \tANN training loss 0.214656 Accuracy: 0.917140\n",
      ">> Epoch 2901 finished \tANN training loss 0.198289 Accuracy: 0.922437\n",
      ">> Epoch 2902 finished \tANN training loss 0.165530 Accuracy: 0.947030\n",
      ">> Epoch 2903 finished \tANN training loss 0.164359 Accuracy: 0.944003\n",
      ">> Epoch 2904 finished \tANN training loss 0.196796 Accuracy: 0.925463\n",
      ">> Epoch 2905 finished \tANN training loss 0.325304 Accuracy: 0.872115\n",
      ">> Epoch 2906 finished \tANN training loss 0.160865 Accuracy: 0.942868\n",
      ">> Epoch 2907 finished \tANN training loss 0.202962 Accuracy: 0.920545\n",
      ">> Epoch 2908 finished \tANN training loss 0.176568 Accuracy: 0.929625\n",
      ">> Epoch 2909 finished \tANN training loss 0.167482 Accuracy: 0.938328\n",
      ">> Epoch 2910 finished \tANN training loss 0.174839 Accuracy: 0.943246\n",
      ">> Epoch 2911 finished \tANN training loss 0.325153 Accuracy: 0.873628\n",
      ">> Epoch 2912 finished \tANN training loss 0.228551 Accuracy: 0.905032\n",
      ">> Epoch 2913 finished \tANN training loss 0.172559 Accuracy: 0.941355\n",
      ">> Epoch 2914 finished \tANN training loss 0.261067 Accuracy: 0.896708\n",
      ">> Epoch 2915 finished \tANN training loss 0.179161 Accuracy: 0.935679\n",
      ">> Epoch 2916 finished \tANN training loss 0.160970 Accuracy: 0.946273\n",
      ">> Epoch 2917 finished \tANN training loss 0.165881 Accuracy: 0.941733\n",
      ">> Epoch 2918 finished \tANN training loss 0.165448 Accuracy: 0.940598\n",
      ">> Epoch 2919 finished \tANN training loss 0.153095 Accuracy: 0.946273\n",
      ">> Epoch 2920 finished \tANN training loss 0.153792 Accuracy: 0.946273\n",
      ">> Epoch 2921 finished \tANN training loss 0.154695 Accuracy: 0.942111\n",
      ">> Epoch 2922 finished \tANN training loss 0.177040 Accuracy: 0.936436\n",
      ">> Epoch 2923 finished \tANN training loss 0.190242 Accuracy: 0.927355\n",
      ">> Epoch 2924 finished \tANN training loss 0.183713 Accuracy: 0.933031\n",
      ">> Epoch 2925 finished \tANN training loss 0.171987 Accuracy: 0.941733\n",
      ">> Epoch 2926 finished \tANN training loss 0.222347 Accuracy: 0.921302\n",
      ">> Epoch 2927 finished \tANN training loss 0.256295 Accuracy: 0.897465\n",
      ">> Epoch 2928 finished \tANN training loss 0.187275 Accuracy: 0.939084\n",
      ">> Epoch 2929 finished \tANN training loss 0.264535 Accuracy: 0.888384\n",
      ">> Epoch 2930 finished \tANN training loss 0.208168 Accuracy: 0.932274\n",
      ">> Epoch 2931 finished \tANN training loss 0.170789 Accuracy: 0.934166\n",
      ">> Epoch 2932 finished \tANN training loss 0.151861 Accuracy: 0.947030\n",
      ">> Epoch 2933 finished \tANN training loss 0.198796 Accuracy: 0.925842\n",
      ">> Epoch 2934 finished \tANN training loss 0.161060 Accuracy: 0.942868\n",
      ">> Epoch 2935 finished \tANN training loss 0.202222 Accuracy: 0.931517\n",
      ">> Epoch 2936 finished \tANN training loss 0.232617 Accuracy: 0.911843\n",
      ">> Epoch 2937 finished \tANN training loss 0.199676 Accuracy: 0.915248\n",
      ">> Epoch 2938 finished \tANN training loss 0.261841 Accuracy: 0.911843\n",
      ">> Epoch 2939 finished \tANN training loss 0.211592 Accuracy: 0.914491\n",
      ">> Epoch 2940 finished \tANN training loss 0.193441 Accuracy: 0.932274\n",
      ">> Epoch 2941 finished \tANN training loss 0.211248 Accuracy: 0.921302\n",
      ">> Epoch 2942 finished \tANN training loss 0.186852 Accuracy: 0.932652\n",
      ">> Epoch 2943 finished \tANN training loss 0.174888 Accuracy: 0.930004\n",
      ">> Epoch 2944 finished \tANN training loss 0.154261 Accuracy: 0.949678\n",
      ">> Epoch 2945 finished \tANN training loss 0.169141 Accuracy: 0.938706\n",
      ">> Epoch 2946 finished \tANN training loss 0.196807 Accuracy: 0.928112\n",
      ">> Epoch 2947 finished \tANN training loss 0.183573 Accuracy: 0.934922\n",
      ">> Epoch 2948 finished \tANN training loss 0.186057 Accuracy: 0.928869\n",
      ">> Epoch 2949 finished \tANN training loss 0.191523 Accuracy: 0.933031\n",
      ">> Epoch 2950 finished \tANN training loss 0.145377 Accuracy: 0.951192\n",
      ">> Epoch 2951 finished \tANN training loss 0.160426 Accuracy: 0.940598\n",
      ">> Epoch 2952 finished \tANN training loss 0.192425 Accuracy: 0.930382\n",
      ">> Epoch 2953 finished \tANN training loss 0.157995 Accuracy: 0.940598\n",
      ">> Epoch 2954 finished \tANN training loss 0.252591 Accuracy: 0.908816\n",
      ">> Epoch 2955 finished \tANN training loss 0.204385 Accuracy: 0.921302\n",
      ">> Epoch 2956 finished \tANN training loss 0.155761 Accuracy: 0.942111\n",
      ">> Epoch 2957 finished \tANN training loss 0.166743 Accuracy: 0.937949\n",
      ">> Epoch 2958 finished \tANN training loss 0.236951 Accuracy: 0.906546\n",
      ">> Epoch 2959 finished \tANN training loss 0.174718 Accuracy: 0.938328\n",
      ">> Epoch 2960 finished \tANN training loss 0.180786 Accuracy: 0.935679\n",
      ">> Epoch 2961 finished \tANN training loss 0.192234 Accuracy: 0.930382\n",
      ">> Epoch 2962 finished \tANN training loss 0.135439 Accuracy: 0.954597\n",
      ">> Epoch 2963 finished \tANN training loss 0.198646 Accuracy: 0.935679\n",
      ">> Epoch 2964 finished \tANN training loss 0.346323 Accuracy: 0.874385\n",
      ">> Epoch 2965 finished \tANN training loss 0.220084 Accuracy: 0.918275\n",
      ">> Epoch 2966 finished \tANN training loss 0.183192 Accuracy: 0.935301\n",
      ">> Epoch 2967 finished \tANN training loss 0.238253 Accuracy: 0.913356\n",
      ">> Epoch 2968 finished \tANN training loss 0.157037 Accuracy: 0.948543\n",
      ">> Epoch 2969 finished \tANN training loss 0.190211 Accuracy: 0.934166\n",
      ">> Epoch 2970 finished \tANN training loss 0.205086 Accuracy: 0.925463\n",
      ">> Epoch 2971 finished \tANN training loss 0.160341 Accuracy: 0.940598\n",
      ">> Epoch 2972 finished \tANN training loss 0.164254 Accuracy: 0.938706\n",
      ">> Epoch 2973 finished \tANN training loss 0.183174 Accuracy: 0.931896\n",
      ">> Epoch 2974 finished \tANN training loss 0.179796 Accuracy: 0.940219\n",
      ">> Epoch 2975 finished \tANN training loss 0.172424 Accuracy: 0.938328\n",
      ">> Epoch 2976 finished \tANN training loss 0.174706 Accuracy: 0.935301\n",
      ">> Epoch 2977 finished \tANN training loss 0.166044 Accuracy: 0.937949\n",
      ">> Epoch 2978 finished \tANN training loss 0.157804 Accuracy: 0.940976\n",
      ">> Epoch 2979 finished \tANN training loss 0.291760 Accuracy: 0.880817\n",
      ">> Epoch 2980 finished \tANN training loss 0.158931 Accuracy: 0.946273\n",
      ">> Epoch 2981 finished \tANN training loss 0.208602 Accuracy: 0.922815\n",
      ">> Epoch 2982 finished \tANN training loss 0.181346 Accuracy: 0.934544\n",
      ">> Epoch 2983 finished \tANN training loss 0.195177 Accuracy: 0.928112\n",
      ">> Epoch 2984 finished \tANN training loss 0.144820 Accuracy: 0.955354\n",
      ">> Epoch 2985 finished \tANN training loss 0.161902 Accuracy: 0.942490\n",
      ">> Epoch 2986 finished \tANN training loss 0.369790 Accuracy: 0.867953\n",
      ">> Epoch 2987 finished \tANN training loss 0.191170 Accuracy: 0.930760\n",
      ">> Epoch 2988 finished \tANN training loss 0.232730 Accuracy: 0.923950\n",
      ">> Epoch 2989 finished \tANN training loss 0.183206 Accuracy: 0.926220\n",
      ">> Epoch 2990 finished \tANN training loss 0.166983 Accuracy: 0.940219\n",
      ">> Epoch 2991 finished \tANN training loss 0.175415 Accuracy: 0.934544\n",
      ">> Epoch 2992 finished \tANN training loss 0.169858 Accuracy: 0.939463\n",
      ">> Epoch 2993 finished \tANN training loss 0.149226 Accuracy: 0.947408\n",
      ">> Epoch 2994 finished \tANN training loss 0.176763 Accuracy: 0.936058\n",
      ">> Epoch 2995 finished \tANN training loss 0.153773 Accuracy: 0.939084\n",
      ">> Epoch 2996 finished \tANN training loss 0.246820 Accuracy: 0.891790\n",
      ">> Epoch 2997 finished \tANN training loss 0.216697 Accuracy: 0.909572\n",
      ">> Epoch 2998 finished \tANN training loss 0.162407 Accuracy: 0.937949\n",
      ">> Epoch 2999 finished \tANN training loss 0.161254 Accuracy: 0.939084\n",
      "[END] Fine tuning step\n"
     ]
    }
   ],
   "source": [
    "from dbn.dbn.tensorflow import SupervisedDBNClassification\n",
    "model = SupervisedDBNClassification(hidden_layers_structure=[256, 256],\n",
    "                                         learning_rate_rbm=0.05,\n",
    "                                         learning_rate=0.5,\n",
    "                                         n_epochs_rbm=10,\n",
    "                                         n_iter_backprop=EPOCHS,\n",
    "                                         batch_size=64,\n",
    "                                         activation_function='relu',\n",
    "                                         dropout_p=0.1)\n",
    "\n",
    "history = model.fit(X_train, y_train)\n",
    "Y_pred = model.predict(X_test)\n",
    "from sklearn.metrics import hamming_loss, accuracy_score, precision_score, recall_score\n",
    "m, e, h = model, [hamming_loss(y_test, Y_pred), accuracy_score(y_test, Y_pred), precision_score(y_test, Y_pred, average='micro'), recall_score(y_test, Y_pred, average='micro')], history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3dde9f21-3f87-4fad-b891-100ef45ebe69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<h2>Deep Belief Networks (DBN)</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.16\n",
      "Accuracy: 84%\n",
      "Precision: 0.84\n",
      "Recall: 0.84\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1800x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "name = \"Deep Belief Networks (DBN)\"\n",
    "display(Markdown(f'<h2>{name}</h2>'))\n",
    "print(f'Loss: {e[0]:.2f}')\n",
    "print(f'Accuracy: {int(e[1] * 100)}%')\n",
    "print(f'Precision: {e[2]:.2f}')\n",
    "print(f'Recall: {e[3]:.2f}')\n",
    "\n",
    "plt.figure(1)\n",
    "range_epochs = np.arange(1, len(h.losses)+1)\n",
    "plt.plot(range_epochs, h.losses, label='Loss',color='red')\n",
    "plt.plot(range_epochs, h.accuracies, label='Accuracy',color='green')\n",
    "plt.title(f\"Evaluation Metrics {name}\", size=16)\n",
    "plt.xlabel(\"Epoch\", size=14)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e4a6540-f438-4f6a-8754-3812de604c34",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Outcome diversity:  3524 3524 3524 3524\n",
      "Number of wrong: 1188 out of 14096\n"
     ]
    }
   ],
   "source": [
    "test_set = []\n",
    "res_set = []\n",
    "\n",
    "con2 = sqlite3.connect(os.path.join(current_path,\"tmp\",\"save.db3\"))\n",
    "cur2 = con2.cursor()\n",
    "cur2.execute(f\"Select {feature_column},result FROM DataSet\")\n",
    "rows = cur2.fetchall()\n",
    "parameters = [[float(item or 0) for item in row[:-1]] for row in rows]\n",
    "expected = [int(row[-1]) for row in rows]\n",
    "con2.close()\n",
    "\n",
    "print(\"Outcome diversity: \", expected.count(0),expected.count(1),expected.count(2),expected.count(3))\n",
    "\n",
    "test_valid = np.array(parameters)\n",
    "predicted = list(model.predict(test_valid))\n",
    "check = []\n",
    "for idx, res in enumerate(expected):\n",
    "    check.append(predicted[idx]==res)\n",
    "print(\"Number of wrong:\", check.count(False), \"out of\", len(check))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
